'use strict'; (function() { const indexCfg = { encode: false, tokenize: function(str) { return str.replace(/[\x00-\x7F]/g, '').split(''); } }; indexCfg.doc = { id: 'id', field: ['title', 'content'], store: ['title', 'href'], }; const index = FlexSearch.create('balance', indexCfg); window.bookSearchIndex = index; index.add({ 'id': 0, 'href': '/docs/sicp/hardware/', 'title': "硬件部分", 'content': " 计算机科学基础知识之硬件部分 现代计算机体系的基础理论部分仍然是70年代就已经产生的，这些年来一直没有多大突破，只是制造水平和加工工艺在逐步提升。未来除非是量子计算、生物计算等发展成熟，才可能使得计算机基础理论获得革命性突破。\n我们在应用软件开发领域，往往非常善于创造包装一些名词，但它们的本质就是那么回事，学习计算机体系的理论有助于我们抓住这些本质。\n体系结构 CPU要运行一个程序，它需要指令和数据，指令相当于你要干什么，数据是干这件事所需要的材料。\n冯诺依曼结构 冯诺依曼结构就是把指令也当做数据，把指令和数据放在一起。好处就是设计上会简单一些，可以使用一条总线集中存储；另外它还采用了二进制编码的线性地址空间。缺点就是它的数据传输效率远低于CPU的运算效率，因此需要缓存来提升效率。\n它的CPU有两套单元： * ALU：算术逻辑单元，实现多组算术和逻辑运算。由与门和或门组成，进行二进制的算术运算，包括加、减、乘、与、或、非、异或。 * CU：控制单元，用于程序流程的管理。从内存中取指令放入指令寄存器中分析并执行。\nPS：在系统层面上，我们说的内存并不是指物理上的两根内存条，那个叫主存。比如硬盘上的缓存也是内存、打印机上也有缓存等等。\n哈佛结构 哈佛结构将指令和数据分开处理，指令和数据拥有不同的总线和地址空间，并行能力非常强，早期的大型计算机就采用这种结构。缺点就是早期电子电路昂贵，成本的问题使得它不适合于通用计算机没有推广开来。 现在纯粹的哈佛结构多用于数字信号处理器(DSP)、单片机等特定领域，它们的指令相对简单也没有缓存。\n对比总结 实际上现代计算机是对两种架构做了一些折中的。在内存中指令和数据是在一起的，在CPU的L1缓存中，会区分指令缓存和数据缓存，最终执行的时候指令和数据是从两个不同的地方出来的。另外冯诺依曼统一的地址空间也便于我们实现操作系统内存的管理、动态加载程序、JIT等。\n总线 我们通常所说的总线未必是电路板上一条条线路，它只是一种方式，可能是软件的，也可能是硬件的，代表了一整套的规范体系。就像高速公路交通网，包括了公路、收费站、加油站、维护人员、交通规则、信号灯指示牌，总线也是一样，除了数据通道，还包括了数据交换方式，比如从何处取(内存)，从哪开始从哪结束有多长，取出来的是数据还是地址等。\n现在主流的总线标准为PCI/PCIe，该标准的带宽高，能探测硬件变更，支持热插拔。\n总线结构 按照不同的传输速度，我们会把总线分开，通过不同的速度来进行分流，使快速的部分拥有更多的流量带宽。北桥芯片处理快速设备，例如CPU、内存、显卡等，南桥芯片处理慢速设备，例如硬盘、网卡等。\n前端总线(FSB)负责CPU与北桥芯片的数据传输，代表CPU与外界数据的通讯速度，相当于CPU能处理的最高能力。而后端总线(BSB)负责与CPU内核通讯，其速度高于FSB。现在的芯片集成度越来越高的趋势也正是因为想减少各样的总线来提升各部件之间传输的速度。\n中央处理器 中央处理器是用来解释指令、处理数据的。编程实质上就是针对CPU而言的。例如我们往硬盘里写一个文件，就要知道文件名称、写在哪个地址、写入的长度等，即使这些工作不全是由CPU完成，CPU至少也要完成其中的调度工作。\n主频、外频 主频是内核工作频率，表达脉冲信号的震荡速度，与CPU的实际运算能力没有直接关系。而外频是内核与主板间的同步速度，同时也是内存和主板之间的同步速度。\n对现代的CPU而言，衡量其运算速度和性能要看各方面的性能指标，例如缓存、指令集等。很可能出现主频较高的CPU实际运算速度较低的情况。\n指令集 指令集是包含了基本数据类型、指令、寄存器、寻址模式、存储体系、中断和异常处理等打包的一套规范，是CPU真正能够理解的东西。\n我们通常分为精简指令集(RISC)和复杂指令集(CISC)。\n典型的复杂指令集就是x86，它的指令特别多，功能丰富，但每条指令的字长不等，也就造成了它需要先读出指令才知道后面的数据/参数有多长，执行速度相对较慢。而有一些虚拟机内会把指令设置为定长的，默认就是两个参数，这样它的缓存亲和性好，效率就高。x86这么设计有一些历史原因，当时还没有CPU缓存的概念。而精简指令集在早期反而是一种高大上的东西，它的指令和寻址方式少，格式统一，并行速度快，主要用于大型机和中高档服务器中。\nIntel认为自己定义的x86指令集由于历史原因等不好，于是在64位时代定义了IA-64指令集，但这种指令集和以前的x86并不兼容，它采用了模拟的方式去运行x86，这种方式在当时的windows2000等系统上运行的不好，所以微软持反对态度。此时AMD抓住了机会，它基于原有的386/IA-32标准做了扩充，也就有了现在的x86-64指令集，也可以叫做x64或AMD64。后来，Intel迫于其他厂商的压力，也去使用AMD64指令集，并在后来发展出了兼容的Intel 64，这种指令集和AMD64大部分是相同的。\n32位处理器的最大寻址为4GB(2的32次方)，但64位处理器的最大寻址却不是2的64次方。我们知道存储单位的级别从小到大分别为Bytes、KB、MB、GB、TB、PB、EB，每级都等于前一级*1024，所以AMD64理论上可以访问16EB的地址空间，但目前的操作系统只支持到48位，也就是256TB的最大寻址，这种设定的根本原因就是能降低成本。\n此外，AMD64里增加了R8-R15的通用寄存器。\n寄存器和缓存 寄存器是所有存储体里最快的一个，因为数量少，所以可以直接给每个寄存器取个名字，而无需用地址。\n早期，数据由硬盘到内存，再经过前端总线直接到寄存器，因为前端总线传输的效率远低于CPU运算的效率，为了提高性能，我们在CPU内部，寄存器和内存之间增加了一层cache，使得前端总线每次传输更多的内容进入CPU。早期的CPU缓存只有L1，它将指令和数据分开；后来发展至L2，L2不区分指令和数据；再后来多核时代有了L3，能在一个物理处理器的多个核中共享。\n缓存只是解决性能问题的一个媒介，它本身有易丢失、易覆盖的特性，不能像寄存器和主存一样当做目标存储器使用。当CPU需要一个数据时，它会先去L1找，找不到则去L2，再找不到去L3找，再找不到就会去系统总线，找到以后批量的传到L3，再把命中的一部分填充至L2，再填充至L1，再返回给处理器。所以L1里有的数据L2、L3肯定有，每级缓存数据都是下一级的一部分。\n同时，基于时间局部性(正在被访问的数据可能近期再次被访问)、空间局部性(临近地址数据可能即将被访问)、顺序局部性(大部分指令是顺序执行)，可以让缓存有较高的命中率。PS:我们宏观世界的缓存例如web服务中的memcache往往只是基于时间局部性，因为CPU是针对指令和字节的才去讨论其空间局部性和顺序局部性。\n我们写程序要尽可能的让其缓存亲和性更高，数据连续性更高，比如按一定长度对齐某些数据；对于性能要求高的程序，向操作系统申请锁死主存的一部分，避免被交换到硬盘当中去；甚至对于性能要求极致的场景，可以使用汇编以尽可能的使用寄存器。\n缓存由多个块组成，每个块我们称为cache line，每行的数据是连续的，每行的大小通常是64字节，行与行之间可能不连续，所以我们对齐数据的时候也是按行来对齐。同时，缓存中有很多的标志位，通过这些标志位去检查缓存是否更新，以决定是否需要置换回内存。\n多核 在一个处理器内集成多个独立实体物理内核。我们提及Core1、Core2的时候就表示多核，而CPU1、CPU2的时候则是多个CPU。多核能更好的在成本和性能上做出平衡，也不一定比多CPU慢，这主要看软件层面的优化。多核之间可以通过内部的L3缓存进行通讯或数据共享，而多CPU只能通过前端总线或额外建立其他外部通讯机制。\n多核架构又分为两种：\n对称多处理架构(SMP)，多用于桌面端。每个处理器(在多核心处理器的例子中，对称多处理架构，将每一个核心都当成是独立的处理器)的地位是平等的，对资源的使用权限相同。好处是体系简单，缺点就是由于只有一个内存控制器，存在资源竞争的问题，一般是通过软硬件锁的机制解决，但随着处理器数量增加访问冲突就会增加，效率就会下降。\n非统一内存访问架构(NUMA)，是一种为多处理器的电脑设计的内存架构。它将内存分散给多个处理器，处理器访问它自己的本地内存的速度比非本地内存(内存位于另一个处理器，或者是处理器之间共享的内存)快一些。它的扩展性更好，更适用于服务器，针对这种架构去编写程序效率也会更高。\n超线程 对于IO密集型任务，会出现CPU等待时间长的情况。那么超线程就是利用特殊的指令，在单个物理核内虚拟出多个逻辑处理器，在指令等待时做别的任务来减少闲置的时间，当然也需要额外的地方(AS，architectural state)保存当前上下文以切换任务。\n一般语言里提供的CPU数量都是逻辑处理器的数量，会将超线程虚拟的也算进去。例如python的multiprocessing.cpu_count()，或Go的runtime.NumCPU()。\n超线程多数时候可提升执行效率，但在有些情况下可能会导致性能下降，例如一些CPU密集的场合可能会对垃圾回收器造成负担；或者资源冲突时，依然需要等待，类似于同步锁。\n内存 内存严格来说叫内部存储器，不止包括物理上的内存条(即主存)，硬盘、打印机等缓存也算作内部存储器。\n这里说的是主存，即随机存取存储器(RAM，Random Access Memory)，它是与CPU直接交换数据的内部存储器。它可以随时读写，且速度很快，通常做为操作系统的临时数据存储介质。所谓的随机存取，是指当存储器的消息被读取或写入时，所需要的时间与这段信息所在的位置无关。\nDRAM 动态随机存取存储器。它具有结构简单，空间小，需要刷新的特点，往往被用于作为主存。\n需要刷新，是指电容器充满电后代表1，未充电的代表0。由于电容器或多或少有漏电的情形，若不作特别处理，电荷会渐渐随时间流失而使数据发生错误。刷新是指重新为电容器充电，弥补流失了的电荷。\nDDR是指具有双倍数据传输率的SDRAM(动态随机存取存储器)，其数据传输速度为系统时脉的两倍。\nSRAM 静态随机存取存储器。它具有结构复杂，成本高，速度快的特点，一个典型的应用就是缓存。\n所谓的“静态”，是指这种存储器只要保持通电，里面储存的数据就可以恒常保持。相对之下，DRAM里面所储存的数据就需要周期性地更新。\n双通道 它在北桥内使用两个内存控制器分别控制一个通道，从而增加寻址和存储带宽，但是由于缓存的存在，并不需要这样的带宽，所以它对性能的提升往往感受不出来。在集成显卡的场景下会有一定帮助，因为集成显卡用内存作为显存，可以专门使用一条通道。\n显卡 转换显示信息，向显示器提供扫描信号。\n 2D芯片处理3D时需要CPU参与，称作软加速。 3D芯片自己完成，称作硬加速。  GPU是专门用来执行复杂的数学和几何计算的，它和CPU有什么区别呢？\nCPU需要很强的通用性来处理各种不同的数据类型，同时又要逻辑判断又会引入大量的分支跳转和中断的处理。这些都使得CPU的内部结构异常复杂。而GPU面对的则是类型高度统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境。GPU的核数远超CPU，被称为众核(NVIDIA Fermi有512个核)。每个核拥有的缓存大小相对小，数字逻辑运算单元也少而简单。\n当程序员为CPU编写程序时，他们倾向于利用复杂的逻辑结构优化算法从而减少计算任务的运行时间，即Latency。当程序员为GPU编写程序时，则利用其处理海量数据的优势，通过提高总的数据吞吐量(Throughput)来掩盖Lantency。\n硬盘 主要的持久化存储媒介。\n分为固态硬盘(SSD)和机械硬盘(HDD)。SSD使⽤非易失性内存NAND Flash存储数据，无须电⼒维持。又分为单层SLC、双层MLC、三层TLC。单层最快，寿命最⻓，成本也最⾼。现在多使⽤MLC，TLC常作为U盘。\n其接口又分为SATA和SCSI。SATA是串行ATA，PC的标准接口。SCSI多用于小型机。\n其工作模式在BIOS可以设置，早期大多使用PIO，通过CPU执行IO指令读写数据，CPU要持续参与。现在多使用DMA，CPU只需要在开始和结束时参与，中间由DMA完成。\nIO cpu如何访问一大堆的设备？分为PMIO和MMIO。\nPMIO(Port Mapped I/O)是指端口映射输入输出，早期的时候会把主存和其他设备分开，分别用不同的CPU指令读写。因为使用了不同的地址总线，南桥一些慢速设备的访问不会拖累主存访问的效率。\n后来发现这种方式不好，64位时代内存地址空间充裕了就使用了MMIO(Memory Mapped I/O)，它把内存地址空间分段，某一段设备用、程序用、操作系统用等，CPU使用相同的指令不同的地址就可操作设备，所有的设备都在监控地址总线，发现自己被访问就通过自身的缓存和MMU建立连接。\nBIOS 基本输入输出系统，启动后加载的第一个程序。\n最早没有操作系统的时候，写的程序就是面向BIOS的，BIOS在完成硬件初始化之后，会去执行硬盘上某个特定扇区的指令，所以只要把程序放在特定位置程序就可以启动。后来操作系统就放在那个位置，我们写的程序面向操作系统。\n它向操作系统提供系统参数、引导操作系统，但现代的操作系统比如mac就没有BIOS，而是直接控制硬件。\n" }); index.add({ 'id': 1, 'href': '/docs/sicp/software/', 'title': "软件部分", 'content': " 计算机科学基础知识之软件部分 操作系统 它是计算机体系的内核和基石，管理计算机硬件与软件资源。分为:\n 个人机: Windows, macOS, Linux/BSD 大型机: Linux, Unix 嵌入式: VxWorks 移动端: Android, Windows CE  因为Unix商业版权的原因，必须完全符合UNIX标准才能称为UNIX系统，其他的BSD/Linux只能称为UNIX-like。学术上的操作系统和我们日常口中说的操作系统不太一样，我们一般说的windows严格来说属于一个操作系统产品或者说一个操作系统的发行版，它是系统本身和一些软件(浏览器、扫雷)的打包，而学术上的操作系统指的是内核和一些必要的服务。\n现代操作系统的基本功能包括:\n 内存管理(memory management) 进程管理(process management) 中断处理(interrupt handling) 文件系统(file system) 安全机制(protection and security) 进程通信(inter-process communications) 设备驱动(device driver)  内核 微内核就是把最核心、最基础的部分单独作为内核，其他功能围绕它处理。包括地址空间、线程处理、进程通信等。这类东西它们需要以特权模式运行，其他基础服务当做普通应用程序独立运行。\n在内核中运行的程序使用的内存，叫内核空间，也叫内核态。其他程序运行在用户空间，也叫用户态。用户态的代码需要在内核态运行时，并不是直接放在内核态中运行的，这样安全没法保证，首先会做权限检查，通过之后相当于提交了申请，内核运行完成以后返回结果唤醒用户态的程序，这就又涉及到了上下文切换和状态保存。所以用户态和内核态的切换会消耗大量的资源。\n微内核的优点就是内核很小，裁剪起来方便，裁剪不同的基础服务就可以形成不同的版本面向不同的用户，另外就是其中某个服务崩溃的话不会影响到内核，内核可以重启改服务。当然缺点就是由于处于不同的地址空间，基础服务和内核通信时得使用类似于IPC(Inter-Process Communication)的方式通讯，效率相对会差一些。\n微内核的典型代表是学术上的windows和macOS，而不是Linux，早期的Linux为了性能考虑采用了宏内核。\n宏内核也叫单一内核，把核心和基础服务放在一个地址空间内均以特权模式运行，好处就是调用一些基础服务的时候相当于函数调用，不需要通讯，性能很高。缺点就是复杂度和耦合度很高，虽然代码是模块化的，但其中某个模块崩溃都可能导致整个系统崩溃，也不方便裁剪和移植。\n现代的操作系统往往是采用混合内核的，并不是泾渭分明的。\n系统调用 系统调用是内核对外的接口，内核态的一些内核函数。应用程序只要和硬件打交道都会涉及到系统调用，向操作系统申请并等待回复，应该尽量避免或考虑优化，比如有些场景可以使用在用户空间的带buffer的文件替代操作系统提供的文件读写API。\n典型的系统调用汇编代码: global _start section .data hello : db `hello, world!\\n` section .text _start: mov rax, 1 ; system call number should be store in rax  mov rdi, 1 ; argument #1 in rdi: where to write (descriptor)?  mov rsi, hello ; argument #2 in rsi: where does the string start?  mov rdx, 14 ; argument #3 in rdx: how many bytes to write?  syscall ; this instruction invokes a system call  mov rax, 60 ; \u0026#39;exit\u0026#39; syscall number  xor rdi, rdi syscall\n相比于call指令， int属于中断指令，需要栈切换并进行相关检查，开销更大一些。\n进程 基础概念 程序和进程有什么区别？\n某个程序里包含了某个进程所需要的数据，但在某个时间点，进程中的内容未必和程序中的内容是一一对应的。我们开发一个程序，不仅包括可执行的代码，还有周边的素材等等，程序运行的时候，也未必会把全部内容都载入到内存。而进程指的是程序运行时，在内存当中受操作系统管理的部分。程序就像是蓝图，我们可以是照着同一份蓝图启动多个进程。\n进程不是执行单位，而是一个资源边界。相当于在内存这个世界里面，进程圈了一块地，这块地有很多的属性，比如虚拟地址空间、PID等，而地上的工人、流水线才是执行单位，我们称为线程。所以每个进程都有一个主线程。\n 进程是程序的运行期实例(但不同操作系统对进程定义可能不同) 是系统动态执行基本单元 是系统资源分配单位 是线程的容器 是指令、数据及相关资源的集合 是程序运行过程的抽象  状态  ready:除分配CPU外，其他准备就绪(按优先级排队调度) running:占用处理器资源，正在执行 waiting:因IO blocking、sync等原因⽆无法继续执⾏  调度 采用抢占式调度，CPU分配时间片，时间片结束则强制性切换并保存上下文。另外一种调度模式叫协作式调度，一般是在用户空间实现的。\n线程 也称轻量级进程(LWP)，是进程中的实际执行单位，由程序计数器、寄存器、栈内存组成。\n 进程拥有一到多个线程 线程是调度和时间片的分配单位，更多线程理论上会获得更多的CPU资源 线程共享进程的资源 同一程序的多个线程是可以在多核处理器上并行执行来提高执行吞吐率的，这个要看操作系统的调度策略  协程只是在用户空间的线程里实现的一种策略，本身和线程有很大的区别。\n内核线程和用户线程是有区别的，我们一般使用的线程都是被包装过的，很少通过系统调用来使用线程。用户线程可能是系统线程的包装体，它们是一对一关系；也可能是多个用户线程对应一个系统线程，多个用户线程分享一个时间片，这是多对一关系；还有一种可能是多对多关系，类似于Go的机制，某个时刻一个用户线程必然对应一个系统线程，但总体来看用户线程可能比系统线程更多或者更少。\n虚拟存储器 基础概念 操作系统会有一个很大的地址空间，也叫虚拟地址空间。这个空间的前面一大段是操作系统用的，之后的每个进程也都会有一个独立的很大的地址空间。这样不同的程序可以使用相同的虚拟地址，当程序在运行时访问这个地址就是访问进程内的虚拟地址，通过内存管理单元(MMU)翻译映射到一个物理地址。这样的好处就是无论在程序内的地址空间怎么折腾都不会影响到其他的程序，对编译器也更友好更方便，可以提前分配。\n我们在编译时看到的都是虚拟地址，物理地址在运行期才能看到。虚拟地址空间未必会全部映射到主存中，也会给各个设备保留一段空间。\n虚拟存储器可以看成硬盘保存的一个字节数组，虚拟地址空间有256TB，而实际的物理内存可能只有8GB，有这么大的虚拟地址空间就不能阻止程序去使用，不够的物理存储体我们就通过硬盘上的交换分区来弥补。也有可能物理内存加上交换分区都不够程序使用，在Linux中就会引发OOM机制。\n内存分配过程 假设某个程序需要内存分配器分配10MB的内存，那么操作系统会怎么做呢？首先会划分出一个虚拟地址范围，然后返回起始地址的指针。它此时没有必要通过MMU分配真实的物理内存，因为有可能这段内存后续根本没有读写发生。接下来若写入数据，也只会以页(8KB)为单位一点点的去写，每次写入的时候操作系统再去补物理内存，采用一种按需分配的机会主义原则。具体如何实现呢？当向一个虚拟地址写入数据时，就会去MMU找对应的物理地址，没有找到就说明没有建立映射关系还没有分配物理内存，就会引发一个缺页异常(page fault)，操作系统内有专门的程序把这一页补上，来实现按需分配。\n我们通过程序可以模拟这种虚拟内存和物理内存的关系: #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; // gcc -g -O0 -o test test.c // ./test int main() { const size_t length = 1024 * 1024 * 100; const size_t pause = length / 10; unsigned char *p = malloc(length); // 分配100MB内存  unsigned char *x = p; for (int i = 0; i \u0026lt; (int)length; i++) // 循环写入数据  { *x = 1; x++; if (i % (int)pause == 0) // 隔一段时间暂停一下便于观察  { printf(\u0026#34;%d\\n\u0026#34;, i); getchar(); // 可以让用户在命令行中随时控制运行进度  } } free(p); return EXIT_SUCCESS; }\n观察运行结果: [ubuntu] ~/.mac $ pidstat -r -p `pidof test` 1 │Linux 4.9.184-linuxkit (cabd4e519687) 12/06/19 _x86_64_ (2 CPU)│ │11:10:18 UID PID minflt/s majflt/s VSZ RSS %MEM Command │11:10:19 0 180 0.00 0.00 106908 21624 1.06 test │11:10:20 0 180 0.00 0.00 106908 21624 1.06 test │11:10:21 0 180 0.00 0.00 106908 21624 1.06 test │11:10:22 0 180 2560.00 0.00 106908 31920 1.56 test │11:10:23 0 180 0.00 0.00 106908 31920 1.56 test │11:10:24 0 180 2534.65 0.00 106908 42216 2.06 test │11:10:25 0 180 0.00 0.00 106908 42216 2.06 test │11:10:26 0 180 2560.00 0.00 106908 52512 2.57 test │11:10:27 0 180 0.00 0.00 106908 52512 2.57 test │11:10:28 0 180 0.00 0.00 106908 52512 2.57 test │11:10:29 0 180 0.00 0.00 106908 52512 2.57 test │11:10:30 0 180 2560.00 0.00 106908 62544 3.06 test VSZ表示虚拟内存，RSS表示物理内存，可以看到随用户的控制，数据不断写入，物理内存增加。\n换入换出 假设这10MB内存已经分配下来，该程序却长时间不用，操作系统就会把这10MB内存的数据保存到硬盘的交换分区上，并对这些内存页的状态做变更，MMU的映射地址做变更，这些内存就可以去给别的程序用，这就叫换出(swap out)。下次重新激活该程序时，会把硬盘上交换分区的数据重新放回某些空闲的页并重新建立映射，这就是换入(swap in)。我们可以通过监控工具观察到系统内的换入换出情况: [ubuntu] ~ $ dstat You did not select any stats, using -cdngy by default. --total-cpu-usage-- -dsk/total- -net/total- ---paging-- ---system-- usr sys idl wai stl| read writ| recv send| in out | int csw 3 4 77 16 0| 12M 101k| 0 0 | 0 0 |1464 2562 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 175 408 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 148 345 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 143 341 // paging的in和out即为当前换入换出大小,int表示当前有多少中断,csw表示当前有多少上下文切换 当程序运行需要的内存大于机器的物理内存时，就可能造成频繁的换入换出，产生颠簸效应(thrashing)。\n性能相关 如果程序需要性能更高、速度要有保障，就需要向操作系统申请锁死这段内存。同时，缺页异常属于内核级别的，有一定的开销，所以为了追求性能的极致，有的C程序会先进行一个初始化操作，缺页异常仍然会有只是会提前，在执行具体的算法时就会更高效不受缺页异常的影响，而一些高级语言可能会由于编译器的优化使得提前初始化写入被优化忽略掉。\n物理内存分配还采用了写入时复制(copy-on-write)的机制，即A若引用一块内存，那么复制A到B的时候并不会复制这块内存，只有当去写入A或B的时候才会去复制这块内存，起到节约内存的目的。\n对于服务器来讲，假设物理内存有8G，当前运行的程序只有4G，操作系统就会拿另外4G当做自己的cache用，比如缓存文件读写等，程序需要使用时再从cache里还回来。但对于桌面端用户来讲，GUI程序居多，占用内存也多，所以往往会有足够的内存来让用户载入一个程序的速度更快。服务器往往运行的程序数量和时间更长更稳定，所以不同操作系统的分配内存策略也不同。\n某种角度上，假设所有数据都交换到硬盘上，我们可以认为所有的数据保存在硬盘上，内存上只保存活跃数据，内存可以看成是硬盘的缓存或者说L4，虚拟存储器就可以看成硬盘上一个巨大的数组。\n可执行文件 一个可执行程序看上去像是单个文件的数据库，里面分成不同的表。可查看其头部信息: [ubuntu] ~/.mac $ readelf -h test ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 // 一个64位程序 Data: 2\u0026#39;s complement, little endian // 大小端情况 Version: 1 (current) OS/ABI: UNIX - System V // 哪个平台使用 ABI Version: 0 Type: DYN (Shared object file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x610 //入口地址 Start of program headers: 64 (bytes into file) Start of section headers: 8880 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 9 Size of section headers: 64 (bytes) Number of section headers: 34 Section header string table index: 33\n还可以查看其内部的分布情况: [ubuntu] ~/.mac $ readelf -S test There are 34 section headers, starting at offset 0x22b0: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .interp PROGBITS 0000000000000238 00000238 000000000000001c 0000000000000000 A 0 0 1 [ 2] .note.ABI-tag NOTE 0000000000000254 00000254 0000000000000020 0000000000000000 A 0 0 4 [ 3] .note.gnu.build-i NOTE 0000000000000274 00000274 0000000000000024 0000000000000000 A 0 0 4 [ 4] .gnu.hash GNU_HASH 0000000000000298 00000298 000000000000001c 0000000000000000 A 5 0 8 [ 5] .dynsym DYNSYM 00000000000002b8 000002b8 00000000000000f0 0000000000000018 A 6 1 8 [ 6] .dynstr STRTAB 00000000000003a8 000003a8 0000000000000098 0000000000000000 A 0 0 1 [ 7] .gnu.version VERSYM 0000000000000440 00000440 0000000000000014 0000000000000002 A 5 0 2 [ 8] .gnu.version_r VERNEED 0000000000000458 00000458 0000000000000020 0000000000000000 A 6 1 8 [ 9] .rela.dyn RELA 0000000000000478 00000478 00000000000000c0 0000000000000018 A 5 0 8 [10] .rela.plt RELA 0000000000000538 00000538 0000000000000060 0000000000000018 AI 5 22 8 [11] .init PROGBITS 0000000000000598 00000598 0000000000000017 0000000000000000 AX 0 0 4 [12] .plt PROGBITS 00000000000005b0 000005b0 0000000000000050 0000000000000010 AX 0 0 16 [13] .plt.got PROGBITS 0000000000000600 00000600 0000000000000008 0000000000000008 AX 0 0 8 [14] .text PROGBITS 0000000000000610 00000610 0000000000000222 0000000000000000 AX 0 0 16 [15] .fini PROGBITS 0000000000000834 00000834 0000000000000009 0000000000000000 AX 0 0 4 [16] .rodata PROGBITS 0000000000000840 00000840 0000000000000008 0000000000000000 A 0 0 4 [17] .eh_frame_hdr PROGBITS 0000000000000848 00000848 000000000000003c 0000000000000000 A 0 0 4 [18] .eh_frame PROGBITS 0000000000000888 00000888 0000000000000108 0000000000000000 A 0 0 8 [19] .init_array INIT_ARRAY 0000000000200da0 00000da0 0000000000000008 0000000000000008 WA 0 0 8 [20] .fini_array FINI_ARRAY 0000000000200da8 00000da8 0000000000000008 0000000000000008 WA 0 0 8 [21] .dynamic DYNAMIC 0000000000200db0 00000db0 00000000000001f0 0000000000000010 WA 6 0 8 [22] .got PROGBITS 0000000000200fa0 00000fa0 0000000000000060 0000000000000008 WA 0 0 8 [23] .data PROGBITS 0000000000201000 00001000 0000000000000010 0000000000000000 WA 0 0 8 [24] .bss NOBITS 0000000000201010 00001010 0000000000000008 0000000000000000 WA 0 0 1 [25] .comment PROGBITS 0000000000000000 00001010 000000000000002b 0000000000000001 MS 0 0 1 [26] .debug_aranges PROGBITS 0000000000000000 0000103b 0000000000000030 0000000000000000 0 0 1 [27] .debug_info PROGBITS 0000000000000000 0000106b 000000000000038d 0000000000000000 0 0 1 [28] .debug_abbrev PROGBITS 0000000000000000 000013f8 0000000000000109 0000000000000000 0 0 1 [29] .debug_line PROGBITS 0000000000000000 00001501 00000000000000ee 0000000000000000 0 0 1 [30] .debug_str PROGBITS 0000000000000000 000015ef 0000000000000295 0000000000000001 MS 0 0 1 [31] .symtab SYMTAB 0000000000000000 00001888 00000000000006a8 0000000000000018 32 48 8 [32] .strtab STRTAB 0000000000000000 00001f30 000000000000023f 0000000000000000 0 0 1 [33] .shstrtab STRTAB 0000000000000000 0000216f 000000000000013e 0000000000000000 0 0 1 可以看出该文件有34个表，每个表有自己的名字、起始和终止的虚拟地址、长度信息、权限信息等。\n它等于是一个蓝图，执行时按这个蓝图虚拟存储器去规划并映射它的地址空间。\n" }); index.add({ 'id': 2, 'href': '/docs/go/lock/', 'title': "Lock", 'content': " 锁的原理 锁是怎么实现的？怎么做到独占的？实际上得从原子操作说起。\n原子操作 原子操作不是说一定要只能一个动作，而是说把它包装成一条指令或者一个函数的时候，它可以保证不会被侵入。在单核CPU上，一条指令肯定是原子的，但不见得一条指令就只做了一个操作，可能是两个操作，比如CAS(Compare\u0026amp;Set或Compare\u0026amp;Swap，X86下对应的是CMPXCHG汇编指令)是比较并交换操作数，这在单核上没有问题，但在多核上如何保证不被打断呢？这就需要硬件来支持了。\n我们在intel IA-64手册中，可以翻到这样一条指令前缀: 按文档描述，把这条前缀加到某些指令前时，它可以实现一个原子操作。在x86体系中，CPU里专门有一条引线叫HLOCK pin，当遇到有LOCK前缀的指令就拉低该引线电位，从而锁住了总线。那么在同一总线上的其他Core就无法通过总线访问内存了。所以原子操作的本质仍然是锁，只是这个锁是硬件层面的。也不存在软件层面上真正意义的无锁操作，底层仍然是锁。\n我们在Go的源码中也能看到大量这样的代码:\n// src/runtime/internal/atomic/asm_amd64.s TEXT runtime∕internal∕atomic·Cas(SB),NOSPLIT,$0-17 MOVQ\tptr+0(FP), BX MOVL\told+8(FP), AX MOVL\tnew+12(FP), CX LOCK CMPXCHGL\tCX, 0(BX) SETEQ\tret+16(FP) RET 随着现在CPU核数逐步增多，这种LOCK前缀锁总线的方式带来的性能问题就凸显了出来，所以现在的体系遇到LOCK前缀时，不是去锁整个总线，而是先检查一下要锁的内容是不是在cache中，如果在的话只锁那一行cacheline，只有同时访问这一个cacheline的其他core才会被锁住，就像数据库的表锁和行锁。这样一来，性能的影响没那么大了，但是原子操作还是会带来性能影响的，只是硬件层面的东西我们作为程序员改变不了什么也就很少去提。\n那么原子操作和我们平时所说的互斥锁有什么区别呢？我们谈原子操作是只针对一个操作，而锁是往往是要包含一段逻辑、一个block的。\n无锁结构 也就是Lock Free，它的做法用伪码来表达是这样的:\nfor { old = atomic.Load() if (atomic.CAS(old, new)){ break } } // CAS 伪码 func compareAndSwap(addr int, old int, new int) bool{ if (*addr != old){ return False } *addr = new return True }  当old通过原子操作读出以后，如果有其他CPU操作修改了这个值，那么atomic.CAS就会发现old变了则修改失败重新循环，反之修改成功退出循环，这就是无锁结构。运气好的话一次就执行完了，运气不好一直被打断的话循环多少次是未知的。它的实际使用场景比如说是一个无锁结构的链表队列，当需要向队列尾部插入元素时，插入不成功则说明有其他线程刚刚插入过，队列尾部的地址已经变了，则需重试。\n这种结构也有个问题，就是ABA的问题。试想一下atomic.Load读出来是A，然后被人修改为了B再修改回A，atomic.CAS就发现不了接着执行自己的逻辑。这样粗看好像也没有什么问题，但CAS只是检查的一个地址，实际情况往往会有其他的逻辑，有人做了一个比喻:你拿着一个装满钱的手提箱在飞机场，此时过来了一个火辣性感的美女，然后她很暖昧地挑逗着你，并趁你不注意的时候，把用一个一模一样的手提箱和你那装满钱的箱子调了个包，然后就离开了，你看到你的手提箱还在那，于是就提着手提箱去赶飞机去了。\n怎么解决ABA的问题呢？可以采用数据库乐观锁的办法，每次进行修改的时候添加一个时间戳或者流水号，上例就是atomic.Load读出来以后就是A20191222，修改为B就变为了B20191223，再进行一次修改就是A20191224了。\n缓存一致性 CPU是不会和内存直接交互的，它和内存之间的读写都是通过L1、L2、L3缓存来做中转。那么如果内存上有个X=1，CPU1和CPU2都把这个X读到自己的缓存上，CPU1这时候对X做了修改让X=3，CPU2又如何知道呢？这就是缓存一致性的问题，需要确保的是任一时刻，缓存的内容是相同的。\n缓存是以行为单位的，也就是cacheline，每行中除了缓存的数据外还包括内存地址和状态。而状态又分为四种，即M、E、S、I。M即modify，表示当前CPU修改过数据，需要以此为准回写到主存中去；E即exclusive，独占，当前的CPU独占了这个数据，和主存中是一致的，其他CPU没有的；S即shared，共享，各个CPU都有这行数据，且是和主存一致的；I即invalid，表示失效的，CPU发现是这个状态就意味着需要从主存里重新去拿一下。\n当CPU2要去写某一行数据的时候，它就会向总线发出一个请求: CPU2要独占某一段地址。CPU1、CPU3、CPU4一直都在嗅探总线去接收总线的通知，然后去检查自己的缓存中有没有这行数据，如果CPU3有且这行状态是共享的，那就把CPU3的这行变为失效状态；但如果CPU1那行已经是独占的，这个CPU2就得等，等到CPU1修改完数据回写到主存当中会解除CPU1的独占状态，CPU2重新从主存刷新自己的缓存再把它修改为独占状态。修改了数据就需要改为modify，因为需要一批数据一同刷入主存。\n这种通过四种状态保证缓存一致性的方式和我们日常见到的锁的原理差不多，数据库修改某行的时候也是加行锁，其他人要修改该行就得排队，要修改其他行就不受影响。\nGo语言中的锁 Futex 锁的本质是通过某种操作实现休眠、唤醒等操作，那它就一定要由操作系统来实现，由OS实现才能避免对于休眠的单位不去分配时间片。那么锁就需要进行系统调用，它的效率就会非常低？Linux在很早期的版本就提供了一种锁Futex，虽然是由操作系统提供的，但它是在用户空间实现的，是一种特殊的系统调用，大部分情况下不需要进入内核空间，避免了通常的系统调用所需的用户态内核态之间的切换。Futex其实就是一块内存空间，通常是一个整型变量，大家通过原子操作对它做修改，要么就修改成功执行逻辑，要么就修改失败等待它。\nLinux手册中提供了这种锁的调用方式，包括锁定、等待、唤醒等参数。Go中调用其API:\n// src/runtime/os_linux.go  func futex(addr unsafe.Pointer, op int32, val uint32, ts, addr2 unsafe.Pointer, val3 uint32) int32 // Linux futex. // //\tfutexsleep(uint32 *addr, uint32 val) //\tfutexwakeup(uint32 *addr) // // Futexsleep atomically checks if *addr == val and if so, sleeps on addr. // Futexwakeup wakes up threads sleeping on addr. // Futexsleep is allowed to wake up spuriously.  func futexsleep(addr *uint32, val uint32, ns int64) { if ns \u0026lt; 0 { futex(unsafe.Pointer(addr), _FUTEX_WAIT_PRIVATE, val, nil, nil, 0) return } var ts timespec ts.setNsec(ns) futex(unsafe.Pointer(addr), _FUTEX_WAIT_PRIVATE, val, unsafe.Pointer(\u0026amp;ts), nil, 0) } func futexwakeup(addr *uint32, cnt uint32) { ret := futex(unsafe.Pointer(addr), _FUTEX_WAKE_PRIVATE, cnt, nil, nil, 0) if ret \u0026gt;= 0 { return } systemstack(func() { print(\u0026#34;futexwakeup addr=\u0026#34;, addr, \u0026#34; returned \u0026#34;, ret, \u0026#34;\\n\u0026#34;) }) *(*int32)(unsafe.Pointer(uintptr(0x1006))) = 0x1006 } 有了API，并不能直接用，还要对其进行包装:\n// src/runtime/lock_futex.go  func lock(l *mutex) { gp := getg() if gp.m.locks \u0026lt; 0 { throw(\u0026#34;runtime·lock: lock count\u0026#34;) } gp.m.locks++ // 尝试原子操作修改l.key的值为锁定状态 \tv := atomic.Xchg(key32(\u0026amp;l.key), mutex_locked) if v == mutex_unlocked { return } // 尝试失败则进入自旋状态 \twait := v spin := 0 if ncpu \u0026gt; 1 { spin = active_spin } for { // 每自旋一次尝试拿一次锁 \tfor i := 0; i \u0026lt; spin; i++ { for l.key == mutex_unlocked { if atomic.Cas(key32(\u0026amp;l.key), mutex_unlocked, wait) { return } } procyield(active_spin_cnt) } // 在rescheduling状态进行尝试拿锁 \tfor i := 0; i \u0026lt; passive_spin; i++ { for l.key == mutex_unlocked { if atomic.Cas(key32(\u0026amp;l.key), mutex_unlocked, wait) { return } } osyield() } // 尝试进入睡眠状态 \tv = atomic.Xchg(key32(\u0026amp;l.key), mutex_sleeping) if v == mutex_unlocked { return } // 进入futex睡眠状态 \twait = mutex_sleeping futexsleep(key32(\u0026amp;l.key), mutex_sleeping, -1) } } func unlock(l *mutex) { v := atomic.Xchg(key32(\u0026amp;l.key), mutex_unlocked) if v == mutex_unlocked { throw(\u0026#34;unlock of unlocked lock\u0026#34;) } // futex唤醒操作 \tif v == mutex_sleeping { futexwakeup(key32(\u0026amp;l.key), 1) } gp := getg() gp.m.locks-- if gp.m.locks \u0026lt; 0 { throw(\u0026#34;runtime·unlock: lock count\u0026#34;) } if gp.m.locks == 0 \u0026amp;\u0026amp; gp.preempt { gp.stackguard0 = stackPreempt } } 其一开始尝试拿锁属于投机，先以最乐观的情况考虑，如果没人竞争就能直接拿到锁，这种概率并不低，我们自己做性能设计时也可以参考它先设计乐观的情况。尝试失败则进入自旋状态，自旋状态打个比方，就是你在火车上上厕所，发现厕所有人，你在外面焦急的转圈等待；它是次一级的理想状态，因为厕所的人出来你马上就能进去，若是回到座位上可能被人插队；procyield(active_spin_cnt)背后会调用一个专门的CPU指令PAUSE，它可以降低自旋状态时CPU的功耗并进入一个短暂的等待。自旋时没拿到锁则进入另一个状态，相当于回到座位上但是盯着厕所的门，这个状态下执行的osyield()是操作系统提供的等待，这种等待的时长就比CPU指令长很多，同时涉及到状态切换开销也会大很多。这种积极的尝试如果仍然失败，则进入睡眠状态，等待厕所里面的人出来唤醒它，唤醒后重新进入这个循环。\n尽管做了这样的包装，这种锁仍然属于较低层次的，一般不会给用户直接用。\nSema 信号量，可以控制同时执行的数量，如果数量是1就相当于互斥锁，如果都在执行了再进来人就得排队。\n首先，它的结构是这样的: // src/runtime/sema.go type semaRoot struct { lock mutex treap *sudog // root of balanced tree of unique waiters. \tnwait uint32 // Number of waiters. Read w/o the lock. }\nlock 就是之前设计的那种锁，在这之上提供了一个treap这样的平衡树结构，它是等待人(G对象)的列表，还有nwait计数器存储等待人的数量。\n它的核心获取锁的逻辑: func semacquire1(addr *uint32, lifo bool, profile semaProfileFlags, skipframes int) { //简单的情况，即直接成功获取锁 \tif cansemacquire(addr) { return } ... // 复杂的情况:  // 1.增加等待者计数；  // 2.再尝试一次获取锁，成功则返回；  // 3.将自己enqueue waiter；  // 4.睡眠 \tfor { lock(\u0026amp;root.lock) atomic.Xadd(\u0026amp;root.nwait, 1) if cansemacquire(addr) { atomic.Xadd(\u0026amp;root.nwait, -1) unlock(\u0026amp;root.lock) break } root.queue(addr, s, lifo) goparkunlock(\u0026amp;root.lock, waitReasonSemacquire, traceEvGoBlockSync, 4+skipframes) if s.ticket != 0 || cansemacquire(addr) { break } } if s.releasetime \u0026gt; 0 { blockevent(s.releasetime-t0, 3+skipframes) } releaseSudog(s) } func cansemacquire(addr *uint32) bool { for { v := atomic.Load(addr) if v == 0 { return false } if atomic.Cas(addr, v, v-1) { return true } } } 首先尝试去锁定，并给等待者的数量加上1，然后通过cansemacquire检查一下能不能获得这把锁，能获得则减1退出循环。不能获得则加入到队列中，goparkunlock休眠。信号量归根结底是用原子操作来维护某个地址上的信号量加减，用一个锁来维护一个等待者计数器，这里的\u0026amp;root.lock是为了保护对计数器的操作和入队的操作。\n接着我们看看释放: func semrelease1(addr *uint32, handoff bool, skipframes int) { root := semroot(addr) atomic.Xadd(addr, 1) // 简单的情况：没有等待者 \tif atomic.Load(\u0026amp;root.nwait) == 0 { return } // 复杂的情况：找到一个等待者并唤醒它 \tlock(\u0026amp;root.lock) if atomic.Load(\u0026amp;root.nwait) == 0 { unlock(\u0026amp;root.lock) return } s, t0 := root.dequeue(addr) if s != nil { atomic.Xadd(\u0026amp;root.nwait, -1) } unlock(\u0026amp;root.lock) if s != nil { // May be slow or even yield, so unlock first \tacquiretime := s.acquiretime if acquiretime != 0 { mutexevent(t0-acquiretime, 3+skipframes) } if s.ticket != 0 { throw(\u0026#34;corrupted semaphore ticket\u0026#34;) } if handoff \u0026amp;\u0026amp; cansemacquire(addr) { s.ticket = 1 } readyWithTime(s, 5+skipframes) if s.ticket == 1 \u0026amp;\u0026amp; getg().m.locks == 0 { goyield() } } }\n首先，释放必然使地址上的信号量加1。其次，去查看是否有人等，没人等则直接退出；如果有人等，则从队列中dequeue一个等待者、计数器减一，等待者可能是按地址排序的，但这属于其内部实现，我们没法确定弹出的是谁。最后如果传入的handoff为true表示要进行权限转移，会给这个弹出的等待者发一张票，之前semacquire1的for循环中goparkunlock休眠后被唤醒的第一件事就是检查有没有拿到票，拿到了则可以短路出去，没必要再走一次for循环和别人竞争抢锁\u0026amp;root.lock。\n信号量结合了它的特征，在一些短路的设计上值得我们学习。它仍然是runtime层面的，还不是交给用户去使用的。\nMutex 给用户使用的锁在标准库中，我们来看看它的实现: // src/sync/mutex.go type Mutex struct { state int32 sema uint32 } const ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked \tmutexWoken mutexStarving mutexWaiterShift = iota )\nMutex结构包括一个状态和一个计数，这个状态分为四种，即锁定、唤醒(这里可以理解为自旋)、饥饿、等待者转移。怎样会出现饥饿状态呢？比如A、B竞争一把锁的时候，A拿到了，B经过不断尝试最终进入了睡眠状态，A释放锁的时候又有C去竞争锁，C此时可能处于自旋状态，同理C后面可能还有D、E，B就一直拿不到锁处于饥饿状态。这种状态在并发编程中并不少见。\n接着我们看看其锁定的过程: func (m *Mutex) Lock() { // 进入快速路径，乐观状态，没有竞争 \tif atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // 进入慢速方式 \tm.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 starving := false awoke := false iter := 0 old := m.state for { // 依然通过循环处理  // 判断没有人处于饥饿状态，且还有可自旋次数，则进入自旋状态去尝试拿这把锁 \tif old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) { if !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state // 拿到锁则是mutexLocked状态，接着向下走；没拿到重新看可自旋次数。 \tcontinue } // 从这开始就有两种可能，要么拿到锁了，要么自旋次数用完了 \tnew := old // 接着主要做一些状态变更和处理 \tif old\u0026amp;mutexStarving == 0 { new |= mutexLocked } if old\u0026amp;(mutexLocked|mutexStarving) != 0 { new += 1 \u0026lt;\u0026lt; mutexWaiterShift } if starving \u0026amp;\u0026amp; old\u0026amp;mutexLocked != 0 { new |= mutexStarving } if awoke { if new\u0026amp;mutexWoken == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } new \u0026amp;^= mutexWoken } if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { // 没人上锁且没有饥饿状态的，则可以拿到锁跳出整个循环 \tif old\u0026amp;(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS \t} // 如果我之前已经在等待了，则排在队列的最前面 \tqueueLifo := waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } runtime_SemacquireMutex(\u0026amp;m.sema, queueLifo, 1) // 判断时间是不是超出了饥饿状态的时间阈值 \tstarving = starving || runtime_nanotime()-waitStartTime \u0026gt; starvationThresholdNs old = m.state // 如果我自己就是饥饿的，那么我拿到锁，做相关状态修改，退出循环 \tif old\u0026amp;mutexStarving != 0 { if old\u0026amp;(mutexLocked|mutexWoken) != 0 || old\u0026gt;\u0026gt;mutexWaiterShift == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } delta := int32(mutexLocked - 1\u0026lt;\u0026lt;mutexWaiterShift) if !starving || old\u0026gt;\u0026gt;mutexWaiterShift == 1 { delta -= mutexStarving } atomic.AddInt32(\u0026amp;m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } if race.Enabled { race.Acquire(unsafe.Pointer(m)) } }\n总结 我们从原子操作到Mutex，经历了四个层次的包装，每层包装面向不同的目的去解决不同的问题。在做发动机的时候，我们考虑的是动力、性能、省油，但拿它做飞机引擎还是做汽车引擎就要做不同的包装。我们平时做设计的时候往往也需要层进式的考虑问题，不要总是想着一步到位。\n" }); index.add({ 'id': 3, 'href': '/docs/other/tools/', 'title': "Tools", 'content': " 常用工具整理 体检工具 生产环境不同于开发环境，生产环境往往是一个很干净的、只保留了相关依赖的环境，而且需要运行很长的时间。而开发环境属于实验室性质的，类库比较齐全，只跑个单元测试或者benchmark之类的，运行时间很短。所以开发环境中很小的问题比如内存泄漏几KB，在生产环境随着时间的累积或者成千上万的访问，可能会把垃圾回收器搞崩溃。这种情况如果我们不擅于使用工具可能找不到任何问题。\n另外，开发环境我们可以使用100%的资源，但生产环境一定要预留一些资源用来做调度、预警之类的。\ndstat 它能实时查看一些基本信息，默认情况下它会包括:\n CPU基本信息(用户使用时间、系统使用时间、空闲时间等) 磁盘基本信息(读、写) 网络基本信息(接受、发送) 换入换出信息 系统基本信息(中断的次数、上下文切换的次数)  如下所示: [ubuntu] ~/.mac $ dstat You did not select any stats, using -cdngy by default. --total-cpu-usage-- -dsk/total- -net/total- ---paging-- ---system-- usr sys idl wai stl| read writ| recv send| in out | int csw 0 0 100 0 0|2797B 597B| 0 0 | 0 0 | 90 236 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 140 323 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 163 376 0 1 100 0 0| 0 0 | 0 0 | 0 0 | 169 391\n生产环境下我们程序出错的时候，应该先从大的方面入手定位到具体是哪个方面的问题，看看当前的系统环境有没有问题，是不是我们的程序在当前的系统环境下水土不服。比如程序是IO密集型的，系统中有另一个程序在和它抢磁盘资源等。可以通过dstat --list查看它能对哪些细分项目查看其情况。查看更多使用示例\nsysstat 通过定位了系统中哪个方面的问题之后，接着我们应该去定位我们自己程序哪个方面有问题。sysstat可以根据单个进程去检查它的各个方面，比如说我们定位到是内存方面的问题，接着去看自己程序中内存的问题: [ubuntu] ~/.mac $ pidstat -r -p `pidof tmux` 2 Linux 4.9.184-linuxkit (cabd4e519687) 12/09/19 _x86_64_\t(2 CPU) 10:02:38 UID PID minflt/s majflt/s VSZ RSS %MEM Command 10:02:40 0 35 0.00 0.00 27424 4000 0.20 tmux: server 10:02:42 0 35 0.00 0.00 27424 4000 0.20 tmux: server 10:02:44 0 35 0.00 0.00 27424 4000 0.20 tmux: server 10:02:46 0 35 0.00 0.00 27424 4000 0.20 tmux: server 我们把tmux当做是自己写的某个程序，每2秒输出一次信息。minflt/s就代表一些小范围的缺页异常，可能是一些数据不需要了只要补上相应的物理内存即可。而majflt/s代表了需要从硬盘换入内存，这可能就意味着我们程序是不是有的任务优先级太低被操作系统换出到硬盘上了，我们可能需要通过系统调用告诉操作系统把某段内存锁死。\n更详细的使用方法，请参考官方文档。\nstrace 接着我们可以深入到自己程序的逻辑中去，比如使用strace检查我们程序的系统调用。可能只是一个简单的程序: package main func main() { println(\u0026#34;hello world!\u0026#34;) }\n却涉及到大量的系统调用: [ubuntu] ~/.mac $ go build test.go [ubuntu] ~/.mac $ strace ~/.mac/test execve(\u0026#34;/root/.mac/test\u0026#34;, [\u0026#34;/root/.mac/test\u0026#34;], 0x7ffec1a0b740 /* 14 vars */) = 0 arch_prctl(ARCH_SET_FS, 0x4c5650) = 0 sched_getaffinity(0, 8192, [0, 1]) = 16 openat(AT_FDCWD, \u0026#34;/sys/kernel/mm/transparent_hugepage/hpage_pmd_size\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) mmap(NULL, 262144, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd246a01000 mmap(0xc000000000, 67108864, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xc000000000 mmap(0xc000000000, 67108864, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0xc000000000 mmap(NULL, 33554432, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd244a01000 mmap(NULL, 2164736, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd2447f0000 mmap(NULL, 65536, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd2447e0000 mmap(NULL, 65536, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd2447d0000 rt_sigprocmask(SIG_SETMASK, NULL, [], 8) = 0 sigaltstack(NULL, {ss_sp=NULL, ss_flags=SS_DISABLE, ss_size=0}) = 0 sigaltstack({ss_sp=0xc000002000, ss_flags=0, ss_size=32768}, NULL) = 0 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0 gettid() = 394 rt_sigaction(SIGHUP, NULL, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, 8) = 0 rt_sigaction(SIGHUP, {sa_handler=0x44d8f0, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x44da20}, NULL, 8) = 0 rt_sigaction(SIGINT, NULL, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, 8) = 0 rt_sigaction(SIGINT, {sa_handler=0x44d8f0, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x44da20}, NULL, 8) = 0 ......\n打印输入输出必然会涉及系统调用，但如果我们使用一些第三方库时发现系统调用仍然很多，就可以去查找有没有优化替代的方案。\n一般，我们查看一些摘要信息即可: [ubuntu] ~/.mac $ strace -c ~/.mac/test hello world! % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 0.00 0.000000 0 1 write 0.00 0.000000 0 7 mmap 0.00 0.000000 0 114 rt_sigaction 0.00 0.000000 0 6 rt_sigprocmask 0.00 0.000000 0 2 clone 0.00 0.000000 0 1 execve 0.00 0.000000 0 2 sigaltstack 0.00 0.000000 0 1 arch_prctl 0.00 0.000000 0 1 gettid 0.00 0.000000 0 3 futex 0.00 0.000000 0 1 sched_getaffinity 0.00 0.000000 0 1 1 openat ------ ----------- ----------- --------- --------- ---------------- 100.00 0.000000 140 1 total\n开发工具 GNU通用的开发工具，也叫binutils，是一个标准，属于随身带的瑞士军刀，任何语言编写的程序都适用，但可能与语言自带的工具链细节上有些出入。官方网站\n它主要包括:\n readelf : 查看ELF文件信息。 objdump : 查看⽬标文件 (ELF/COFF) 信息。 addr2line : 将地址转换为文件行号信息。 nm : 查看符号表。 strip : 删除符号表。 objcopy : 拷⻉数据到⽬标⽂文件。 strings : 输出字符串。 size : 查看各段⼤小。  当我们不熟悉一门语言写的程序时，我们可以把它翻译成汇编语言，在把汇编语言翻译成C语言，也许这个C语言无法运行，但方便了我们阅读和理解程序的思路。\n调试工具 GNU通用的调试工具，也叫gdb。binutils属于静态的观察，而gdb就可以动态的观察到每一个汇编指令的执行。官方网站\n也可以使用一些带图形界面的类似工具，例如gdbgui。还有些cheatsheet很好用。\n构建工具 GNU的自动构建工具为make，有些像脚本语言，把一堆命令放一起批量执行。使用它做编译属于增量编译，即通过对比修改时间来判断是否需要重新执行。官方网站\nhello: hello.s nasm -g -f elf64 -o hello.o hello.s ld -o $@ hello.o clean: -rm *.o -rm hello .PHONY: clean  对于这段构建代码，hello:后的部分就是告诉它要去检查哪些文件的修改时间；$@就表示当前这段的目标hello，$\u0026lt;表示这段的第一个依赖项，$^表示这段的所有依赖项；命令前加-表示该命令如有错误则忽略；PHONY表示没有目标，没有依赖，总是执行规则，在该例中，若恰好文件夹内有一个名为clean的文件，没有PHONY时则make clean不会执行；另外，由于历史原因makefile只能使用tab来缩进，不能使用空格。\n" }); index.add({ 'id': 4, 'href': '/categories/', 'title': "Categories", 'content': "" }); index.add({ 'id': 5, 'href': '/docs/go/defer/', 'title': "defer实现方式", 'content': " Defer延迟调用 defer是GO语言中独有的特性，在其他语言中可能采用try...finally这样的方式来实现，两者还是有很大区别的。finally是立即执行的，而defer会延迟执行，且defer可以分割很多的逻辑。延迟调用最大的优势是即便函数执行出错，依然能保证回收资源等操作得以执行。\n我们看到很多的文章中是这样描述defer执行方式的，参数首先会被复制进defer func中，然后执行原函数，然后执行defer func，最后再执行return。那么真的是这样么？这似乎解释不了如下示例: func test1() int { x := 100 defer func() { x++ }() return x } func test2() (x int) { x = 100 defer func() { x++ }() return 100 } func main() { println(\u0026#34;test1:\u0026#34;, test1()) println(\u0026#34;test2:\u0026#34;, test2()) } [ubuntu] ~/.mac $ go run test.go test1: 100 test2: 101\n按照这个观点，似乎test1()的执行过程应该是x等于100，然后x++，然后返回x=101；test2()应该是x等于100，然后x++，然后返回100。但执行结果却都和我们预想的不一样，带着这样的疑问，我们来深入了解defer的执行机制。\n我们先来看一个简单的例子: func test(a, b int) { println(\u0026#34;test: \u0026#34;, a, b) } func main() { a, b := 0x11, 0x22 defer test(a, b) a++ b++ println(\u0026#34;main: \u0026#34;, a, b) }\n然后反汇编看看它的执行过程: [ubuntu] ~/.mac $ go build test.go [ubuntu] ~/.mac $ go tool objdump -s \u0026#34;main\\.main\u0026#34; test TEXT main.main(SB) /root/.mac/test.go test.go:6\t0x4523b0\t64488b0c25f8ffffff\tMOVQ FS:0xfffffff8, CX test.go:6\t0x4523b9\t483b6110\tCMPQ 0x10(CX), SP test.go:6\t0x4523bd\t0f86ad000000\tJBE 0x452470 test.go:6\t0x4523c3\t4883ec58\tSUBQ $0x58, SP test.go:6\t0x4523c7\t48896c2450\tMOVQ BP, 0x50(SP) test.go:6\t0x4523cc\t488d6c2450\tLEAQ 0x50(SP), BP test.go:8\t0x4523d1\tc744241010000000\tMOVL $0x10, 0x10(SP) test.go:8\t0x4523d9\t488d05705a0200\tLEAQ 0x25a70(IP), AX test.go:8\t0x4523e0\t4889442428\tMOVQ AX, 0x28(SP) test.go:8\t0x4523e5\t48c744244011000000\tMOVQ $0x11, 0x40(SP) test.go:8\t0x4523ee\t48c744244822000000\tMOVQ $0x22, 0x48(SP) test.go:8\t0x4523f7\t488d442410\tLEAQ 0x10(SP), AX test.go:8\t0x4523fc\t48890424\tMOVQ AX, 0(SP) test.go:8\t0x452400\te87b16fdff\tCALL runtime.deferprocStack(SB)  test.go:8\t0x452405\t85c0\tTESTL AX, AX test.go:8\t0x452407\t7557\tJNE 0x452460 test.go:11\t0x452409\te8a230fdff\tCALL runtime.printlock(SB) test.go:11\t0x45240e\t488d0583130200\tLEAQ 0x21383(IP), AX test.go:11\t0x452415\t48890424\tMOVQ AX, 0(SP) test.go:11\t0x452419\t48c744240807000000\tMOVQ $0x7, 0x8(SP) test.go:11\t0x452422\te8c939fdff\tCALL runtime.printstring(SB) test.go:11\t0x452427\t48c7042412000000\tMOVQ $0x12, 0(SP) test.go:11\t0x45242f\te8fc37fdff\tCALL runtime.printint(SB) test.go:11\t0x452434\te8b732fdff\tCALL runtime.printsp(SB) test.go:11\t0x452439\t48c7042423000000\tMOVQ $0x23, 0(SP) test.go:11\t0x452441\te8ea37fdff\tCALL runtime.printint(SB) test.go:11\t0x452446\te8f532fdff\tCALL runtime.printnl(SB) test.go:11\t0x45244b\te8e030fdff\tCALL runtime.printunlock(SB) test.go:12\t0x452450\t90\tNOPL test.go:12\t0x452451\te82a1cfdff\tCALL runtime.deferreturn(SB)  test.go:12\t0x452456\t488b6c2450\tMOVQ 0x50(SP), BP test.go:12\t0x45245b\t4883c458\tADDQ $0x58, SP test.go:12\t0x45245f\tc3\tRET test.go:8\t0x452460\t90\tNOPL test.go:8\t0x452461\te81a1cfdff\tCALL runtime.deferreturn(SB)  test.go:8\t0x452466\t488b6c2450\tMOVQ 0x50(SP), BP test.go:8\t0x45246b\t4883c458\tADDQ $0x58, SP test.go:8\t0x45246f\tc3\tRET test.go:6\t0x452470\te82b7affff\tCALL runtime.morestack_noctxt(SB) test.go:6\t0x452475\te936ffffff\tJMP main.main(SB)\n我们发现defer test(a, b)实际上会被转化为CALL runtime.deferproc(SB)(Go1.13才使用deferprocStack，这里先以deferproc为例)，之后进行的a++已经不会影响到它，而在main函数执行完之后，才会去通过CALL runtime.deferreturn(SB)调用它。\n我们再来看看runtime.deferproc干了些什么，我在这里也把源码中重要的注释翻译了过来:\n// go/src/runtime/panic.go // siz表示fn方法中参数需要占用多少个字节，使用siz创建了一个deferred的方法fn // 编译器将一个defer语句转化为一个对此方法的调用 func deferproc(siz int32, fn *funcval) { // fn之后紧跟着fn的参数 \tif getg().m.curg != getg() { throw(\u0026#34;defer on system stack\u0026#34;) } //fn的参数处于一个危险的状态，deferproc的stack map并没有复制它们。所以我们不能让垃圾回收器或者栈复制触发，直到我们把这些参数复制到一个安全的地方。下面的内存复制会做到这一点。在复制完成前，我们只能调用nosplit routines。 \tsp := getcallersp() argp := uintptr(unsafe.Pointer(\u0026amp;fn)) + unsafe.Sizeof(fn) callerpc := getcallerpc() d := newdefer(siz) \tif d._panic != nil { throw(\u0026#34;deferproc: d.panic != nil after newdefer\u0026#34;) } d.fn = fn d.pc = callerpc d.sp = sp \tswitch siz { case 0: // Do nothing. \tcase sys.PtrSize: *(*uintptr)(deferArgs(d)) = *(*uintptr)(unsafe.Pointer(argp)) default: memmove(deferArgs(d), unsafe.Pointer(argp), uintptr(siz)) } return0() } 我们发现newdefer函数返回的是一个这样的结构体: // go/src/runtime/runtime2.go type _defer struct { siz int32 // includes both arguments and results \tstarted bool heap bool openDefer bool sp uintptr // sp at time of defer \tpc uintptr // pc at time of defer \tfn *funcval // can be nil for open-coded defers \t_panic *_panic // panic that is running defer \tlink *_defer fd unsafe.Pointer // funcdata for the function associated with the frame \tvarp uintptr // value of varp for the stack frame  framepc uintptr }\n鉴于篇幅，我删除了其注释，但可根据这些注释得出结论，defer func()这个语句会被保存在当前Goroutine中，把它的参数、所需要的栈大小等保存为一个_defer对象，把多个_defer形成一个链表，也就是一个FILO的队列。\n但是Goroutine和函数执行没什么直接的关系，如果是A嵌套B，B嵌套C，A、B、C都有各自的defer语句，那么它们都会被保存在这个Goroutine的_defer链表中，它怎么保证执行C的时候不把B的defer执行掉，这个秘密藏在CALL runtime.deferreturn(SB)中:\nfunc deferreturn(arg0 uintptr) { gp := getg() d := gp._defer if d == nil { return } sp := getcallersp() if d.sp != sp { \treturn } if d.openDefer { done := runOpenDeferFrame(gp, d) if !done { throw(\u0026#34;unfinished open-coded defers in deferreturn\u0026#34;) } gp._defer = d.link freedefer(d) return } switch d.siz { case 0: // Do nothing. \tcase sys.PtrSize: *(*uintptr)(unsafe.Pointer(\u0026amp;arg0)) = *(*uintptr)(deferArgs(d)) default: memmove(unsafe.Pointer(\u0026amp;arg0), deferArgs(d), uintptr(d.siz)) } fn := d.fn d.fn = nil gp._defer = d.link freedefer(d) jmpdefer(fn, uintptr(unsafe.Pointer(\u0026amp;arg0))) } 函数执行调用这个指令的时候，它先拿到当前Goroutine的_defer链表，然后依次检查它的SP就行了，这个SP是执行deferproc时存进去的当前这个函数的栈顶，只要不一致那肯定是父函数的栈了。\n回到最初的问题，我们发现反编译之后，函数的整个执行顺序是这样的，函数调用方已经分配好了被调用方的参数和返回值相对于栈顶的地址，然后执行函数，遇到defer语句时先存在Goroutine的_defer链表中接着执行函数，执行完函数后回过头来执行_defer的func，最后调用RET指令并恢复现场。套用到test1()中，就是先定义了返回值(return_val)是个整数并给它了个地址，然后执行x:=100，然后return x被翻译为了return_val=x，然后执行x++，最后调用RET指令。在test2()中，return_val直接叫x，然后给它赋值100，return 100已经没有意义，然后执行return_val_x++，最后调用RET指令。\n整个defer的执行核心过程如下图所示: 此外，我们在挖掘源码的时候发现defer是有很多堆上内存分配行为的，这会影响性能。在Go1.13中编译器会判断如果没有发生内存逃逸，就调用deferprocStack把_defer对象建在栈上，这个对象的heap属性就是描述它是否在堆上分配的。具体是如何判断的，初步了解是defer func是顶级函数时就分配到栈上，如果它外层有迭代循环之类的将会被分配到堆上，之后再详细了解。\n" }); index.add({ 'id': 6, 'href': '/docs/', 'title': "Docs", 'content': "" }); index.add({ 'id': 7, 'href': '/docs/go/goroutine/', 'title': "Go并发机制", 'content': " Go并发调度 背景知识 GO和其他语言不同的就是我们很少在GO中听到多线程的概念，其提供的API中也没有创建线程这种东西。因为这门语言从用户写的第一行代码开始就是并发状态的。\n并发与并行 并发是指多个逻辑可以同时执行，把CPU时间分成不同的时间片段，这些时间片段分配给不同的逻辑，构成一个完整的CPU执行时间序列。 而并行是一种特殊的并发，不同逻辑由于CPU的多核，分配在不同的核上可以在物理时间上同时执行。这种状态其实很难实现，因为往往任一操作系统，它本身跑的程序非常多，远大于CPU核数。\n线程与协程 线程是执行单位，相当于工厂里的生产线。操作系统是按线程分配时间片，所以程序的线程越多获得的执行时间也就越长。线程是在系统空间实现的，而协程是在用户空间实现的，操作系统根本不知道协程。\n比如某个线程上有A、B两个任务，若A有死循环或者A等待网络响应等就会发生B被饿死的情况，为了避免这种情况，A就会主动让给B或者调度器去执行。这就是协程的工作方式，任务之间相互协商，属于协作式多任务系统，通常是在用户空间实现一个框架。而多线程是抢占式调度，不管某个程序会不会主动让出，当前时间片执行完就会被操作系统强迫分给其他线程。\n程序等于算法加数据，算法相当于一个解决问题的过程，数据又分为系统数据和用户数据。用户数据保存在用户堆栈上。操作系统为每个线程分配一个栈，大多用来保存局部变量，通常编译期就能确定，运行期通过寄存器访问，无需垃圾回收。而堆内存属于进程，进程内的线程共享，需要运行期动态分配以及垃圾回收。\n运行时 现代的编程语言创建一个线程往往是使用一个标准库或者第三方库提供API的，分配内存也往往会向操作系统提前申请一大块内存，通过这样一层抽象来减少用户态和内核态的切换来提升效率，我们把这层抽象叫做runtime(运行时)。它就像一个弱化版的操作系统，可以针对用户空间内的代码，结合当前语言的特性做大量的优化。\nGo运行时第一个抽象出的概念就是P(Processor)，相当于处理器。物理上有多少个CPU、有多少个核，runtime并不关心，它是在OS上的一层抽象，os才是在硬件的上一层抽象。runtime认为在当前的环境内只有一个程序，所以我们可以通过P来设定并发的数量，同时能执行这个程序内的多少个并发任务。\n第二个抽象是M(Machine)，对应了一个系统线程，是对线程的包装，也就是说P控制了同时有多少个M在执行。它是实际执行体，和P绑定，以调度循环方式不断执行G并发任务。\n第三个抽象就是G(Goroutine)，实际上就是任务载体，或者说资源包，包括了函数地址，需要的参数，所需的内存。当我们使用go func(){}()时，实际上就是创建了一个G对象。\n为什么G需要内存，按说M相当于线程也就应该有了栈内存？实际上它们都有自己的内存，G中的内存为G.stack(默认大小2KB)，M中的内存为G0。G在M上运行，就像是列车在线路上运行，线路本身也需要去投入资源维护。而把两块内存分开，是因为M所需的内存比较连续、相对固定、逻辑完整，G却会因为各种各样的原因或者异常可能会调度到别的M上去。\nG、M、P共同构成了多任务并发执行的基本模式，P用来控制同时有多少个并发任务执行，M对应到某个线程，G代表了go func语句翻译的一个任务包，最终还得有个调度器统合起来，把G放到合适的M上去执行。\n任务平衡 正向分析 当我们在一个for循环中创建了成千上万个并发任务时，它们并不是立即执行的，而是打包成一个个G对象保存在两个队列中(P本地队列和G全局队列)。\n假设当前只有4个P，在main函数执行的时候就需要一个P1/M1绑定体，main中创建的其他go func就会打包成G对象放在P1.queue中。也就是说任一M内创建的G都会保存在当前这个P的本地队列中，为什么不能放在P2、P3、P4的队列中？放在别的队列就需要去判断这个P是不是闲置的，还可能需要加锁等等，会变得很复杂。\n那么如果在main中创建了1000个G，它们就得等P1/M1中当前的任务执行完了才会得到执行，可能P2、P3、P4都是闲置的，这明显不合理。如何在多个P之间去平衡任务呢？使用了两种方法，一种是规定了每个P本地队列只能放256个G，一次放的过多时会按一定规则比如放一半到全局队列中去；另一种是某个P若闲置了就会在全局队列中去找(可能有很多P都在全局中找，就需要排队去找)，找到了就把一部分任务移动到自己的本地队列中，没有找到就会去其他P中偷一部分任务过来，从全局队里或其他P中偷都是需要加锁的，效率相对会低一些。\n这样的平衡方式也就决定了我们没有办法确定哪个方法先执行，哪个后执行，除非我们自己写逻辑去判断先后。我们再来看一个关于执行顺序的示例:\nfunc main() { runtime.GOMAXPROCS(1) // 设置P为1  for i := 0; i \u0026lt; 10; i++ { go func(id int) { // 创建10个G  time.Sleep(time.Second) fmt.Println(id) }(i) } time.Sleep(time.Second * 2) } 执行结果:\n[ubuntu] ~/.mac/gocode $ go run goroutine.go 9 0 1 2 3 4 5 6 7 8  为什么当P为1的时候，它不是顺序输出的，9总是在第一个？\n 每个P的本地队列中其实包含两个部分，runnext[1]和runq[256]。当我们每次添加一个任务的时候，它会先放在runnext中，再添加一个任务时，会把新添加的放在runnext，之前添加的放在runq中。runnext总是保留用户最后创建的任务，执行的时候先查runnext去执行。\n 为什么要有runnext的设计？\n 假设只创建了一个并发任务，也放在runq中让别的P去抢没有必要，而且大多数情况下我们不会去批量创建G；另外若runq既用来P1执行又让P2、P3去偷，那就又会涉及到加锁。\n 那么为什么是G9放在runnext，而不是G0？\n 因为放在runnext以后我们无法保证还有多少逻辑执行完才轮到它，就可能会runq中的任务都被偷走了且执行完了G0才会执行，这对G0很不公平。\n显然任务被分成了三个性能层次，runnext是完全私有的，runq属于原子操作(原子操作对CPU来讲也是锁，锁的是地址总线)，Global属于一定要加mutex锁的，这三个层次产生资源竞争的可能性逐步增大。\n逆向分析 在最开始的时候，我们先设计为一个循环队列，它底层结构可能就是一个数组。问题在于，当有多个人去竞争的时候，这个数组就会存在资源竞争效应，我们就会考虑加入锁，显然这种效率是最低的。\n假设现在有3个P/M，我们就可以把一个大的队列拆分成3个小的队列，让每个P/M持有一个私有的队列，这种优化策略使得锁的问题可以解决掉。但也带来新的问题，可能P1已执行完自己的任务，P2、P3还得执行很久，我们可能一开始按任务的数量平均分配至各个私有队列，但有的任务执行时间很长，有的任务很快就能执行完。\n因此，P1应该去P2、P3中拿取任务才是合理的，所有人有义务去完成整个系统的任务。P1直接去拿就会和P2、P3打起来形成竞争效应，第二步的优化策略就是保留一个全局队列，P1可以先去全局队列里找，而P2、P3有很大概率是在本地队列去找的，P1获得锁的概率就会更大，全局队列使得锁的压力被分摊，同时也使得P2、P3中若有多余的任务也可以放进去。\n当P1的本地队列已执行完，全局队列中的任务也被执行完时，它就会任选P2或P3，形成直接的竞争。这时候我们考虑的优化策略，就是把本地队列一分为二，上面是runnext用于本地执行，下面是runq[256]用来给P1偷的。\n这种结构很像CPU的存储结构，通过分散距离、增加存储层次来减少直接竞争冲突的概率。\n调度执行 P、M解绑 当我们创建一个G的时候，实际上是背后的调度器在当前M上的G0去执行的，它发现有新的任务出现时，会发出一个唤醒信号，去检查有没有P空闲的，以及有没有M是休眠状态的？若P空闲且没有休眠的M，就会去创建一个M对象。所以唤醒操作要有意义，就得有P闲着没事干。\n那么M是怎样变为休眠状态的？\n当一个P和M绑定之后，它会进入到一个调度程序(Schedule函数)，调度程序会去找G对象(按runnext、runq、Global、other P的顺序)，找到之后内存由G0上执行切换到G.stack上去执行，执行完成之后进入收尾阶段，清理现场把G当做一个包装对象让它能重复使用。然后重新回到Schedule函数形成一个调度循环。\n这个循环可能因为找不到G对象而中断，比如说当前就只有一个任务。那么P和M就会解绑，M会进入休眠状态。\n还有一种P和M解绑的情况，比如当前在进行一个系统调用，而这个系统调用花了很长时间，调度器就会把这个P拿走干别的事，而M压根不知道，因为它在内核态，等系统调用结束以后M发现找不到P，那它就没法继续执行，只能把当前的任务状态保存回G.stack，在把执行一半的任务重新放回队列，M再次进入休眠状态，执行一半的任务再下次遇到P/M时接着执行。\n这就可能导致一个问题，创建出大量的空闲的M，不会被回收。M是会在操作系统内核中创建一个线程，尽管这种休眠状态下的M不会被CPU分配时间片，但仍然会占用管理资源，另外每个M上都带着G0内存，相当于资源泄漏了。我们通过如下代码来模拟这种情况：\nfunc main(){ for i :=0;i\u0026lt;1000;i++{ go func(){ runtime.LockOSThread() //通过锁模拟系统调用  defer runtime.UnlockOSThread() time.Sleep(time.Second*5) }() } time.Sleep(time.Minute) } 通过go build test.go \u0026amp;\u0026amp; GODEBUG=schedtrace=1000 ./test运行：\nSCHED 0ms: gomaxprocs=4 idleprocs=2 threads=5 spinningthreads=1 idlethreads=2 runqueue=0 [0 0 0 0] SCHED 1002ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 2008ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 3013ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 4014ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 5015ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=127 runqueue=0 [0 0 0 0] SCHED 6017ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] SCHED 7025ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] SCHED 8027ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] SCHED 9029ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] SCHED 10031ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] 我们发现任务开始的时候共创建了1010个线程，任务执行完以后，仍然有1007个休眠的线程。当我们把runtime.LockOSThread()注释掉，重新运行：\nSCHED 0ms: gomaxprocs=4 idleprocs=1 threads=5 spinningthreads=1 idlethreads=1 runqueue=0 [48 49 133 0] SCHED 1004ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 2008ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 3010ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 4015ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 5026ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=7 runqueue=0 [0 0 0 0] SCHED 6031ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=7 runqueue=0 [0 0 0 0] 发现没有系统调用，那就根本不会有那么多线程。我们再把runtime.LockOSThread()保留，defer runtime.UnlockOSThread()去掉，运行结果如下：\nSCHED 0ms: gomaxprocs=4 idleprocs=2 threads=5 spinningthreads=1 idlethreads=2 runqueue=0 [0 0 152 0] SCHED 1000ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 2001ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 3008ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 4016ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 5019ms: gomaxprocs=4 idleprocs=0 threads=938 spinningthreads=0 idlethreads=4 runqueue=0 [18 1 3 7] SCHED 6027ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] SCHED 7037ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] SCHED 8042ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] SCHED 9044ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] cSCHED 10047ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] 我们发现那些创建的线程是会被回收的，线程没有被解锁意味着线程的状态没有被解除而陷入了死锁状态，线程不能再去接收新的任务没有存在的意义自然会被杀掉。\n综上，我们发现P往往是恒定的，而G和M是可复用的，复用虽然可能造成资源的浪费，但它避免了重新创建时的可能造成的竞争效应。对于一些长期运行的东西，我们需要再创建还是释放之间做一些权衡。\n任务饿死 假设当前的P/M正在执行一个G，这时候G里面创建了一个G1，G1会被放到当前P的runnext中，但它可能迟迟得不到执行被饿死，因为G中可能还有大量的逻辑代码执行完才轮到runnext，这显然是不合理的。怎么解决这个问题呢？是否可以让当前这个P/M交替的执行G和G1？P不是真正的CPU，没法实现基于时间片的抢占式调度，只能实现类似于协程那样的协作式调度。很多语言里都使用类似于Gosched()这样的函数来主动交出执行权，但Go中却很少见；还有一种形式是runtime带一个计数器，每执行一个任务后累加计数，当到达一个指定的计数就会被认为是使用完了时间片，向当前执行的P/M发出一个抢占式的信号，然后G主动让出执行权限。Go到底是怎样做的？我们来看如下示例：\n// GODEBUG=schedtrace=1000,scheddetail=1 ./test 可查看运行期GMP状态 func main(){ runtime.GOMAXPROCS(1) for i:=0;i\u0026lt;3;i++{ go func(id int){ println(id) x := 0 for{ // 死循环  x++ //print()  } }(i) } time.Sleep(time.Second) } 我们模拟了只有一个P/M，这时候创建了3个G，让第一个G执行的过程中进入死循环，运行结果就是只打印出了任务0，其他G被饿死了。但当我们在死循环内x++后面加入一个函数，则任务0、1、2都会被打印出。问题就出在这个函数上。\n我们先使用一个简单的函数来观察：\n//go:noinline func test(){ println() } func main(){ test() } 使用go build \u0026amp;\u0026amp; go tool objdump -s \u0026quot;main\\.test\u0026quot; test反汇编：\nTEXT main.test(SB) /mnt/hgfs/disk/test.go test.go:5\t0x4525b0\t64488b0c25f8ffffff\tMOVQ FS:0xfffffff8, CX\ttest.go:5\t0x4525b9\t483b6110\tCMPQ 0x10(CX), SP\ttest.go:5\t0x4525bd\t7624\tJBE 0x4525e3\ttest.go:5\t0x4525bf\t4883ec08\tSUBQ $0x8, SP\ttest.go:5\t0x4525c3\t48892c24\tMOVQ BP, 0(SP)\ttest.go:5\t0x4525c7\t488d2c24\tLEAQ 0(SP), BP\ttest.go:6\t0x4525cb\te80031fdff\tCALL runtime.printlock(SB)\ttest.go:6\t0x4525d0\te88b33fdff\tCALL runtime.printnl(SB)\ttest.go:6\t0x4525d5\te87631fdff\tCALL runtime.printunlock(SB)\ttest.go:7\t0x4525da\t488b2c24\tMOVQ 0(SP), BP\ttest.go:7\t0x4525de\t4883c408\tADDQ $0x8, SP\ttest.go:7\t0x4525e2\tc3\tRET\ttest.go:5\t0x4525e3\te8187bffff\tCALL runtime.morestack_noctxt(SB)\ttest.go:5\t0x4525e8\tebc6\tJMP main.test(SB)\t 我们发现头部的三条指令和尾部的两条指令都是编译器插入的。runtime.morestack_noctxt会做两件事情，一是检查当前栈帧空间是否足够，如果不够可以帮助扩容；二是检查是否有人发出了抢占式调度信号，如果发现了信号，它就让出执行权限。函数前使用go:nosplit可以禁止编译器插入这样的指令。\n" }); index.add({ 'id': 8, 'href': '/', 'title': "Introduction", 'content': " 非法操作的知识库 主要用于记录学习过程中的重要知识点。\n关于作者  Github  Twitter  Email  Telegram  " }); index.add({ 'id': 9, 'href': '/docs/mysql/query/', 'title': "Mysql查询", 'content': " Mysql常用查询整理 数据准备 1、创建表格:\nCREATE TABLE student_info ( number INT PRIMARY KEY, name VARCHAR(5), sex ENUM(\u0026#39;男\u0026#39;, \u0026#39;女\u0026#39;), id_number CHAR(18), department VARCHAR(30), major VARCHAR(30), enrollment_time DATE, UNIQUE KEY (id_number) ); CREATE TABLE student_score ( number INT, subject VARCHAR(30), score TINYINT, PRIMARY KEY (number, subject), CONSTRAINT FOREIGN KEY(number) REFERENCES student_info(number) ); 2、填充数据: INSERT INTO student_info(number, name, sex, id_number, department, major, enrollment_time) VALUES (20180101, \u0026#39;杜子腾\u0026#39;, \u0026#39;男\u0026#39;, \u0026#39;158177199901044792\u0026#39;, \u0026#39;计算机学院\u0026#39;, \u0026#39;计算机科学与工程\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180102, \u0026#39;杜琦燕\u0026#39;, \u0026#39;女\u0026#39;, \u0026#39;151008199801178529\u0026#39;, \u0026#39;计算机学院\u0026#39;, \u0026#39;计算机科学与工程\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180103, \u0026#39;范统\u0026#39;, \u0026#39;男\u0026#39;, \u0026#39;17156319980116959X\u0026#39;, \u0026#39;计算机学院\u0026#39;, \u0026#39;软件工程\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180104, \u0026#39;史珍香\u0026#39;, \u0026#39;女\u0026#39;, \u0026#39;141992199701078600\u0026#39;, \u0026#39;计算机学院\u0026#39;, \u0026#39;软件工程\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180105, \u0026#39;范剑\u0026#39;, \u0026#39;男\u0026#39;, \u0026#39;181048199308156368\u0026#39;, \u0026#39;航天学院\u0026#39;, \u0026#39;飞行器设计\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180106, \u0026#39;朱逸群\u0026#39;, \u0026#39;男\u0026#39;, \u0026#39;197995199501078445\u0026#39;, \u0026#39;航天学院\u0026#39;, \u0026#39;电子信息\u0026#39;, \u0026#39;2018-09-01\u0026#39;); INSERT INTO student_score (number, subject, score) VALUES (20180101, \u0026#39;母猪的产后护理\u0026#39;, 78), (20180101, \u0026#39;论萨达姆的战争准备\u0026#39;, 88), (20180102, \u0026#39;母猪的产后护理\u0026#39;, 100), (20180102, \u0026#39;论萨达姆的战争准备\u0026#39;, 98), (20180103, \u0026#39;母猪的产后护理\u0026#39;, 59), (20180103, \u0026#39;论萨达姆的战争准备\u0026#39;, 61), (20180104, \u0026#39;母猪的产后护理\u0026#39;, 55), (20180104, \u0026#39;论萨达姆的战争准备\u0026#39;, 46);\n3、填充结果:\nstudent_info表\n   number \u0026nbsp;name\u0026nbsp; sex id_number department \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;major\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; enrollment_time     20180101 杜子腾 男 158177199901044792 计算机学院 计算机科学与工程 2018-09-01   20180102 杜琦燕 女 151008199801178529 计算机学院 计算机科学与工程 2018-09-01   20180103 范统 男 17156319980116959X 计算机学院 软件工程 2018-09-01   20180104 史珍香 女 141992199701078600 计算机学院 软件工程 2018-09-01   20180105 范剑 男 181048199308156368 航天学院 飞行器设计 2018-09-01   20180106 朱逸群 男 197995199501078445 航天学院 电子信息 2018-09-01    student_score表\n   number subject score     20180101 母猪的产后护理 78   20180101 论萨达姆的战争准备 88   20180102 母猪的产后护理 100   20180102 论萨达姆的战争准备 98   20180103 母猪的产后护理 59   20180103 论萨达姆的战争准备 61   20180104 母猪的产后护理 55   20180104 论萨达姆的战争准备 46    基础查询 别名  方式一:select number as 学号 from student_score 方式二:select number 学号 from student_score\n  查询结果: mysql\u0026gt; select number 学号 from student_score; +----------+ | 学号 | +----------+ | 20180101 | | 20180101 | | 20180102 | | 20180102 | | 20180103 | | 20180103 | | 20180104 | | 20180104 | +----------+ 8 rows in set (0.00 sec)\n多列也可以: mysql\u0026gt; select number 学号, name 姓名 from student_info; +----------+-----------+ | 学号 | 姓名 | +----------+-----------+ | 20180101 | 杜子腾 | | 20180102 | 杜琦燕 | | 20180103 | 范统 | | 20180104 | 史珍香 | | 20180105 | 范剑 | | 20180106 | 朱逸群 | +----------+-----------+ 6 rows in set (0.00 sec)\n去重 单列去重: mysql\u0026gt; select distinct department from student_info; +-----------------+ | department | +-----------------+ | 计算机学院 | | 航天学院 | +-----------------+ 2 rows in set (0.00 sec)\n多列去重: mysql\u0026gt; select distinct department,major from student_info; +-----------------+--------------------------+ | department | major | +-----------------+--------------------------+ | 计算机学院 | 计算机科学与工程 | | 计算机学院 | 软件工程 | | 航天学院 | 飞行器设计 | | 航天学院 | 电子信息 | +-----------------+--------------------------+ 4 rows in set (0.00 sec)\n限制查询结果条数 使用limit 从哪开始，多少条，从哪开始可以省略，省略代表第0行。\nmysql\u0026gt; select * from student_info limit 3,8; +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ 3 rows in set (0.00 sec) 排序 多列排序: mysql\u0026gt; select * from student_info order by name asc, number desc; +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 6 rows in set (0.00 sec) mysql\u0026gt; select * from student_info order by name desc, number desc; +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 6 rows in set (0.00 sec)\n带条件查询 简单搜索条件 不等于可以使用\u0026lt;\u0026gt;或!= : mysql\u0026gt; select * from student_info where department \u0026lt;\u0026gt; \u0026#39;计算机学院\u0026#39;; +----------+-----------+------+--------------------+--------------+-----------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+--------------+-----------------+-----------------+ | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | +----------+-----------+------+--------------------+--------------+-----------------+-----------------+ 2 rows in set (0.00 sec)\n区间内使用between...and...，不在某区间使用not between...and...: mysql\u0026gt; select * from student_info where number between 20180103 and 20180105; +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ 3 rows in set (0.01 sec) mysql\u0026gt; select * from student_info where number not between 20180103 and 20180105; +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 3 rows in set (0.00 sec)\n匹配列表中的元素 使用in (...)和not in筛选出在某个列表中的记录: mysql\u0026gt; select * from student_info where major in (\u0026#39;软件工程\u0026#39;, \u0026#39;电子信息\u0026#39;); +----------+-----------+------+--------------------+-----------------+--------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------+-----------------+ 3 rows in set (0.00 sec)\n使用is null 和 is not null可筛选出某列是NULL的记录，而不能使用普通的操作符例如等号来进行比较，NULL代表没有值。\n多个搜索条件 AND优先级高于OR: mysql\u0026gt; SELECT * FROM student_score WHERE score \u0026gt; 95 OR score \u0026lt; 55 AND subject = \u0026#39;论萨达姆的战争准备\u0026#39;; +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180102 | 母猪的产后护理 | 100 | | 20180102 | 论萨达姆的战争准备 | 98 | | 20180104 | 论萨达姆的战争准备 | 46 | +----------+-----------------------------+-------+ 3 rows in set (0.00 sec)\n模糊查询 使用like和not like进行模糊匹配查询，%代表任意一个字符串，而_代表任意一个字符: mysql\u0026gt; select * from student_info where name like \u0026#39;杜_\u0026#39;; Empty set (0.00 sec) mysql\u0026gt; select * from student_info where name like \u0026#39;范_\u0026#39;; +----------+--------+------+--------------------+-----------------+-----------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+--------+------+--------------------+-----------------+-----------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | +----------+--------+------+--------------------+-----------------+-----------------+-----------------+ 2 rows in set (0.00 sec) mysql\u0026gt; select * from student_info where name like \u0026#39;%杜%\u0026#39;; +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 2 rows in set (0.00 sec)\n函数和表达式 表达式 可以将表达式放在查询列表中: mysql\u0026gt; select number,subject,score+100 from student_score; +----------+-----------------------------+-----------+ | number | subject | score+100 | +----------+-----------------------------+-----------+ | 20180101 | 母猪的产后护理 | 178 | | 20180101 | 论萨达姆的战争准备 | 188 | | 20180102 | 母猪的产后护理 | 200 | | 20180102 | 论萨达姆的战争准备 | 198 | | 20180103 | 母猪的产后护理 | 159 | | 20180103 | 论萨达姆的战争准备 | 161 | | 20180104 | 母猪的产后护理 | 155 | | 20180104 | 论萨达姆的战争准备 | 146 | +----------+-----------------------------+-----------+ 8 rows in set (0.00 sec)\n也可以把表达式作为搜索的条件: mysql\u0026gt; select * from student_score where score%3=0; +----------+-----------------------+-------+ | number | subject | score | +----------+-----------------------+-------+ | 20180101 | 母猪的产后护理 | 78 | +----------+-----------------------+-------+ 1 row in set (0.00 sec)\n文本处理 连接字符串: mysql\u0026gt; select concat(\u0026#39;学号为\u0026#39;,number,\u0026#39;的学生在[\u0026#39;,subject,\u0026#39;]的成绩为\u0026#39;,score) from student_score; +--------------------------------------------------------------------------+ | concat(\u0026#39;学号为\u0026#39;,number,\u0026#39;的学生在[\u0026#39;,subject,\u0026#39;]的成绩为\u0026#39;,score) | +--------------------------------------------------------------------------+ | 学号为20180101的学生在[母猪的产后护理]的成绩为78 | | 学号为20180101的学生在[论萨达姆的战争准备]的成绩为88 | | 学号为20180102的学生在[母猪的产后护理]的成绩为100 | | 学号为20180102的学生在[论萨达姆的战争准备]的成绩为98 | | 学号为20180103的学生在[母猪的产后护理]的成绩为59 | | 学号为20180103的学生在[论萨达姆的战争准备]的成绩为61 | | 学号为20180104的学生在[母猪的产后护理]的成绩为55 | | 学号为20180104的学生在[论萨达姆的战争准备]的成绩为46 | +--------------------------------------------------------------------------+ 8 rows in set (0.00 sec)\n子串: mysql\u0026gt; select substring(number, 4, 5) as 学号尾号 from student_info; +--------------+ | 学号尾号 | +--------------+ | 80104 | | 80102 | | 80101 | | 80103 | | 80105 | | 80106 | +--------------+ 6 rows in set (0.00 sec)\n时间处理函数 时间间隔: mysql\u0026gt; select date_add(\u0026#39;2015-01-01 10:20:33\u0026#39;, interval 2 minute); +----------------------------------------------------+ | date_add(\u0026#39;2015-01-01 10:20:33\u0026#39;, interval 2 minute) | +----------------------------------------------------+ | 2015-01-01 10:22:33 | +----------------------------------------------------+ 1 row in set (0.00 sec)\n时间格式化: mysql\u0026gt; select date_format(now(), \u0026#39;%b/%d/%Y %h:%i:%s~%p\u0026#39;); +--------------------------------------------+ | date_format(now(), \u0026#39;%b/%d/%Y %h:%i:%s~%p\u0026#39;) | +--------------------------------------------+ | Dec/02/2019 04:57:31~PM | +--------------------------------------------+ 1 row in set (0.00 sec)\n聚集函数 COUNT用来统计行数 * COUNT(*)统计表中所有的行，包括NULL * COUNT(列名)统计表中某列的所有行，不包括NULL\nmysql\u0026gt; select count(*) from student_info; +----------+ | count(*) | +----------+ | 6 | +----------+ 1 row in set (0.00 sec) mysql\u0026gt; select count(distinct subject) from student_score; +-------------------------+ | count(distinct subject) | +-------------------------+ | 2 | +-------------------------+ 1 row in set (0.00 sec) SUM和AVG: mysql\u0026gt; select sum(score) from student_score; +------------+ | sum(score) | +------------+ | 585 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select avg(score) from student_score where subject=\u0026#34;论萨达姆的战争准备\u0026#34;; +------------+ | avg(score) | +------------+ | 73.2500 | +------------+ 1 row in set (0.00 sec)\n组合使用: mysql\u0026gt; select count(*) as 成绩记录总数, max(score) as 最高分, min(score) as 最低分,avg(score) as 平均分 from student_score; +--------------------+-----------+-----------+-----------+ | 成绩记录总数 | 最高分 | 最低分 | 平均分 | +--------------------+-----------+-----------+-----------+ | 8 | 100 | 46 | 73.1250 | +--------------------+-----------+-----------+-----------+ 1 row in set (0.00 sec)\n隐式类型转换 Mysql会尽量把值转换为表达式中需要的类型，而不是产生错误: mysql\u0026gt; select 1 + \u0026#39;2\u0026#39;; +---------+ | 1 + \u0026#39;2\u0026#39; | +---------+ | 3 | +---------+ 1 row in set (0.00 sec) mysql\u0026gt; select \u0026#39;23sds\u0026#39;+17; +------------+ | \u0026#39;23sds\u0026#39;+17 | +------------+ | 40 | +------------+ 1 row in set, 1 warning (0.00 sec)\n但这种转换不能用于存储数据: mysql\u0026gt; insert into student_score(score,number,subject) values (100,20180101,300); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into student_score(score,number,subject) values (\u0026#39;100\u0026#39;,20180101,400); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into student_score(score,number,subject) values (\u0026#39;asd\u0026#39;,20180101,400); ERROR 1366 (HY000): Incorrect integer value: \u0026#39;asd\u0026#39; for column \u0026#39;score\u0026#39; at row 1\n分组查询 基础查询 分组就是针对某个列，将该列的值相同的记录分到一个组中: mysql\u0026gt; select subject, sum(score) from student_score group by subject; +-----------------------------+------------+ | subject | sum(score) | +-----------------------------+------------+ | 母猪的产后护理 | 292 | | 论萨达姆的战争准备 | 293 | +-----------------------------+------------+ 2 rows in set (0.00 sec)\n把非分组列放入查询列表中会引起争议，导致结果不确定: mysql\u0026gt; select subject, sum(score),number from student_score group by subject; ERROR 1055 (42000): Expression #3 of SELECT list is not in GROUP BY clause and contains nonaggregated column \u0026#39;student.student_score.number\u0026#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by\n分组和过滤条件 是先过滤出符合条件的数据，在进行分组运算的: mysql\u0026gt; select subject, sum(score) from student_score where score\u0026gt;70 group by subject; +-----------------------------+------------+ | subject | sum(score) | +-----------------------------+------------+ | 母猪的产后护理 | 178 | | 论萨达姆的战争准备 | 186 | +-----------------------------+------------+ 2 rows in set (0.00 sec)\n也可以分组后，在筛选出合适的分组: mysql\u0026gt; select subject, sum(score) from student_score group by subject having max(score)\u0026gt;98; +-----------------------+------------+ | subject | sum(score) | +-----------------------+------------+ | 母猪的产后护理 | 292 | +-----------------------+------------+ 1 row in set (0.00 sec)\n分组和排序 mysql\u0026gt; select subject, sum(score) as sum_s from student_score group by subject order by sum_s desc; +-----------------------------+-------+ | subject | sum_s | +-----------------------------+-------+ | 论萨达姆的战争准备 | 293 | | 母猪的产后护理 | 292 | +-----------------------------+-------+ 2 rows in set (0.00 sec) 嵌套分组 如下例，可先按department分成大组，再按major分为小组: mysql\u0026gt; select department, major, count(*) from student_info group by department, major; +-----------------+--------------------------+----------+ | department | major | count(*) | +-----------------+--------------------------+----------+ | 航天学院 | 电子信息 | 1 | | 航天学院 | 飞行器设计 | 1 | | 计算机学院 | 计算机科学与工程 | 2 | | 计算机学院 | 软件工程 | 2 | +-----------------+--------------------------+----------+ 4 rows in set (0.00 sec)\n注意事项  如果分组列中有NULL值，那么NULL会作为一个独立的分组 如果是嵌套分组，聚集函数将作用在最后的分组列上 非分组列不能单独出现在检索列表中(可以被放到聚集函数中) GROUP BY子句后可以跟随表达式(但不能是聚集函数)  简单查询语句中各子句的顺序为: SELECT [DISTINCT] 查询列表 [FROM 表名] [WHERE 布尔表达式] [GROUP BY 分组列表 ] [HAVING 分组过滤条件] [ORDER BY 排序列表] [LIMIT 开始行, 限制条数]\n子查询 标量子查询 标量子查询单纯的代表一个值，可以作为表达式参与运算或作为搜索条件: mysql\u0026gt; select * from student_score where number=(select number from student_info where name=\u0026#39;范统\u0026#39;); +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180103 | 母猪的产后护理 | 59 | | 20180103 | 论萨达姆的战争准备 | 61 | +----------+-----------------------------+-------+ 2 rows in set (0.00 sec)\n列子查询 内层查询结果不是一个单独的值，而是一个列: mysql\u0026gt; select * from student_score where number=(select number from student_info where sex=\u0026#39;男\u0026#39;); ERROR 1242 (21000): Subquery returns more than 1 row mysql\u0026gt; select * from student_score where number in (select number from student_info where sex=\u0026#39;男\u0026#39;); +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180101 | 母猪的产后护理 | 78 | | 20180101 | 论萨达姆的战争准备 | 88 | | 20180103 | 母猪的产后护理 | 59 | | 20180103 | 论萨达姆的战争准备 | 61 | +----------+-----------------------------+-------+ 4 rows in set (0.00 sec)\n而行子查询、表子查询不常用，省略。\nEXISTS和相关子查询 EXISTS和NOT EXISTS单独看很像一个函数，返回查询结果是否为空集: mysql\u0026gt; select exists (select * from student_info where number=20180101); +-----------------------------------------------------------+ | exists (select * from student_info where number=20180101) | +-----------------------------------------------------------+ | 1 | +-----------------------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select not exists (select * from student_info where number=20180101); +---------------------------------------------------------------+ | not exists (select * from student_info where number=20180101) | +---------------------------------------------------------------+ | 0 | +---------------------------------------------------------------+ 1 row in set (0.00 sec)\n之前我们尝试的都是不相关子查询，而相关子查询就是内层查询语句要用到外层查询语句的值，比如我们查学生的基本信息并要求这些学生有成绩的记录: mysql\u0026gt; select * from student_info where exists(select * from student_score where student_score.number=student_info.number); +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 4 rows in set (0.00 sec)\n这个相关子查询的查询过程是:先执行外层查询获得到student_info表的第一条记录，发现它的number值是20180101。把20180101当作参数传入到子查询，此时子查询的意思是判断student_score表的number字段是否有20180101这个值存在，子查询的结果是该值存在，所以整个EXISTS表达式的值为TRUE，那么student_info表的第一条记录可以被加入到结果集。每条记录依次按这个过程执行。\n此外，子查询还可以应用于同一个表，比如我们去查student_score表中分数大于平均分的记录，第一印象可能是如下写法: mysql\u0026gt; select * from student_score where score \u0026gt; avg(score); ERROR 1111 (HY000): Invalid use of group function\n实际应该使用子查询来实现: mysql\u0026gt; select * from student_score where score \u0026gt; (select avg(score) from student_score); +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180101 | 母猪的产后护理 | 78 | | 20180101 | 论萨达姆的战争准备 | 88 | | 20180102 | 母猪的产后护理 | 100 | | 20180102 | 论萨达姆的战争准备 | 98 | +----------+-----------------------------+-------+ 4 rows in set (0.00 sec) 因为聚集函数不能用于WHERE子句，可以把上述写法看做是给student_score做了一个副本。\n连接查询 基础概念 连接的本质就是将各个表中的记录都拉取出来，依次匹配组合形成一个结果集，也就是笛卡尔积的方式。\n我们来看一个示例: mysql\u0026gt; create table t1(m1 int, n1 char(1)); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; create table t2(m2 int, n2 char(1)); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; insert into t1 values(1, \u0026#39;a\u0026#39;),(2, \u0026#39;b\u0026#39;),(3, \u0026#39;c\u0026#39;); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql\u0026gt; insert into t2 values(2, \u0026#39;a\u0026#39;),(3, \u0026#39;b\u0026#39;),(4, \u0026#39;c\u0026#39;); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0\n新建了两个表，并各插入了三条数据，那么连接可以这样做: mysql\u0026gt; select * from t1,t2; +------+------+------+------+ | m1 | n1 | m2 | n2 | +------+------+------+------+ | 1 | a | 2 | a | | 2 | b | 2 | a | | 3 | c | 2 | a | | 1 | a | 3 | b | | 2 | b | 3 | b | | 3 | c | 3 | b | | 1 | a | 4 | c | | 2 | b | 4 | c | | 3 | c | 4 | c | +------+------+------+------+ 9 rows in set (0.00 sec)\n使用以下写法连接都是可以的:\n select t1.m1,t1.n1,t2.m2,t2.n2 from t1, t2 select m1,n1,m2,n2 from t1, t2 select t1.*,t2.* from t1, t2  内外连接 现在我们想通过一条语句既查到学生的基本信息，又查到他的成绩信息: mysql\u0026gt; select student_info.number,name,sex,subject,score from student_info, student_score where student_info.number = student_score.number; +----------+-----------+------+-----------------------------+-------+ | number | name | sex | subject | score | +----------+-----------+------+-----------------------------+-------+ | 20180101 | 杜子腾 | 男 | 母猪的产后护理 | 78 | | 20180101 | 杜子腾 | 男 | 论萨达姆的战争准备 | 88 | | 20180102 | 杜琦燕 | 女 | 母猪的产后护理 | 100 | | 20180102 | 杜琦燕 | 女 | 论萨达姆的战争准备 | 98 | | 20180103 | 范统 | 男 | 母猪的产后护理 | 59 | | 20180103 | 范统 | 男 | 论萨达姆的战争准备 | 61 | | 20180104 | 史珍香 | 女 | 母猪的产后护理 | 55 | | 20180104 | 史珍香 | 女 | 论萨达姆的战争准备 | 46 | +----------+-----------+------+-----------------------------+-------+ 8 rows in set (0.00 sec)\n这时候我们发现有两个人没有成绩，所以他们没有显示在查询结果中。为了有办法让其显示出，就有了内连接和外连接的概念:\n 内连接就是我们之前使用的，没有匹配的记录则结果不会加入到最后的结果集 对于外连接的两个表，驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集  而外连接又分为左外连接，即左侧的表为驱动表。右外连接，即右侧的表为驱动表。\n此外，WHERE子句不论内外连接，凡是不符合WHERE条件的记录都不会在最后的结果集中。而对于外连接的驱动表，ON可以将被驱动表中找不到记录的对应驱动表记录加入到结果集，内连接中WHERE子句和ON子句是等价的。所以我们一般会把WHERE用于涉及单表的过滤条件，ON用于涉及多表的过滤条件。\n外连接的标准语法为: select * from t1 left/right [outer] join t2 on 连接条件 [where 普通过滤条件]，outer和where可省略。\n上例中使用外连接的结果为: mysql\u0026gt; select student_info.number,name,sex,subject,score from student_info left join student_score on student_info.number = student_score.number; +----------+-----------+------+-----------------------------+-------+ | number | name | sex | subject | score | +----------+-----------+------+-----------------------------+-------+ | 20180101 | 杜子腾 | 男 | 母猪的产后护理 | 78 | | 20180101 | 杜子腾 | 男 | 论萨达姆的战争准备 | 88 | | 20180102 | 杜琦燕 | 女 | 母猪的产后护理 | 100 | | 20180102 | 杜琦燕 | 女 | 论萨达姆的战争准备 | 98 | | 20180103 | 范统 | 男 | 母猪的产后护理 | 59 | | 20180103 | 范统 | 男 | 论萨达姆的战争准备 | 61 | | 20180104 | 史珍香 | 女 | 母猪的产后护理 | 55 | | 20180104 | 史珍香 | 女 | 论萨达姆的战争准备 | 46 | | 20180105 | 范剑 | 男 | NULL | NULL | | 20180106 | 朱逸群 | 男 | NULL | NULL | +----------+-----------+------+-----------------------------+-------+ 10 rows in set (0.00 sec)\n内连接以下的写法是等价的:\n select * from t1, t2 select * from t1 join t2 select * from t1 inner join t2 select * from t1 cross join t2  综上，我们总结以下三种连接的结果差异: mysql\u0026gt; select * from t1 inner join t2 on t1.m1=t2.m2; +------+------+------+------+ | m1 | n1 | m2 | n2 | +------+------+------+------+ | 2 | b | 2 | a | | 3 | c | 3 | b | +------+------+------+------+ 2 rows in set (0.00 sec) mysql\u0026gt; select * from t1 left join t2 on t1.m1=t2.m2; +------+------+------+------+ | m1 | n1 | m2 | n2 | +------+------+------+------+ | 2 | b | 2 | a | | 3 | c | 3 | b | | 1 | a | NULL | NULL | +------+------+------+------+ 3 rows in set (0.00 sec) mysql\u0026gt; select * from t1 right join t2 on t1.m1=t2.m2; +------+------+------+------+ | m1 | n1 | m2 | n2 | +------+------+------+------+ | 2 | b | 2 | a | | 3 | c | 3 | b | | NULL | NULL | 4 | c | +------+------+------+------+ 3 rows in set (0.00 sec)\n多表连接 我们可以连接任意数量的表，我们再加入一张表试验: mysql\u0026gt; create table t3(m3 int, n3 char(1)); Query OK, 0 rows affected (0.07 sec) mysql\u0026gt; insert into t3 values(3, \u0026#39;a\u0026#39;),(3, \u0026#39;b\u0026#39;),(4, \u0026#39;c\u0026#39;); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0\n我们使用下面的语法查询是等价的:\n select * from t1 inner join t2 inner join t3 where t1.m1=t2.m2 and t2.m2=t3.m3; select * from t1 inner join t2 on t1.m1=t2.m2 inner join t3 on t1.m1=t3.m3;  查询结果: mysql\u0026gt; select * from t1 inner join t2 on t1.m1=t2.m2 inner join t3 on t1.m1=t3.m3; +------+------+------+------+------+------+ | m1 | n1 | m2 | n2 | m3 | n3 | +------+------+------+------+------+------+ | 3 | c | 3 | b | 3 | a | | 3 | c | 3 | b | 3 | b | +------+------+------+------+------+------+ 2 rows in set (0.00 sec) 也可以用伪代码来描述:\nfor each_row in t1{ for each_row in t2 which t1.m1=t2.m2{ for each_row in t3 which t2.m2=t3.m3{ add_result(each_row) } } }  自连接 我们无法直接自连接，但可以通过别名: mysql\u0026gt; select * from t1, t1; ERROR 1066 (42000): Not unique table/alias: \u0026#39;t1\u0026#39; mysql\u0026gt; select * from t1 as table1, t1 as table2; +------+------+------+------+ | m1 | n1 | m1 | n1 | +------+------+------+------+ | 1 | a | 1 | a | | 2 | b | 1 | a | | 3 | c | 1 | a | | 1 | a | 2 | b | | 2 | b | 2 | b | | 3 | c | 2 | b | | 1 | a | 3 | c | | 2 | b | 3 | c | | 3 | c | 3 | c | +------+------+------+------+ 9 rows in set (0.00 sec)\n而自连接的意义，比如要查询与\u0026rsquo;范统\u0026rsquo;的专业相同的同学: mysql\u0026gt; select * from student_info as s1, student_info as s2 where s1.name=\u0026#39;范统\u0026#39; and s1.major=s2.major; +----------+--------+------+--------------------+-----------------+--------------+-----------------+----------+-----------+------+--------------------+-----------------+--------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | number | name | sex | id_number | department | major | enrollment_time | +----------+--------+------+--------------------+-----------------+--------------+-----------------+----------+-----------+------+--------------------+-----------------+--------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | +----------+--------+------+--------------------+-----------------+--------------+-----------------+----------+-----------+------+--------------------+-----------------+--------------+-----------------+ 2 rows in set (0.00 sec)\n与子查询转换 有的需求既可以用连接查询，也可以用子查询: mysql\u0026gt; select * from student_score where number in (select number from student_info where major=\u0026#39;软件工程\u0026#39;); +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180103 | 母猪的产后护理 | 59 | | 20180103 | 论萨达姆的战争准备 | 61 | | 20180104 | 母猪的产后护理 | 55 | | 20180104 | 论萨达姆的战争准备 | 46 | +----------+-----------------------------+-------+ 4 rows in set (0.00 sec) mysql\u0026gt; select s2.* from student_score as s2, student_info as s1 where s1.number=s2.number and s1.major=\u0026#39;软件工程\u0026#39;; +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180103 | 母猪的产后护理 | 59 | | 20180103 | 论萨达姆的战争准备 | 61 | | 20180104 | 母猪的产后护理 | 55 | | 20180104 | 论萨达姆的战争准备 | 46 | +----------+-----------------------------+-------+ 4 rows in set (0.00 sec)\n" }); index.add({ 'id': 10, 'href': '/tags/', 'title': "Tags", 'content': "" }); index.add({ 'id': 11, 'href': '/docs/go/gc/', 'title': "垃圾回收器", 'content': " 垃圾回收器的设计 背景知识 垃圾回收器的首要任务就是节约内存，尽可能的节约内存也意味着要尽可能的增加执行频率，这样就会影响性能。如果不想影响用户代码的性能，就得尽量隔久一些执行一次垃圾回收，这就可能导致大量内存无法回收，空间浪费严重。所以垃圾回收器的设计难点就是在这两者间取得平衡，很难做到完美。\n我们说垃圾回收通常是针对堆上的垃圾，堆内存都是要释放的，区别只是有的语言需要手动释放，有的语言由垃圾回收器来释放，不释放就是内存泄漏了。而栈内存是绑定在线程上，在Go中也就是M(G0)以及G，默认的2KB会当做一个对象来处理，垃圾回收器通常不会介入。\nGo中的垃圾回收属于很传统的策略，基于标记清理，标记出死了的对象然后清理掉，但它不会压缩内存，有的语言会压缩好处在于可以空出大量的连续内存空间，但Go由于支持指针不会这样做。\n另外，由于Go需要支持垃圾回收和用户逻辑的并发，也让垃圾回收这件事复杂了很多。就像我们要打扫一条街，那把街两头堵住打扫完了再打开是最方便的，但现在要在打扫的同时不能影响游客游览，这就可能这条街永远打扫不干净。\n即便是并发，也会有一个短暂的暂停行为，被称为STW(stop the world)。需要在这个时间内去通知所有的P，我要开始垃圾回收了，并做一些相关的状态设置，用户代码被冻结。所以有时候用户程序对垃圾回收器不友好是可能造成卡顿的，比如说在极短的时间内大量创建了微小对象，逼的垃圾回收器执行频率升高，卡顿就会明显，这种情况就要考虑用对象池等方式来优化。\n垃圾回收的过程主要涉及怎么触发、怎么启动、怎么标记、怎么清理这些问题，我们下面来详细了解这些问题。\n触发 有三种情况会触发垃圾回收，通过自动触发，手工触发，系统监控程序来触发。\n自动触发是有一个阈值(nextGC)，默认可能是4MB或者8MB，当在堆上分配的内存超过该阈值，则自动启动回收，每次启动后调整下次阈值翻倍。\n手工强制使用runtime.GC这样的代码来执行垃圾回收，这种方式不会去检查阈值，往往用来模拟和测试。\n为什么还需要系统监控程序触发呢？假设某段时间有个热点，内存突然使用了100MB，那么自动触发的阈值就会被推高到200MB，这时候热点消失内存只使用了50MB时，可能在50~200之间一直没法触发自动回收而产生大量垃圾。系统监控程序会检查上次垃圾回收若已经超过2分钟，则强制执行一次垃圾回收，这种方式也不会检查阈值。\n那么自动触发时如何检查阈值是否达到呢？正常想法可能是每次执行malloc(size)函数的时候累加其size并检查一次，这种效率会很低，每次分配都去检查，且这个函数被所有的P/M共享就涉及到需要加锁。Go中采用的优化策略是不在malloc(size)时检查，只有在大对象分配的时候才检查，因为内存分配只有两种情况，要么从操作系统拿回一大块内存来分配给某个大对象，要么拿回一大块内存切成N多小块复用。\n启动 启动的第一步就是开启STW，让所有的P/M进入到一种特殊的状态。其实开启STW之前还要做一件事情，上一个垃圾回收周期的清理工作。然后垃圾回收的相关指令和函数会被打包为一个个worker，进而作为G对象交给调度器执行，垃圾回收代码和用户代码都是G对象从而实现了并发。\nworker worker分为三种，第一种属于正式工，专门做垃圾回收；第二种属于小时工，执行一段时间垃圾回收就释放P/M执行用户逻辑；第三种是临时工，没有用户G的时候，P/M会闲置，就可能有临时工来执行一段时间。如果没有正式工，小时工和临时工随时都可能因为抢占式调度去执行用户代码，可能导致垃圾回收无法结束；如果都是正式工也不行，正式工不会被抢占，用户逻辑可能被饿死；所以有了小时工和临时工，小时工算是辅助正式工来加快垃圾回收的效率，而临时工更不靠谱，只有在P/M闲置时才可能来帮忙。\n这种种措施就是要保证:\n 垃圾回收一定能够完成 垃圾回收尽可能快的完成 垃圾回收不能影响用户代码的执行  controller 在一个垃圾回收的周期内，会有一个controller来收集信息，它会收集完成这个周期花了多少物理时间，花了多少CPU时间，开始和结束的时候堆的大小，使用的正式工、临时工、小时工的数量。通过这些信息，controller就会去推算下一个周期垃圾回收的阈值应升高还是降低，比如nextGC当前是4MB，下一次就应该是8MB，通过controller推算出应该降低10%，那最终触发的阈值就是7.2MB；另外，controller也会去推算多少正式工、临时工、小时工参与是合理的。这些推算都是概率问题，属于局部性原则的一种应用，本次垃圾回收的压力大，那么下次垃圾回收压力大的概率就高一些。这种简单的策略为垃圾回收增加了一些灵活性，比僵化的阈值设定要好一些。\n标记 三色标记 启动之后就要开始执行标记操作，标记有一个基本的规则叫三色标记原则。\n我们把任一段代码编译之后，会发现编译器插入一些例如PCDATA这样的指令，它属于伪指令，是为了在编译时记录对象的相关信息以及一些元数据信息，这些信息可以用来给内存分配器提供参考:当在堆上分配一个对象的时候，除了去分配相应的内存(比如起始位置0x100100)，还会在一个位图中查找到索引0x100100的位置，按照元数据中的类型信息标记出该对象的第几个位置是指针。\n而一个对象要么是从全局变量引用下来，要么是从栈上引用下来，自然就会有根对象，这个根对象就是位图中的指针。垃圾回收的时候就是先去查看位图有没有指针，根据指针一路追踪扫描下去。\n在一次扫描开始时，会认为所有的对象是白色的。根对象一定是活的，那么被它引用的对象也一定是活的，就把它标记为灰色的，并把它的引用放在一个队列中去。接着把这个队列的灰色对象依次拿出来，比如先拿出了灰色的A，看A引用的对象是什么，把A引用的对象重新加到队列中去，并把A标记为黑色。重复执行这个过程，那么最终就只会剩下两种对象，黑色的和白色的，黑色的是活着的，白色的是死掉的。\n写屏障 但还有个问题没有解决，标记的同时用户代码也在执行，如果已经标记为黑色的对象又引用了一个白色对象C怎么办，因为不会对黑色对象进行二次扫描，在最终清理时就会把这个C也误杀掉。为了解决这个问题，在编译期编译器就会对指针写操作的语句插入一段写屏障代码，这段代码会判断如果当前正在垃圾回收，指针的写操作不会立即执行，而是先执行写屏障逻辑。写屏障逻辑会判断这个指针若是黑色的，就把它重新变成灰色的加入队列进行二次扫描。\n具体如何加入写屏障的，我们可以看如下示例: var x *int func main(){ x = new(int) println(x) }\n然后我们编译并反汇编: [ubuntu] ~/.mac $ go tool objdump -s \u0026#34;main\\.main\u0026#34; test TEXT main.main(SB) /root/.mac/test.go test.go:5\t0x452330\t64488b0c25f8ffffff\tMOVQ FS:0xfffffff8, CX test.go:5\t0x452339\t483b6110\tCMPQ 0x10(CX), SP test.go:5\t0x45233d\t766a\tJBE 0x4523a9 test.go:5\t0x45233f\t4883ec18\tSUBQ $0x18, SP test.go:5\t0x452343\t48896c2410\tMOVQ BP, 0x10(SP) test.go:5\t0x452348\t488d6c2410\tLEAQ 0x10(SP), BP test.go:6\t0x45234d\t488d052cbc0000\tLEAQ 0xbc2c(IP), AX test.go:6\t0x452354\t48890424\tMOVQ AX, 0(SP) test.go:6\t0x452358\te8038afbff\tCALL runtime.newobject(SB) test.go:6\t0x45235d\t488b442408\tMOVQ 0x8(SP), AX test.go:6\t0x452362\t833d37dd080000\tCMPL $0x0, runtime.writeBarrier(SB) test.go:6\t0x452369\t7530\tJNE 0x45239b  test.go:6\t0x45236b\t4889058e270700\tMOVQ AX, main.x(SB) test.go:7\t0x452372\te83931fdff\tCALL runtime.printlock(SB) test.go:7\t0x452377\t488b0582270700\tMOVQ main.x(SB), AX test.go:7\t0x45237e\t48890424\tMOVQ AX, 0(SP) test.go:7\t0x452382\te8293afdff\tCALL runtime.printpointer(SB) test.go:7\t0x452387\te8b433fdff\tCALL runtime.printnl(SB) test.go:7\t0x45238c\te89f31fdff\tCALL runtime.printunlock(SB) test.go:8\t0x452391\t488b6c2410\tMOVQ 0x10(SP), BP test.go:8\t0x452396\t4883c418\tADDQ $0x18, SP test.go:8\t0x45239a\tc3\tRET test.go:6\t0x45239b\t488d3d5e270700\tLEAQ main.x(SB), DI test.go:6\t0x4523a2\te8f998ffff\tCALL runtime.gcWriteBarrier(SB) test.go:6\t0x4523a7\tebc9\tJMP 0x452372  test.go:5\t0x4523a9\te8f27affff\tCALL runtime.morestack_noctxt(SB) test.go:5\t0x4523ae\teb80\tJMP main.main(SB)\n我们看到new(int)对应CALL runtime.newobject(SB)，之后通过CMPL $0x0, runtime.writeBarrier(SB)进行比较，比较结果为真则跳转至下面的CALL runtime.gcWriteBarrier(SB)，执行完了再跳转回去继续赋值。\nvar writeBarrier struct { enabled bool // compiler emits a check of this before calling write barrier \tpad [3]byte // compiler uses 32-bit load for \u0026#34;enabled\u0026#34; field \tneeded bool // whether we need a write barrier for current GC phase \tcgo bool // whether we need a write barrier for a cgo check \talignme uint64 // guarantee alignment so that compiler can use a 32 or 64-bit load } 我们通过写屏障的定义也就知道了$0x0是和这里的enabled进行比较的，这种简单的比较对性能的影响是非常小的。\n挣工分 还有一个问题，用户代码中分配对象的速度远大于回收的速度，造成垃圾回收无法结束。这种情况如何处理呢？\n每次分配对象的时候，会去检查若当前正在垃圾回收，则每个G对象都会有一个信用值，分配一个size大小的对象，就把这个信用值减去size，直到这个信用值为负数，则把这个执行一半的G暂停并保存上下文丢回给调度器，其绑定的P/M来帮助进行垃圾回收挣工分，工分挣到一定程度比如3倍的信用值则接着去执行用户代码(这个可能就不会接着之前暂停的G、可能是任意G)。\n但是仅这种挣工分来还债再接着执行用户代码的方式效率可能会很低，因为本身垃圾回收器就有worker，这些worker可能突然执行效率很高，导致来协助挣工分的P/M挣不到，于是就有了一个公用的信用值来存储垃圾回收器中workder挣的工分。所以当公用的信用值还有额度的时候，说明垃圾回收的压力还不大，用户G会先去尝试扣减这个公用信用值，如果不够扣才会去帮助垃圾回收。\n清理 标记完之后如何清理呢？内存是分块的，每个大块下又分了很多小块，每个小块可能代表一个对象。它还有一份元数据，是一个位图，位图和这些内存块一一对应。所谓的回收清理只是标记出在这个位图中哪些块是死了的，告诉内存分配器哪些块是可以合并的等，以便于下一次能直接复用。\n清理操作也是和用户代码并发的，但要清理的这些对象和用户逻辑之间没有任何干扰，互相不影响，相对比较容易。\n总结 在研究垃圾回收器的设计过程中，我们发现整个处理过程是比较复杂的。垃圾回收器的设计中有大量的细节处理是在找平衡，在执行效率和空间占用中找到平衡。\n" }); index.add({ 'id': 12, 'href': '/docs/go/map/', 'title': "字典", 'content': " 字典 现代编程语言，例如Python和Go中都有字典，其作为一种常见数据结构使用频率非常高。一般作为内置类型，解释器或者编译器都会对其特别的照顾，做相当多的优化，它的设计也需要在通用和性能上找到平衡，当然也是我们非常好的学习案例。\n要存储一批数据，我们最先想到的就是用数组，因为它对所有的存储器亲和性是最好的，内存可以看成是一个大的字节数组，CPU cache line也是一个64字节的数组。但数组有个问题，即索引效率低，我们往往是通过排序然后进行二分查找来提高索引的效率。可是如果我们的数据需要频繁的编辑(插入、删除、修改)时，这种排序就可能造成我们需要频繁的对其中的局部进行重排，这时候延伸出了大小堆、树堆等各种各样的结构来解决这些问题。其中有一种数据结构，也就是我们今天要提到的字典(map/dict)，它在各方面效率做到了很好的平衡，它的经典实现方式是hash table，也有很多其它实现方式，但不管是怎样实现的，映射在内存层面仍然是数组，那么它是怎样实现的呢？\n首先，我们不考虑value，仅看key是怎么映射到数组上的。数组通过下标数字访问，不管key是什么类型，我们都需要把它通过哈希函数转换为一个数字，若得到的数字很大超过了数组的长度，我们就可以通过取模(n%len)的方式来得到它在数组中的位置。所以任何一个可哈希的Key我们都能把它映射到数组上的某个位置，那么我们就可以把key-value打包为一个struct放在数组中某个位置，解决了高效的查找和编辑的问题。\n接下来的问题就是哈希碰撞了。当两个key哈希并取模后的结果是相同的数字时，有一个简单的处理方式就是用链表链起来，即链表法，把一个横向的大的数组转化为了多个纵向的小的链表，Go采用的这种方式。另外一种方法就是若发现冲突，则把新的key加上一个magic_number计算得出一个新的位置，横向的填充到这个空位，称为开放寻址法，Python采用这种方式。\n链表法的问题就在于链表的访问效率差，如何优化？当CPU去读取数据时，它会基于空间局部性原则将附近的数据从内存读入L3，然后是L2、L1。那么我们基于这个原则，应当把链表转换为数组，把原有的一个个的item放入一个桶中:\n把每8(或8的倍数)个item当做一个桶，一个桶链接另一个桶。当我们需要根据某个查询条件查询数据的时候，我们可以把整个桶拿出来遍历查找，很可能整个桶是被L1或者L3缓存过的，这个访问效率就可能比在内存中去读取快上百倍。\n那么针对这个桶是否还有优化空间呢？我们发现遍历的时候是去判断它的key是否相等，并不需要知道它的value。按照当前这种结构value就占用了缓存器的空间:\n我们应该尽可能的缓存更多的keys，于是可以把桶分为上下两个部分:\n那么还能进一步优化吗？我们发现keys的数据类型不知道，如果是个整数倒还很容易和查询条件做比较，但若是个字符串，两个字符串的比较效率是非常低的。针对这种情况，我们可以再做一层访问拦截:\n这层数组放入keys的哈希值，只有当某个位置的哈希值和查询条件匹配时，我们才会去进一步比对keys数组中对应位置的key。这样我们就通过一个整数型数组拦截掉了很多的预判。甚至这个整数数组也无需使用int64，我们只取hashcode的高位构成一个int8类型，[8]int8形成一个64位的数组正好能被一个寄存器存下。\n另外这层数组像一个位图，还能用来判断这个桶中还有没有空位，插入数据时先看数组中是否有空位就可以相应的在keys和values中找到空位，删除数据时也不会进行收缩，只是在相应的位置上做标记。\n现在，我们经过一层层的优化，字典变成了这个样子:\n只要哈希算法分布的很平均，那么基础数组越长，桶的链表就越短，访问效率也越高，这就涉及到一个扩容的问题。随着数据的插入，键值对的总个数和基础数组的长度有一个比例，当这个比例达到一个阈值，就会触发扩容操作。扩容时我们不能直接新建个基础数组，然后把原数组数据一次性搬过去，这种方式会导致某次操作的时间过长使应用卡死。而应该在触发时，设定一个标志，之后对这个字典的每次查询、修改、插入、删除都先去检查这个标志，若标志为真且本次操作的数据在旧字典中，则将它及附近的一段数据都迁移至新字典，这叫随机迁移。同时，为防止每次操作都发生在新字典中，其内部还有个计数器，让其迁移时能够从旧字典的头部再顺序迁移一部分数据，也就是顺序迁移。这样就能保证所有的数据都被迁移过去，迁移完成后，旧字典整个被释放掉。\n当删除字典元素时，对于Go这种关注性能的语言，字典的内存不会被压缩，可能会造成内存浪费。如果有大量删除元素的情况，只能新建一个字典，把旧字典的数据手工搬过去，让垃圾回收器回收旧字典。基于这个原因，我们在桶中应该去存储keys和values的内容而不是它们的指针。因为key和value的生命周期是和整个map相同的，不存指针也就意味着减轻了垃圾回收期的压力，原本需要检查回收1(map)+n(keys)+n(values)个对象变为了只需检查1个map对象。所以Go中做了如下设定，如果key和value的长度小于128字节，同时key和value本身不是指针，那么它们会被嵌入到字典内部。\n通过以上，我们了解到任何一个看似简单的东西背后可能都隐藏了复杂的设计。\n" }); })();