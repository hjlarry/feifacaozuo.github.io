'use strict';(function(){const indexCfg={encode:false,tokenize:function(str){return str.replace(/[\x00-\x7F]/g,'').split('');}};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/go/lock/','title':"Lock",'content':"锁的原理 锁是怎么实现的？怎么做到独占的？实际上得从原子操作说起。\n原子操作 原子操作不是说一定要只能一个动作，而是说把它包装成一条指令或者一个函数的时候，它可以保证不会被侵入。在单核CPU上，一条指令肯定是原子的，但不见得一条指令就只做了一个操作，可能是两个操作，比如CAS(Compare\u0026amp;Set或Compare\u0026amp;Swap，X86下对应的是CMPXCHG汇编指令)是比较并交换操作数，这在单核上没有问题，但在多核上如何保证不被打断呢？这就需要硬件来支持了。\n我们在intel IA-64手册中，可以翻到这样一条指令前缀: 按文档描述，把这条前缀加到某些指令前时，它可以实现一个原子操作。在x86体系中，CPU里专门有一条引线叫HLOCK pin，当遇到有LOCK前缀的指令就拉低该引线电位，从而锁住了总线。那么在同一总线上的其他Core就无法通过总线访问内存了。所以原子操作的本质仍然是锁，只是这个锁是硬件层面的。也不存在软件层面上真正意义的无锁操作，底层仍然是锁。\n我们在Go的源码中也能看到大量这样的代码:\n// src/runtime/internal/atomic/asm_amd64.s TEXT runtime∕internal∕atomic·Cas(SB),NOSPLIT,$0-17 MOVQ\tptr+0(FP), BX MOVL\told+8(FP), AX MOVL\tnew+12(FP), CX LOCK CMPXCHGL\tCX, 0(BX) SETEQ\tret+16(FP) RET 随着现在CPU核数逐步增多，这种LOCK前缀锁总线的方式带来的性能问题就凸显了出来，所以现在的体系遇到LOCK前缀时，不是去锁整个总线，而是先检查一下要锁的内容是不是在cache中，如果在的话只锁那一行cacheline，只有同时访问这一个cacheline的其他core才会被锁住，就像数据库的表锁和行锁。这样一来，性能的影响没那么大了，但是原子操作还是会带来性能影响的，只是硬件层面的东西我们作为程序员改变不了什么也就很少去提。\n那么原子操作和我们平时所说的互斥锁有什么区别呢？我们谈原子操作是只针对一个操作，而锁是往往是要包含一段逻辑、一个block的。\n无锁结构 也就是Lock Free，它的做法用伪码来表达是这样的:\nfor { old = atomic.Load() if (atomic.CAS(old, new)){ break } } // CAS 伪码 func compareAndSwap(addr int, old int, new int) bool{ if (*addr != old){ return False } *addr = new return True } 当old通过原子操作读出以后，如果有其他CPU操作修改了这个值，那么atomic.CAS就会发现old变了则修改失败重新循环，反之修改成功退出循环，这就是无锁结构。运气好的话一次就执行完了，运气不好一直被打断的话循环多少次是未知的。它的实际使用场景比如说是一个无锁结构的链表队列，当需要向队列尾部插入元素时，插入不成功则说明有其他线程刚刚插入过，队列尾部的地址已经变了，则需重试。\n这种结构也有个问题，就是ABA的问题。试想一下atomic.Load读出来是A，然后被人修改为了B再修改回A，atomic.CAS就发现不了接着执行自己的逻辑。这样粗看好像也没有什么问题，但CAS只是检查的一个地址，实际情况往往会有其他的逻辑，有人做了一个比喻:你拿着一个装满钱的手提箱在飞机场，此时过来了一个火辣性感的美女，然后她很暖昧地挑逗着你，并趁你不注意的时候，把用一个一模一样的手提箱和你那装满钱的箱子调了个包，然后就离开了，你看到你的手提箱还在那，于是就提着手提箱去赶飞机去了。\n怎么解决ABA的问题呢？可以采用数据库乐观锁的办法，每次进行修改的时候添加一个时间戳或者流水号，上例就是atomic.Load读出来以后就是A20191222，修改为B就变为了B20191223，再进行一次修改就是A20191224了。\n缓存一致性 CPU是不会和内存直接交互的，它和内存之间的读写都是通过L1、L2、L3缓存来做中转。那么如果内存上有个X=1，CPU1和CPU2都把这个X读到自己的缓存上，CPU1这时候对X做了修改让X=3，CPU2又如何知道呢？这就是缓存一致性的问题，需要确保的是任一时刻，缓存的内容是相同的。\n缓存是以行为单位的，也就是cacheline，每行中除了缓存的数据外还包括内存地址和状态。而状态又分为四种，即M、E、S、I。M即modify，表示当前CPU修改过数据，需要以此为准回写到主存中去；E即exclusive，独占，当前的CPU独占了这个数据，和主存中是一致的，其他CPU没有的；S即shared，共享，各个CPU都有这行数据，且是和主存一致的；I即invalid，表示失效的，CPU发现是这个状态就意味着需要从主存里重新去拿一下。\n当CPU2要去写某一行数据的时候，它就会向总线发出一个请求: CPU2要独占某一段地址。CPU1、CPU3、CPU4一直都在嗅探总线去接收总线的通知，然后去检查自己的缓存中有没有这行数据，如果CPU3有且这行状态是共享的，那就把CPU3的这行变为失效状态；但如果CPU1那行已经是独占的，这个CPU2就得等，等到CPU1修改完数据回写到主存当中会解除CPU1的独占状态，CPU2重新从主存刷新自己的缓存再把它修改为独占状态。修改了数据就需要改为modify，因为需要一批数据一同刷入主存。\n这种通过四种状态保证缓存一致性的方式和我们日常见到的锁的原理差不多，数据库修改某行的时候也是加行锁，其他人要修改该行就得排队，要修改其他行就不受影响。\nGo语言中的锁 Futex 锁的本质是通过某种操作实现休眠、唤醒等操作，那它就一定要由操作系统来实现，由OS实现才能避免对于休眠的单位不去分配时间片。那么锁就需要进行系统调用，它的效率就会非常低？Linux在很早期的版本就提供了一种锁Futex，虽然是由操作系统提供的，但它是在用户空间实现的，是一种特殊的系统调用，大部分情况下不需要进入内核空间，避免了通常的系统调用所需的用户态内核态之间的切换。Futex其实就是一块内存空间，通常是一个整型变量，大家通过原子操作对它做修改，要么就修改成功执行逻辑，要么就修改失败等待它。\nLinux手册中提供了这种锁的调用方式，包括锁定、等待、唤醒等参数。Go中调用其API:\n// src/runtime/os_linux.go  func futex(addr unsafe.Pointer, op int32, val uint32, ts, addr2 unsafe.Pointer, val3 uint32) int32 // Linux futex. // //\tfutexsleep(uint32 *addr, uint32 val) //\tfutexwakeup(uint32 *addr) // // Futexsleep atomically checks if *addr == val and if so, sleeps on addr. // Futexwakeup wakes up threads sleeping on addr. // Futexsleep is allowed to wake up spuriously.  func futexsleep(addr *uint32, val uint32, ns int64) { if ns \u0026lt; 0 { futex(unsafe.Pointer(addr), _FUTEX_WAIT_PRIVATE, val, nil, nil, 0) return } var ts timespec ts.setNsec(ns) futex(unsafe.Pointer(addr), _FUTEX_WAIT_PRIVATE, val, unsafe.Pointer(\u0026amp;ts), nil, 0) } func futexwakeup(addr *uint32, cnt uint32) { ret := futex(unsafe.Pointer(addr), _FUTEX_WAKE_PRIVATE, cnt, nil, nil, 0) if ret \u0026gt;= 0 { return } systemstack(func() { print(\u0026#34;futexwakeup addr=\u0026#34;, addr, \u0026#34; returned \u0026#34;, ret, \u0026#34;\\n\u0026#34;) }) *(*int32)(unsafe.Pointer(uintptr(0x1006))) = 0x1006 } 有了API，并不能直接用，还要对其进行包装:\n// src/runtime/lock_futex.go  func lock(l *mutex) { gp := getg() if gp.m.locks \u0026lt; 0 { throw(\u0026#34;runtime·lock: lock count\u0026#34;) } gp.m.locks++ // 尝试原子操作修改l.key的值为锁定状态 \tv := atomic.Xchg(key32(\u0026amp;l.key), mutex_locked) if v == mutex_unlocked { return } // 尝试失败则进入自旋状态 \twait := v spin := 0 if ncpu \u0026gt; 1 { spin = active_spin } for { // 每自旋一次尝试拿一次锁 \tfor i := 0; i \u0026lt; spin; i++ { for l.key == mutex_unlocked { if atomic.Cas(key32(\u0026amp;l.key), mutex_unlocked, wait) { return } } procyield(active_spin_cnt) } // 在rescheduling状态进行尝试拿锁 \tfor i := 0; i \u0026lt; passive_spin; i++ { for l.key == mutex_unlocked { if atomic.Cas(key32(\u0026amp;l.key), mutex_unlocked, wait) { return } } osyield() } // 尝试进入睡眠状态 \tv = atomic.Xchg(key32(\u0026amp;l.key), mutex_sleeping) if v == mutex_unlocked { return } // 进入futex睡眠状态 \twait = mutex_sleeping futexsleep(key32(\u0026amp;l.key), mutex_sleeping, -1) } } func unlock(l *mutex) { v := atomic.Xchg(key32(\u0026amp;l.key), mutex_unlocked) if v == mutex_unlocked { throw(\u0026#34;unlock of unlocked lock\u0026#34;) } // futex唤醒操作 \tif v == mutex_sleeping { futexwakeup(key32(\u0026amp;l.key), 1) } gp := getg() gp.m.locks-- if gp.m.locks \u0026lt; 0 { throw(\u0026#34;runtime·unlock: lock count\u0026#34;) } if gp.m.locks == 0 \u0026amp;\u0026amp; gp.preempt { gp.stackguard0 = stackPreempt } } 其一开始尝试拿锁属于投机，先以最乐观的情况考虑，如果没人竞争就能直接拿到锁，这种概率并不低，我们自己做性能设计时也可以参考它先设计乐观的情况。尝试失败则进入自旋状态，自旋状态打个比方，就是你在火车上上厕所，发现厕所有人，你在外面焦急的转圈等待；它是次一级的理想状态，因为厕所的人出来你马上就能进去，若是回到座位上可能被人插队；procyield(active_spin_cnt)背后会调用一个专门的CPU指令PAUSE，它可以降低自旋状态时CPU的功耗并进入一个短暂的等待。自旋时没拿到锁则进入另一个状态，相当于回到座位上但是盯着厕所的门，这个状态下执行的osyield()是操作系统提供的等待，这种等待的时长就比CPU指令长很多，同时涉及到状态切换开销也会大很多。这种积极的尝试如果仍然失败，则进入睡眠状态，等待厕所里面的人出来唤醒它，唤醒后重新进入这个循环。\n尽管做了这样的包装，这种锁仍然属于较低层次的，一般不会给用户直接用。\nSema 信号量，可以控制同时执行的数量，如果数量是1就相当于互斥锁，如果都在执行了再进来人就得排队。\n首先，它的结构是这样的: // src/runtime/sema.go type semaRoot struct { lock mutex treap *sudog // root of balanced tree of unique waiters. \tnwait uint32 // Number of waiters. Read w/o the lock. }\nlock 就是之前设计的那种锁，在这之上提供了一个treap这样的平衡树结构，它是等待人(G对象)的列表，还有nwait计数器存储等待人的数量。\n它的核心获取锁的逻辑: func semacquire1(addr *uint32, lifo bool, profile semaProfileFlags, skipframes int) { //简单的情况，即直接成功获取锁 \tif cansemacquire(addr) { return } ... // 复杂的情况:  // 1.增加等待者计数；  // 2.再尝试一次获取锁，成功则返回；  // 3.将自己enqueue waiter；  // 4.睡眠 \tfor { lock(\u0026amp;root.lock) atomic.Xadd(\u0026amp;root.nwait, 1) if cansemacquire(addr) { atomic.Xadd(\u0026amp;root.nwait, -1) unlock(\u0026amp;root.lock) break } root.queue(addr, s, lifo) goparkunlock(\u0026amp;root.lock, waitReasonSemacquire, traceEvGoBlockSync, 4+skipframes) if s.ticket != 0 || cansemacquire(addr) { break } } if s.releasetime \u0026gt; 0 { blockevent(s.releasetime-t0, 3+skipframes) } releaseSudog(s) } func cansemacquire(addr *uint32) bool { for { v := atomic.Load(addr) if v == 0 { return false } if atomic.Cas(addr, v, v-1) { return true } } } 首先尝试去锁定，并给等待者的数量加上1，然后通过cansemacquire检查一下能不能获得这把锁，能获得则减1退出循环。不能获得则加入到队列中，goparkunlock休眠。信号量归根结底是用原子操作来维护某个地址上的信号量加减，用一个锁来维护一个等待者计数器，这里的\u0026amp;root.lock是为了保护对计数器的操作和入队的操作。\n接着我们看看释放: func semrelease1(addr *uint32, handoff bool, skipframes int) { root := semroot(addr) atomic.Xadd(addr, 1) // 简单的情况：没有等待者 \tif atomic.Load(\u0026amp;root.nwait) == 0 { return } // 复杂的情况：找到一个等待者并唤醒它 \tlock(\u0026amp;root.lock) if atomic.Load(\u0026amp;root.nwait) == 0 { unlock(\u0026amp;root.lock) return } s, t0 := root.dequeue(addr) if s != nil { atomic.Xadd(\u0026amp;root.nwait, -1) } unlock(\u0026amp;root.lock) if s != nil { // May be slow or even yield, so unlock first \tacquiretime := s.acquiretime if acquiretime != 0 { mutexevent(t0-acquiretime, 3+skipframes) } if s.ticket != 0 { throw(\u0026#34;corrupted semaphore ticket\u0026#34;) } if handoff \u0026amp;\u0026amp; cansemacquire(addr) { s.ticket = 1 } readyWithTime(s, 5+skipframes) if s.ticket == 1 \u0026amp;\u0026amp; getg().m.locks == 0 { goyield() } } }\n首先，释放必然使地址上的信号量加1。其次，去查看是否有人等，没人等则直接退出；如果有人等，则从队列中dequeue一个等待者、计数器减一，等待者可能是按地址排序的，但这属于其内部实现，我们没法确定弹出的是谁。最后如果传入的handoff为true表示要进行权限转移，会给这个弹出的等待者发一张票，之前semacquire1的for循环中goparkunlock休眠后被唤醒的第一件事就是检查有没有拿到票，拿到了则可以短路出去，没必要再走一次for循环和别人竞争抢锁\u0026amp;root.lock。\n信号量结合了它的特征，在一些短路的设计上值得我们学习。它仍然是runtime层面的，还不是交给用户去使用的。\nMutex 给用户使用的锁在标准库中，我们来看看它的实现: // src/sync/mutex.go type Mutex struct { state int32 sema uint32 } const ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked \tmutexWoken mutexStarving mutexWaiterShift = iota )\nMutex结构包括一个状态和一个计数，这个状态分为四种，即锁定、唤醒(这里可以理解为自旋)、饥饿、等待者转移。怎样会出现饥饿状态呢？比如A、B竞争一把锁的时候，A拿到了，B经过不断尝试最终进入了睡眠状态，A释放锁的时候又有C去竞争锁，C此时可能处于自旋状态，同理C后面可能还有D、E，B就一直拿不到锁处于饥饿状态。这种状态在并发编程中并不少见。\n接着我们看看其锁定的过程: func (m *Mutex) Lock() { // 进入快速路径，乐观状态，没有竞争 \tif atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // 进入慢速方式 \tm.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 starving := false awoke := false iter := 0 old := m.state for { // 依然通过循环处理  // 判断没有人处于饥饿状态，且还有可自旋次数，则进入自旋状态去尝试拿这把锁 \tif old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) { if !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state // 拿到锁则是mutexLocked状态，接着向下走；没拿到重新看可自旋次数。 \tcontinue } // 从这开始就有两种可能，要么拿到锁了，要么自旋次数用完了 \tnew := old // 接着主要做一些状态变更和处理 \tif old\u0026amp;mutexStarving == 0 { new |= mutexLocked } if old\u0026amp;(mutexLocked|mutexStarving) != 0 { new += 1 \u0026lt;\u0026lt; mutexWaiterShift } if starving \u0026amp;\u0026amp; old\u0026amp;mutexLocked != 0 { new |= mutexStarving } if awoke { if new\u0026amp;mutexWoken == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } new \u0026amp;^= mutexWoken } if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { // 没人上锁且没有饥饿状态的，则可以拿到锁跳出整个循环 \tif old\u0026amp;(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS \t} // 如果我之前已经在等待了，则排在队列的最前面 \tqueueLifo := waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } runtime_SemacquireMutex(\u0026amp;m.sema, queueLifo, 1) // 判断时间是不是超出了饥饿状态的时间阈值 \tstarving = starving || runtime_nanotime()-waitStartTime \u0026gt; starvationThresholdNs old = m.state // 如果我自己就是饥饿的，那么我拿到锁，做相关状态修改，退出循环 \tif old\u0026amp;mutexStarving != 0 { if old\u0026amp;(mutexLocked|mutexWoken) != 0 || old\u0026gt;\u0026gt;mutexWaiterShift == 0 { throw(\u0026#34;sync: inconsistent mutex state\u0026#34;) } delta := int32(mutexLocked - 1\u0026lt;\u0026lt;mutexWaiterShift) if !starving || old\u0026gt;\u0026gt;mutexWaiterShift == 1 { delta -= mutexStarving } atomic.AddInt32(\u0026amp;m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } if race.Enabled { race.Acquire(unsafe.Pointer(m)) } }\n总结 我们从原子操作到Mutex，经历了四个层次的包装，每层包装面向不同的目的去解决不同的问题。在做发动机的时候，我们考虑的是动力、性能、省油，但拿它做飞机引擎还是做汽车引擎就要做不同的包装。我们平时做设计的时候往往也需要层进式的考虑问题，不要总是想着一步到位。\n"});index.add({'id':1,'href':'/docs/other/docker/','title':"Docker",'content':"Docker概要 镜像 操作系统分为内核空间和用户空间。对于Linux，内核启动后，会挂载root文件系统为其提供用户空间支持。而Docker中的镜像(Image)，就相当于是一个root文件系统，只是它有些特殊，除了提供容器运行时所需的程序、库、资源、配置等文件外，还会包含一些为运行时准备的配置参数(如匿名卷、环境变量、用户等)。镜像不包含任何动态数据，其内容在构建之后不会改变。\nDocker使用Union FS技术，将镜像设计为分层存储的架构。构建时，会一层层构建，前一层是后一层的基础，每层构建完就不会改变，后一层的任何改变只是发生在自己这一层。例如，删除前一层的文件并不是真正的删除，而只是在本层中标记上一层的文件是删除的。\n获取镜像 使用如下命令可以从镜像仓库中拉取镜像:\ndocker pull [选项] [镜像仓库的地址[:端口号]/]仓库名[:标签] 镜像仓库的地址默认为Docker Hub的地址，对于Docker Hub，仓库名默认为library，所以我们往往可以简写为docker pull ubuntu:18.04。\n列出镜像 我们可以这样列出全部的镜像: PS C:\\Users\\hejl\u0026gt; docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE hjlarry/cheers2019 latest f0c36061dc59 3 hours ago 4.01MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 1487cd0b23aa 3 hours ago 356MB ubuntu 18.04 ccc6e87d482b 4 days ago 64.2MB ubuntu latest ccc6e87d482b 4 days ago 64.2MB golang 1.11-alpine e116d2efa2ab 5 months ago 312MB gcr.azk8s.cn/google_containers/hyperkube-amd64 v1.9.2 583687acb4de 2 years ago 618MB 我们可以看到镜像ID是镜像的唯一标识，但标签可以有多个，例如ubuntu的18.04和latest是同一个镜像。\n镜像的体积可能会比Docker Hub中显示的要大一些，因为Docker Hub进行了一定的压缩。实际这些镜像占用的总空间也不是把他们加起来就能算出来，因为共同的层可以复用。镜像占用的总大小可以通过docker system df看到。\n有一种特殊的镜像，镜像名和标签均为，被称为虚悬镜像(dangling image)。它们没有什么用，可以通过docker image prune一键删除。\n还有一种镜像叫中间层镜像，用来加速构建、重复利用资源，有的中间层镜像也没有标签和名称，它们不能被删除。可以通过docker image ls -a观察到包含中间层镜像的所有镜像。\n删除镜像 使用docker image rm \u0026lt;镜像1\u0026gt; [\u0026lt;镜像2\u0026gt; ...]命令可删除镜像。这里既可以用镜像的名称，也就是\u0026lt;仓库名\u0026gt;:\u0026lt;标签\u0026gt;来表示镜像；也可以用镜像的ID，一般取前3位，足以区分出别的镜像即可。\n在删除镜像时，我们往往会看到删除信息中既有Untagged，也有Deleted。Untagged实际上是因为我们要删除的是某个tag标签下的镜像，需要去取消标签。\n可以使用多个命令配合来批量删除一些镜像，例如docker image rm $(docker image ls -q redis)可以删除所有仓库名为redis的镜像，docker image rm $(docker image ls -q -f before=mongo:3.2)可以删除所有mongo版本3.2之前的镜像。\n定制镜像 镜像的定制实际上就是定制每层所添加的配置和文件，我们可以把每一层的修改、安装、构建、操作的命令都写入一个Dockerfile，通过它来构建、定制镜像。\nFROM 用来指定基础镜像。定制镜像一定是以一个镜像为基础，在其上进行定制，FROM是必备的且必须是第一条指令。\n我们一般可以用一些服务类的镜像作为基础镜像，例如nginx、redis、python、golang等，也可以使用更为基础的操作系统镜像，如ubuntu、centos、alpine等。还以为用scratch作为基础镜像，它表示一个空白的镜像，接下来所写的指令为镜像的第一层，因为有一些静态编译的程序并不需要操作系统提供运行时支持。\nRUN 用来执行命令行命令的，可以像shell脚本一样使用，但我们不应该把每个命令都去对应一个RUN，例如: FROMdebian:stretchRUN apt-get updateRUN apt-get install -y gcc libc6-dev make wgetRUN wget -O redis.tar.gz \u0026#34;http://download.redis.io/releases/redis-5.0.3.tar.gz\u0026#34;RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install 这样构建的镜像非常臃肿，添加了很多运行时不需要的东西，增加了构建部署的时间，也容易出错。应该这样写: FROMdebian:stretchRUN buildDeps=\u0026#39;gcc libc6-dev make wget\u0026#39; \\  \u0026amp;\u0026amp; apt-get update \\  \u0026amp;\u0026amp; apt-get install -y $buildDeps \\  \u0026amp;\u0026amp; wget -O redis.tar.gz \u0026#34;http://download.redis.io/releases/redis-5.0.3.tar.gz\u0026#34; \\  \u0026amp;\u0026amp; mkdir -p /usr/src/redis \\  \u0026amp;\u0026amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\  \u0026amp;\u0026amp; make -C /usr/src/redis \\  \u0026amp;\u0026amp; make -C /usr/src/redis install \\  \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* \\  \u0026amp;\u0026amp; rm redis.tar.gz \\  \u0026amp;\u0026amp; rm -r /usr/src/redis \\  \u0026amp;\u0026amp; apt-get purge -y --auto-remove $buildDeps 所有的命令都是一个目的，即编译、安装redis可执行文件，没必要多层。此外，这组命令的最后添加了清理工作的命令，删除为了编译构建所需的文件，清理了所有下载、展开的文件，还清理了apt的缓存文件。镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。\nCOPY 该指令从构建上下文的目录中复制文件到镜像内的目标路径位置，源路径可以是多个，也可以用通配符，通配符规则是Go的filepath.Match规则。还可以通过添加--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;选项来改变文件的所属用户和组。例如:\nCOPY hom* /mydir/ COPY hom?.txt /mydir/ COPY --chown=55:mygroup files* /mydir/ COPY --chown=bin files* /mydir/ ADD 该命令和COPY的格式和性质基本一致，按最佳实践，COPY的语义更加明确应尽可能的使用，尽在需要自动解压缩的场合使用ADD。\nCMD 因为容器是进程，那么在启动容器的时候，就需要指定所运行的程序及参数，CMD就用来指定默认的容器主进程的启动命令。比如，ubuntu镜像的CMD设置的是/bin/bash，所以我们运行容器docker run -it ubuntu会进入到bash，但当我们使用docker run -it ubuntu cat /etc/os-release运行容器时就用cat /etc/os-release替换掉了/bin/bash命令。\n该指令既支持shell格式，CMD \u0026lt;命令\u0026gt;，也支持exec格式，CMD [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;...]。但是shell格式会被包装一个sh -c的参数。例如CMD echo $HOME在实际的执行时会被替换为CMD [ \u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;echo $HOME\u0026quot; ]。\n另外，docker中的应用都是以前台执行的，而不是像虚拟机、物理机那样，可以用systemd去启动一个后台服务，容器内没有后台服务的概念。类似于CMD service nginx start会发现容器执行后就立即退出了，甚至systemctl命令结果却根本执行不了，因为容器就是为了主进程而存在的，主进程退出容器就没有存在的意义也会退出，这条命令会被翻译为CMD [ \u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;service nginx start\u0026quot;]，sh是主进程，当service nginx start命令结束后，sh就结束了，主进程退出自然容器就会退出。正确的做法是直接执行nginx可执行文件并以前台形式运行，如CMD [\u0026quot;nginx\u0026quot;, \u0026quot;-g\u0026quot;, \u0026quot;daemon off;\u0026quot;]。\nENV 用来设置环境变量，设置后无论是之后的指令，还是运行时的应用都可以直接使用定义的环境变量。支持格式:\n ENV  ENV ==\u0026hellip;  例如: ENV VERSION=1.0 DEBUG=on NAME=\u0026#34;Happy Feet\u0026#34;RUN curl -SLO \u0026#34;https://nodejs.org/dist/v$VERSION/node-v$NAME-linux-x64.tar.xz\u0026#34;\nARG 和ENV类似，也是设置环境变量，只是它在容器运行时不会存在这些环境变量。\nVOLUME 因为容器的运行应保持容器存储层不发生写操作，那么对于数据库类需要动态保存数据的应用，其数据库文件应保存于卷(volume)中。该指令用于挂载一个目录为匿名卷，如果容器运行时用户未指定匿名卷，就会用它做匿名卷，向其写入数据即可避免向容器存储层写入大量数据；如果用户指定，则会覆盖掉这个指令中的设置。\n其格式为VOLUME \u0026lt;路径\u0026gt;或VOLUME [\u0026quot;\u0026lt;路径1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;路径2\u0026gt;\u0026quot;...]。用户指定命名卷可以这样写docker run -d -v mydata:/data xxxx，即把mydata这个命名卷挂载到了/data位置，会替代Dockerfile中定义的匿名卷挂载配置。\nEXPOSE 只是一个声明，容器运行时提供的服务端口。容器不会因为这个声明就自动开启这个端口的服务，只是帮助镜像使用者理解，或是使用docker run -P做随机端口映射时可自动映射到该指令设置的端口。\nWORKDIR 使用该指令可以指定当前目录(或者称为工作目录)，以后各层的当前目录就被设置为它，如该目录不存在则会自动创建该目录。\n比如我们可能会这样写: RUN cd /appRUN echo \u0026#34;hello\u0026#34; \u0026gt; world.txt\n这样构建运行后，会发现找不到/app/world.txt这个文件，因为两个RUN代表两层，它们的执行环境不同，运行到第二层时启动的是一个全新的容器。这个时候就应该用WORKDIR指令进行设置。\nUSER 使用该指令可以切换到指定的用户，其后的每一层执行RUN、CMD以及ENTRYPOINT之类命令都会是这个新的身份。这个用户必须是事先建立好的。\n构建镜像 使用docker build [选项] \u0026lt;上下文路径/URL/-\u0026gt;命令可进行镜像构建。\n上下文 我们经常使用docker build .，往往会理解为.表示当前目录，下意识的认为这是dockerfile的所在路径，但这么理解是不准确的，实际上这是在指定上下文路径。\n那么什么是上下文呢？Docker在运行时分为服务端守护进程和客户端工具，我们输入docker相关命令都是客户端操作，通过Docker Remote API与服务端docker引擎交互。当我们进行镜像构建时，就是通过docker build在服务端进行构建，上下文路径中的内容会被发送过去，这个.就是在指定上下文路径，这样当在dockerfile中遇到文件复制这样的语句，例如COPY ./package.json /app/时并不是要复制dockerfile下的package.json，而是去复制上下文路径下的package.json。所以类似COPY ../package.json /app/或者COPY /opt/*** /app都超出了上下文路径而无效，如果需要它们的话就得把它们复制到上下文目录中去。\ndockerfile一般放在一个空目录或项目的根目录下，如果有东西不希望发送给docker引擎，可以使用.dockerignore剔除掉。默认情况下，会将上下文目录下的名为Dockerfile的文件作为Dockerfile，实际上可以通过如-f ../Dockerfile.php指定某个文件为Dockerfile。\n其他构建方式 还可以直接使用git repo的方式构建: PS C:\\Users\\hejl\u0026gt; docker build https://github.com/twang2218/gitlab-ce-zh.git#:11.1 Sending build context to Docker daemon 6.144kB Step 1/23 : FROM gitlab/gitlab-ce:11.1.4-ce.0 as builder 11.1.4-ce.0: Pulling from gitlab/gitlab-ce 8ee29e426c26: Pull complete 6e83b260b73b: Pull complete e26b65fd1143: Pull complete ... 该命令指定了构建所需的git repo，指定了默认的master分支，构建目录为/11.1/，然后docker会自己去clone项目切换到指定分支，并进入指定目录进行构建。\n也可以通过tar压缩包构建，例如docker build http://url/context.tar.gz，会去下载tar压缩包并自动解压缩，以其为上下文，开始构建。\n容器 镜像是静态的定义，而容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。\n容器的实质是进程，但与直接在宿主执行的进程是不同的，容器进程运行于属于自己独立的命名空间，有自己的root文件系统、网络配置、进程空间、用户ID空间等，也就是它是一个隔离的环境。\n每个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层用于容器运行时读写，该存储层的生命周期和容器是一样的。容器存储层应保持无状态化，所有对文件的写入操作都应该使用数据卷或绑定宿主目录，在这些位置的读写就会跳过容器存储层，直接对宿主发生读写，其性能和稳定性更高。\n创建容器 使用docker create \u0026lt;image\u0026gt;可以基于镜像创建一个容器，创建后其处于停止状态，需要用启动命令启动。 PS C:\\Windows\\system32\u0026gt; docker create -it ubuntu:latest 1179ee64f25b6ddbe95e916c4b888ff4d05878ebabd77c94658c9cbc8686b360 PS C:\\Windows\\system32\u0026gt; docker start -i 117 root@1179ee64f25b:/# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var\n启动容器 使用docker start \u0026lt;container_id/container_name\u0026gt;可以将一个终止状态的容器启动运行。 PS C:\\Windows\\system32\u0026gt; docker container start -i f8b root@f8be09e399ae:/# ps PID TTY TIME CMD 1 pts/0 00:00:00 bash 10 pts/0 00:00:00 ps root@f8be09e399ae:/# exit exit 使用ps或top可以查看进程信息，说明容器中仅运行了默认的bash应用。\n新建并启动 使用docker run命令，相当于docker create+docker start，例如: PS C:\\Users\\hejl\u0026gt; docker run -i -t ubuntu:latest root@f8be09e399ae:/# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var\n-t选项让docker分配一个伪终端来绑定到容器的标准输入上，-i选项让容器的标准输入保持打开。\n当执行docker run时，Docker后台实际上运行了这些操作:\n 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个ip地址给容器 执行用户指定的应用程序 执行完毕后容器被终止  后台运行 很多时候，需要让Docker在后台运行而不是直接把执行命令的结果输出在当前宿主机上，此时可以通过添加-d参数来实现。docker run和docker create命令都可以使用该参数。\n但容器是否会长久运行，只取决于docker run到底跑了什么进程，和-d参数无关。如: PS C:\\Users\\hejl\u0026gt; docker run -d ubuntu:18.04 /bin/sh -c \u0026#34;while true; do echo hello world; sleep 1; done\u0026#34; 6ec4042f4d06f94a46aadebe8d05f33d9916985b19bae6d8d63ed867d89b3714 PS C:\\Users\\hejl\u0026gt; docker logs 6ec hello world hello world hello world ... 使用docker logs可以看到某后台运行的容器的输出信息。\n查看所有容器 使用docker ps可以看到正在运行的容器，docker ps -a会看到包括终止状态的容器，它和docker container ls -a等价。\n进入容器 对于后台运行的容器，有时需要进入容器进行操作，可以使用docker exec或docker attach命令，但attach进入后如果输入exit退出容器会导致容器状态停止，所以更推荐exec的方式。 PS C:\\Users\\hejl\u0026gt; docker exec -it 6f8 bash root@6f8a756d46fe:/# ls bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@6f8a756d46fe:/# exit exit PS C:\\Users\\hejl\u0026gt; docker attach 6f8 root@6f8a756d46fe:/# \n终止和删除 使用docker stop \u0026lt;container_id/container_name\u0026gt;可停止运行中的容器。\n使用docker rm \u0026lt;container_id/container_name\u0026gt;可删除，添加-f参数会强制删除即使该容器正在运行。\n使用docker container prune可以清理掉所有处于终止状态的容器。\n数据管理 在docker内部及容器之间管理数据主要有两种方式，即通过数据卷和挂载主机目录。\n数据卷 数据卷是一个特殊的目录，它会绕过Union FS，提供一些有用的特性:\n 可以在容器之间共享和重用 对数据卷的修改会立即生效 对数据卷的更新不会影响镜像 数据卷一直存在，即使容器被删除  可以通过docker volume create my-vol创建一个数据卷，然后使用docker run -it -v my-vol:/webapp ubuntu来将创建的数据卷挂载到容器中，可同时挂载多个数据卷。\n挂载主机目录 也可以直接将本地主机的一个目录挂载在容器中，本地目录必须是一个绝对路径，挂载后默认是可读写权限，可在挂载时设置为只读。例docker run -it -v C:\\Users\\hejl:/mytt:ro ubuntu。\n网络 启动容器时如果不指定参数，则在容器外部无法通过网络来访问容器内的网络应用和服务。\n可以使用-P参数，大写P使得Docker会随机映射一个49000~49900的端口作为容器的开放网络端口。\n也可通过-p小写p指定端口，如docker run -p 5000:5000 -p 3000:80 ubuntu。\nDocker Compose Compose的定位是定义和运行多个Docker容器的应用，其中有两个重要的概念:\n 服务(service): 一个应用的容器，实际上可以包括若干运行相同镜像的容器实力。 项目(project): 由一组关联的应用容器组成的一个完整业务单元, 在docker-compose.yml文件中定义。  主要命令 对于Compose来说，大部分命令的对象既可以是项目本身，也可以是项目中的服务，如不特别说明，命令的对象就是项目，也就是说项目中的所有服务都会受到命令的影响。\nbuild 用于构建或重新构建项目中的服务容器。\n服务容器一旦构建后，将会带上一个标记名，例如对于web项目中的一个db容器，可能是web_db。\n有一些额外选项:\n \u0026ndash;force-rm，删除构建过程中的临时容器 \u0026ndash;no-cache，构建镜像过程中不使用缓存 \u0026ndash;pull，始终尝试通过pull来获取更新版本的镜像  config 验证docker-compose.yml文件中的格式是否正确，如果正确会显示配置，错误则显示错误原因。\nexec 进入指定的容器，容器必须是运行状态的。例如docker-compose exec web sh\nrun 用于在指定服务上运行一个命令。\n类似于启动容器后运行指定的命令，相关的卷、链接等也会按照配置自动创建，如果存在关联的服务则关联的服务也会自动启动。但指定命令会覆盖掉原有的自动运行的命令，且不会自动创建端口以免冲突。\n额外选项:\n -d，后台运行容器 \u0026ndash;no-deps，不自动启动关联的容器 -e KEY=VAL，设置环境变量 \u0026ndash;rm，运行命令后自动删除容器 \u0026ndash;service-ports，配置服务端口并映射到本地主机  例如: docker-compose run --no-deps web python manage.py shell\nup 它将尝试自动完成包括构建镜像、(重新)创建服务，启动服务，并关联服务相关容器的一系列操作。大部分时候可以通过该命令来启动一个项目。\n默认情况下，启动的容器都在前台，会输出容器的输出信息便于调试。生产环境下建议后台启动。\n额外选项:\n -d，后台运行容器 \u0026ndash;no-deps，不启动服务链接的容器 \u0026ndash;force-recreate，强制重新创建容器 \u0026ndash;no-create，如果容器已经存在了，则不重新创建 -t，停止容器时的超时  模板文件 默认的文件名称为docker-compose.yml，下面主要介绍核心指令的含义。\n每个服务都必须通过image指令或build指令来自动构建生成镜像，如果使用build，Dockerfile中设置的选项(如CMD、EXPOSE、VOLUME、ENV)将会自动被获取，无需在模板文件中重复设置。\nbuild 指定Dockerfile所在文件夹的路径，可以是绝对路径或是相对于docker-compose.yml文件的相对路径。如: version: \u0026#39;3\u0026#39; services: webapp: build: ./dir\n也可以使用context指令指定Dockerfile所在的文件夹路径，使用dockerfile指令指定Dockerfile的文件名，使用arg指令指定构建镜像时的变量。如： version: \u0026#39;3\u0026#39; services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1\ncommand 会覆盖掉容器启动后默认执行的命令。例如: version: \u0026#34;3\u0026#34; services: db: image: mysql:8.0 command: - --character-set-server=utf8mb4 没有command时只启动mysqld，加上以后变为mysqld --character-set-server=utf8mb4\ndepends_on 解决容器之间的依赖、启动先后问题。\nenvironment 设置环境变量，可以使用如下两种格式: environment: RACK_ENV: development SESSION_SECRET: environment: - RACK_ENV=development - SESSION_SECRET 在这里设置的环境变量，不能用于容器的构建过程中，只能在容器运行以后才能获取到。例如若dockerfie中有一层是RUN flask db migrate，则它无法获取到docker-compose.yml中设置的数据库连接的环境变量。正确的方法是dockerfile中没有这一层，而是通过docker-compose run --rm web flask db migrate来达到目的。\nexpose 暴漏端口，但不映射到宿主机，只有被连接的服务能通过该端口访问。\nimage 指定为镜像名称或镜像ID，如果镜像在本地不存在，将会尝试拉取这个镜像。\n"});index.add({'id':2,'href':'/docs/python/descriptor/','title':"Descriptor",'content':"待写 "});index.add({'id':3,'href':'/docs/python/interpreter/','title':"Interpreter",'content':"CPython解释器 字节码 Python中的字节码并不能被CPU执行，而是由栈式虚拟机执行，每条指令的背后都对应了一大堆C实现的机器指令。\n字节码被存储在代码对象(即__code__)的co_code中，以一个函数为例: \u0026gt;\u0026gt;\u0026gt; def add(x, y): ... z = x + y ... return z \u0026gt;\u0026gt;\u0026gt; \u0026#34; \u0026#34;.join(str(b) for b in add.__code__.co_code) \u0026#39;124 0 124 1 23 0 125 2 124 2 83 0\u0026#39; 字节码中每两个数字为一组，第一个为指令，第二个为参数，指令对应的二进制数可以在CPython源码中找到: \u0026lt;!-- cpython/Include/opcode.h --\u0026gt; #define BINARY_ADD 23 #define RETURN_VALUE 83 #define LOAD_FAST 124 #define STORE_FAST 125 这就可以和dis的输出结果对应起来: \u0026gt;\u0026gt;\u0026gt; dis.dis(add) \u0026lt;!-- 源码行 偏移量 指令 参数(目标对象) --\u0026gt; 2 0 LOAD_FAST 0 (x) 2 LOAD_FAST 1 (y) 4 BINARY_ADD 6 STORE_FAST 2 (z) 3 8 LOAD_FAST 2 (z) 10 RETURN_VALUE 指令所对应的源码行这个信息其实保存在代码对象的两个相关属性中，co_firstlineno用来存储该段代码起始的行号，co_lnotab由每两个数字一组组成，前一个为字节码偏移的位置，后一个为相对前一组行号的增量。每条字节码指令代表的意义可通过官方文档此处查询到。\nGIL 全局解释器锁机制使得解释器在同一时刻仅有一个线程可以被调度执行，某个线程若想要执行，就先要拿到GIL，但在每个Python进程中，只有一个GIL。它的存在使得解释器本身的实现更简单一些，更容易实现对象的安全访问，便于进行内存管理和编写扩展。但在多核环境下无法实现并行，对于以多线程为基础的并发应用就是一个灾难。\n对于IO密集型任务，线程是在发生阻塞时主动释放GIL的，让其他线程得以执行。而对于CPU密集型任务，采取超时策略。\n当GIL被其他线程占用时，等待线程会阻塞一段时间。如果超时（默认为0.005秒）后，依然无法获取锁，则发出请求。这种请求设计的很轻巧，就是一个全局条件变量设置。正在执行的线程在解释循环内会检查该标记，然后释放锁，切换线程执行，其自身进入等待状态。属于典型的协作机制。相关源码: \u0026lt;!-- cpython/Python/ceval.c --\u0026gt; main_loop: for (;;) { if (_Py_atomic_load_relaxed(eval_breaker)) { opcode = _Py_OPCODE(*next_instr); if (_Py_atomic_load_relaxed(\u0026amp;ceval-\u0026gt;gil_drop_request)) { /* Give another thread a chance */ drop_gil(ceval, tstate); /* Other threads may run now */ take_gil(ceval, tstate); /* Check if we should make a quick exit. */ exit_thread_if_finalizing(tstate); if (_PyThreadState_Swap(\u0026amp;runtime-\u0026gt;gilstate, tstate) != NULL) { Py_FatalError(\u0026#34;ceval: orphan tstate\u0026#34;); } } } switch (opcode) { case TARGET(NOP): case TARGET(LOAD_FAST): ... } } CPython使用系统线程，且没有实现线程调度。所以，具体哪个等待线程被切换执行，由操作系统决定。甚至，发出请求和被切换执行的未必就是同一个线程。\n对于CPU密集型任务，除了使用多进程架构绕开，也可以使用C来编写多线程的扩展也能绕开GIL限制。\n执行过程 入口 \u0026lt;!-- cpython/Programs/python.c --\u0026gt; int main(int argc, char **argv) { // unix平台是_Py_UnixMain，windows平台是Py_Main  return _Py_UnixMain(argc, argv); } 然后是选择执行模式: \u0026lt;!-- cpython/Modules/main.c --\u0026gt; int _Py_UnixMain(int argc, char **argv) { return pymain_main(\u0026amp;pymain); } static int pymain_main(_PyMain *pymain) { pymain_init(pymain); int res = pymain_cmdline(pymain); if (res \u0026lt; 0) { _Py_FatalInitError(pymain-\u0026gt;err); } if (res == 1) { goto done; } pymain_init_stdio(pymain); // 初始化  pymain-\u0026gt;err = _Py_InitializeCore(\u0026amp;pymain-\u0026gt;config); // 执行逻辑  pymain_run_python(pymain); if (Py_FinalizeEx() \u0026lt; 0) { pymain-\u0026gt;status = 120; } done: // 退出清理  pymain_free(pymain); return pymain-\u0026gt;status; } static void pymain_run_python(_PyMain *pymain) { PyCompilerFlags cf = {.cf_flags = 0}; pymain_header(pymain); pymain_import_readline(pymain); // 执行模式选择  if (pymain-\u0026gt;command) { // 命令行模式 -c  pymain-\u0026gt;status = pymain_run_command(pymain-\u0026gt;command, \u0026amp;cf); } else if (pymain-\u0026gt;module) { // 模块模式 -m  pymain-\u0026gt;status = (pymain_run_module(pymain-\u0026gt;module, 1) != 0); } else { // 入口文件模式  pymain_run_filename(pymain, \u0026amp;cf); } pymain_repl(pymain, \u0026amp;cf); }\n初始化 主要是初始化内置类型，以及创建buildins、sys模块，并初始化sys.modules，sys.path等运行所需的环境配置。 \u0026lt;!-- cpython/Python/pylifecycle.c --\u0026gt; _PyInitError _Py_InitializeCore(const _PyCoreConfig *core_config) { // 创建解释器状态实例  interp = PyInterpreterState_New(); // 创建主线程状态实例  tstate = PyThreadState_New(interp); (void) PyThreadState_Swap(tstate); /* Auto-thread-state API */ _PyGILState_Init(interp, tstate); /* Create the GIL */ PyEval_InitThreads(); // 创建并初始化内置类型  _Py_ReadyTypes(); // 初始化带有对象缓存的内置类型  if (!_PyLong_Init()) return _Py_INIT_ERR(\u0026#34;can\u0026#39;t init longs\u0026#34;); if (!PyByteArray_Init()) return _Py_INIT_ERR(\u0026#34;can\u0026#39;t init bytearray\u0026#34;); if (!_PyFloat_Init()) return _Py_INIT_ERR(\u0026#34;can\u0026#39;t init float\u0026#34;); PyObject *modules = PyDict_New(); // 创建sys.modules,存储运行期被导入的模块  interp-\u0026gt;modules = modules; // 初始化sys模块  err = _PySys_BeginInit(\u0026amp;sysmod); interp-\u0026gt;sysdict = PyModule_GetDict(sysmod); Py_INCREF(interp-\u0026gt;sysdict); PyDict_SetItemString(interp-\u0026gt;sysdict, \u0026#34;modules\u0026#34;, modules); _PyImport_FixupBuiltin(sysmod, \u0026#34;sys\u0026#34;, modules); // 初始化 __buildin__ 模块  bimod = _PyBuiltin_Init(); _PyImport_FixupBuiltin(bimod, \u0026#34;builtins\u0026#34;, modules); interp-\u0026gt;builtins = PyModule_GetDict(bimod); Py_INCREF(interp-\u0026gt;builtins); // 初始化内置异常类型  _PyExc_Init(bimod); // 初始化导入机制  err = _PyImport_Init(interp); err = _PyImportHooks_Init(); /* Initialize _warnings. */ if (_PyWarnings_Init() == NULL) { return _Py_INIT_ERR(\u0026#34;can\u0026#39;t initialize warnings\u0026#34;); } if (!_PyContext_Init()) return _Py_INIT_ERR(\u0026#34;can\u0026#39;t init context\u0026#34;); /* Only when we get here is the runtime core fully initialized */ _PyRuntime.core_initialized = 1; return _Py_INIT_OK(); }\n执行 完成初始化之后，就进入执行流程，这里以文件模式的执行为例: \u0026lt;!-- cpython/Modules/main.c --\u0026gt; static int pymain_run_file(FILE *fp, const wchar_t *filename, PyCompilerFlags *p_cf) { run = PyRun_AnyFileExFlags(fp, filename_str, filename != NULL, p_cf); return run != 0; }\n\u0026lt;!-- cpython/Python/pythonrun.c --\u0026gt; /* Parse input from a file and execute it */ int PyRun_AnyFileExFlags(FILE *fp, const char *filename, int closeit, ...) { return PyRun_SimpleFileExFlags(fp, filename, closeit, flags); } int PyRun_SimpleFileExFlags(FILE *fp, const char *filename, int closeit, ...) { // 获取__main__.__dict__，添加__file__ 信息  m = PyImport_AddModule(\u0026#34;__main__\u0026#34;); d = PyModule_GetDict(m); if (PyDict_GetItemString(d, \u0026#34;__file__\u0026#34;) == NULL) { PyObject *f; f = PyUnicode_DecodeFSDefault(filename); if (f == NULL) goto done; if (PyDict_SetItemString(d, \u0026#34;__file__\u0026#34;, f) \u0026lt; 0) { Py_DECREF(f); goto done; } if (PyDict_SetItemString(d, \u0026#34;__cached__\u0026#34;, Py_None) \u0026lt; 0) { Py_DECREF(f); goto done; } } // 运行入口文件（检查pyc缓存），将__main__.__dict__做为名字空间传入  if (maybe_pyc_file(fp, filename, ext, closeit)) { // 运行缓存文件  v = run_pyc_file(pyc_fp, filename, d, d, flags); fclose(pyc_fp); } else { // 运行py文件  v = PyRun_FileExFlags(fp, filename, Py_file_input, d, d, closeit, flags); } done: if (set_file_name \u0026amp;\u0026amp; PyDict_DelItemString(d, \u0026#34;__file__\u0026#34;)) PyErr_Clear(); Py_DECREF(m); return ret; } // 编译源文件，随后进入字节码执行流程 PyObject * PyRun_FileExFlags(FILE *fp, const char *filename_str, int start, ...) { filename = PyUnicode_DecodeFSDefault(filename_str); arena = PyArena_New(); // 编译源文件  mod = PyParser_ASTFromFileObject(fp, filename, NULL, start, 0, 0, flags, NULL, arena); // 字节码执行流程  ret = run_mod(mod, filename, globals, locals, flags, arena); return ret; } static PyObject * run_mod(mod_ty mod, PyObject *filename, ...) { co = PyAST_CompileObject(mod, filename, flags, -1, arena); v = PyEval_EvalCode((PyObject*)co, globals, locals); } 之后创建执行所需的栈帧对象，并准备好参数等待执行数据。 \u0026lt;!-- cpython/Python/ceval.c --\u0026gt; PyObject * PyEval_EvalCode(PyObject *co, PyObject *globals, PyObject *locals) { return PyEval_EvalCodeEx(co, globals, locals, ...); } PyObject * PyEval_EvalCodeEx(PyObject *_co, PyObject *globals, PyObject *locals, ...) { return _PyEval_EvalCodeWithName(_co, globals, locals, ...); } PyObject * _PyEval_EvalCodeWithName(PyObject *_co, PyObject *globals, PyObject *locals, ...) { // 创建栈帧  tstate = PyThreadState_GET(); f = _PyFrame_New_NoTrack(tstate, co, globals, locals); // 填充参数、自由变量（闭包）等数据  retval = PyEval_EvalFrameEx(f,0); } PyObject * PyEval_EvalFrameEx(PyFrameObject *f, int throwflag) { PyThreadState *tstate = PyThreadState_GET(); return tstate-\u0026gt;interp-\u0026gt;eval_frame(f, throwflag); } PyObject* _Py_HOT_FUNCTION _PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag) { // 指令参数所需的相关名字列表  co = f-\u0026gt;f_code; names = co-\u0026gt;co_names; consts = co-\u0026gt;co_consts; fastlocals = f-\u0026gt;f_localsplus; freevars = f-\u0026gt;f_localsplus + co-\u0026gt;co_nlocals; // 类似于SP、PC寄存器，下一条指令及栈帧顶位置  first_instr = (_Py_CODEUNIT *) PyBytes_AS_STRING(co-\u0026gt;co_code); next_instr = first_instr; stack_pointer = f-\u0026gt;f_stacktop; // 解释循环  main_loop: for (;;) { // 检查并处理GIL  if (_Py_atomic_load_relaxed(\u0026amp;_PyRuntime.ceval.eval_breaker)) { } fast_next_opcode: // 下一条指令和参数  NEXTOPARG(); dispatch_opcode: // 指令执行，每条指令由C实现具体过程  switch (opcode) { TARGET(NOP) FAST_DISPATCH(); TARGET(LOAD_FAST) { PyObject *value = GETLOCAL(oparg); Py_INCREF(value); PUSH(value); FAST_DISPATCH(); } } exit_eval_frame: Py_LeaveRecursiveCall(); f-\u0026gt;f_executing = 0; tstate-\u0026gt;frame = f-\u0026gt;f_back; return _Py_CheckFunctionResult(NULL, retval, \u0026#34;PyEval_EvalFrameEx\u0026#34;); }\n用户栈内存按地址从低向高分配，每次执行时会递增指令计数器。 \u0026lt;!-- cpython/Python/ceval.c --\u0026gt; #define NEXTOPARG() do { \\ _Py_CODEUNIT word = *next_instr; \\ opcode = _Py_OPCODE(word); \\ oparg = _Py_OPARG(word); \\ next_instr++; \\ } while (0) #define EMPTY() (STACK_LEVEL() == 0) #define TOP() (stack_pointer[-1]) #define SECOND() (stack_pointer[-2]) #define THIRD() (stack_pointer[-3]) #define FOURTH() (stack_pointer[-4]) #define PEEK(n) (stack_pointer[-(n)]) #define SET_TOP(v) (stack_pointer[-1] = (v)) #define SET_SECOND(v) (stack_pointer[-2] = (v)) #define SET_THIRD(v) (stack_pointer[-3] = (v)) #define SET_FOURTH(v) (stack_pointer[-4] = (v)) #define SET_VALUE(n, v) (stack_pointer[-(n)] = (v)) #define BASIC_STACKADJ(n) (stack_pointer += n) #define BASIC_PUSH(v) (*stack_pointer++ = (v)) // 地址从低向高进行 #define BASIC_POP() (*--stack_pointer)\n终止 执行完之后，结束之前还要进行一系列的清理操作。 \u0026lt;!-- cpython/Python/pylifecycle.c --\u0026gt; int Py_FinalizeEx(void) { // 等待前台线程结束  wait_for_thread_shutdown(); /* Get current thread state and interpreter pointer */ tstate = PyThreadState_GET(); interp = tstate-\u0026gt;interp; // 调用 atexit 注册的退出函数  call_py_exitfuncs(interp); /* Flush sys.stdout and sys.stderr */ if (flush_std_files() \u0026lt; 0) { status = -1; } /* Disable signal handling */ PyOS_FiniInterrupts(); // 垃圾回收，执行析构方法  _PyGC_CollectIfEnabled(); // 释放导入的模块  PyImport_Cleanup(); // 执行相关结束函数  _PyTraceMalloc_Fini(); _PyImport_Fini(); _PyType_Fini(); _PyFaulthandler_Fini(); _PyExc_Fini(); // 执行内置类型的结束函数  PyMethod_Fini(); PyFrame_Fini(); PyCFunction_Fini(); PyTuple_Fini(); PyList_Fini(); PySet_Fini(); PyBytes_Fini(); PyByteArray_Fini(); PyLong_Fini(); PyFloat_Fini(); PyDict_Fini(); PySlice_Fini(); _PyGC_Fini(); _Py_HashRandomization_Fini(); _PyArg_Fini(); PyAsyncGen_Fini(); _PyContext_Fini(); /* Cleanup Unicode implementation */ _PyUnicode_Fini(); PyGrammar_RemoveAccelerators(\u0026amp;_PyParser_Grammar); /* Cleanup auto-thread-state */ _PyGILState_Fini(); /* Delete current thread. After this, many C API calls become crashy. */ PyThreadState_Swap(NULL); // 清理解释器和主线程状态  PyInterpreterState_Delete(interp); call_ll_exitfuncs(); _PyRuntime_Finalize(); return status; }\n"});index.add({'id':4,'href':'/docs/sicp/asm/','title':"Asm",'content':"汇编语言 基础知识 编程语言是给人看的，CPU看不懂汇编语言，CPU能看懂的只有二进制指令。早期通过纸带打孔的方式输入指令，后来逐渐发展出了助记符，也就是例如跳转、循环之类的指令，再由编译器(汇编器)把这些助记符还原为二进制的指令。所以汇编语言可以理解为机器语言的一种方言，方便人类去记忆它，汇编语言和机器语言就存在着一定程度上的一一对应的关系。\n汇编是面向机器编程的语言，不同的硬件的指令可能是不同的，它能直接访问硬件的存储和端口，最大程度发挥出硬件的能力。它还有一些其他的使用场景，例如优化代码追求极致效率、直接调试和修改没有源码的程序、诊断恶意软件、进行逆向分析等。汇编的缺点也显而易见，对多数人而言，汇编代码难懂，不易维护，难于调试，不易移植，开发效率低。\n汇编语言的风格分为两种，Intel的和AT\u0026amp;T的，相当于用不同的方言描述机器语言。AT\u0026amp;T风格主要是GNU使用的，汇编器主要是GAS/as;Intel风格主要是windows使用的，汇编器有MASM、NASM、TASM、FASM。它们的主要区别在于AT\u0026amp;T会在寄存器名字前加%，在立即操作数前加$前缀，且源和目标操作数的顺序和Intel相反。详细区别可参考wiki，以及这篇文章。\n本文使用NASM汇编器，它采用Intel语法风格，支持很多种格式，包括ELF、COFF、Mach-O、Win32、Win64等，可使用nasm -hf查看其所有支持的格式。\n处理过程 Hello world示例程序: global _start section .data hello : db `hello, world!\\n` section .text _start: mov rax, 1 ; system call number should be store in rax  mov rdi, 1 ; argument #1 in rdi: where to write (descriptor)?  mov rsi, hello ; argument #2 in rsi: where does the string start?  mov rdx, 14 ; argument #3 in rdx: how many bytes to write?  syscall ; this instruction invokes a system call  mov rax, 60 ; \u0026#39;exit\u0026#39; syscall number  xor rdi, rdi syscall\n编译 把每一个源码文件(可能是.c,.s,.go等格式)翻译为一个目标文件(可能是.o)，它和可执行文件很像，也是由一个个表构成，但问题是A文件若调用B文件的函数，A是不知道B在哪的，编译器就会把这个B的位置空下来，并把这个信息写在表中某个位置等待之后进行重定位。\n我们使用编译语句nasm -g -F dwarf -f elf64 -o hello.o hello.s来编译之前的helloworld程序。其中-o hello.o表示输出的目标文件名称为hello.o，-f elf64表示目标文件的格式采取elf64的，-g表示要生成调试信息，-F dwarf用来指定生成的调试信息的格式。此外可以通过-O指定不同的优化级别，可能有O0、O1、O2等，-E表示只做预处理。\n日常说编译的时候往往指的是编译和链接两个过程。\n链接 链接就是把编译后的目标文件合并在一起，通过起始地址就能计算出各个目标文件的偏移量，也就知道了编译时需要重定位的那些函数的地址，再把它填进去。\n我们使用GNU通用的链接器来链接，也可以对比出目标文件和链接后的可执行文件的区别: [ubuntu] ~/.mac/assem $ nasm -g -f elf64 -o hello.o hello.s [ubuntu] ~/.mac/assem $ ld -o hello hello.o [ubuntu] ~/.mac/assem $ file hello.o hello.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped [ubuntu] ~/.mac/assem $ file hello hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped [ubuntu] ~/.mac/assem $ objdump -d -M intel hello.o hello.o: file format elf64-x86-64 Disassembly of section .text: 0000000000000000 \u0026lt;_start\u0026gt;:  0:\tb8 01 00 00 00 mov eax,0x1 5:\tbf 01 00 00 00 mov edi,0x1 a:\t48 be 00 00 00 00 00 movabs rsi,0x0  11:\t00 00 00 14:\tba 0e 00 00 00 mov edx,0xe 19:\t0f 05 syscall 1b:\tb8 3c 00 00 00 mov eax,0x3c 20:\t48 31 ff xor rdi,rdi 23:\t0f 05 syscall [ubuntu] ~/.mac/assem $ objdump -d -M intel hello hello: file format elf64-x86-64 Disassembly of section .text: 00000000004000b0 \u0026lt;_start\u0026gt;:  4000b0:\tb8 01 00 00 00 mov eax,0x1 4000b5:\tbf 01 00 00 00 mov edi,0x1 4000ba:\t48 be d8 00 60 00 00 movabs rsi,0x6000d8  4000c1:\t00 00 00 4000c4:\tba 0e 00 00 00 mov edx,0xe 4000c9:\t0f 05 syscall 4000cb:\tb8 3c 00 00 00 mov eax,0x3c 4000d0:\t48 31 ff xor rdi,rdi 4000d3:\t0f 05 syscall\n通过反编译发现目标文件的起始地址_start是0，所以此时的movabs rsi,0x0也表示不知道hello的地址，而链接之后这些地址都有了。链接器也支持一些常见的参数，例如-e去指定一个非默认的入口标签，-s去移除所有的符号信息，-S仅移除调试信息。\n我们再来看看Go的编译和链接过程: [ubuntu] ~/.mac/gocode $ go build -x main.go WORK=/tmp/go-build182029561 mkdir -p $WORK/b001/ cat \u0026gt;$WORK/b001/importcfg \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; # internal # import config packagefile runtime=/usr/local/go/pkg/linux_amd64/runtime.a EOF cd /root/.mac/gocode /usr/local/go/pkg/tool/linux_amd64/compile -o $WORK/b001/_pkg_.a -trimpath \u0026#34;$WORK/b001=\u0026gt;\u0026#34; -p main -complete -buildid dR1ZsbI6brd59SPrnOhX/dR1ZsbI6brd59SPrnOhX -goversion go1.13 -D _/root/.mac/gocode -importcfg $WORK/b001/importcfg -pack -c=2 ./main.go /usr/local/go/pkg/tool/linux_amd64/buildid -w $WORK/b001/_pkg_.a # internal cp $WORK/b001/_pkg_.a /root/.cache/go-build/dd/ddfadd34424d01a7a08b5c1cad7d09610caf9d21c8372338aed2d3331c8802cd-d # internal cat \u0026gt;$WORK/b001/importcfg.link \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; # internal packagefile command-line-arguments=$WORK/b001/_pkg_.a packagefile runtime=/usr/local/go/pkg/linux_amd64/runtime.a packagefile internal/bytealg=/usr/local/go/pkg/linux_amd64/internal/bytealg.a packagefile internal/cpu=/usr/local/go/pkg/linux_amd64/internal/cpu.a packagefile runtime/internal/atomic=/usr/local/go/pkg/linux_amd64/runtime/internal/atomic.a packagefile runtime/internal/math=/usr/local/go/pkg/linux_amd64/runtime/internal/math.a packagefile runtime/internal/sys=/usr/local/go/pkg/linux_amd64/runtime/internal/sys.a EOF mkdir -p $WORK/b001/exe/ cd . /usr/local/go/pkg/tool/linux_amd64/link -o $WORK/b001/exe/a.out -importcfg $WORK/b001/importcfg.link -buildmode=exe -buildid=Nk0qisr5lCLaTQS25eF-/dR1ZsbI6brd59SPrnOhX/NtfWFt1P1m_70TCcgRz3/Nk0qisr5lCLaTQS25eF- -extld=gcc $WORK/b001/_pkg_.a /usr/local/go/pkg/tool/linux_amd64/buildid -w $WORK/b001/exe/a.out # internal cp $WORK/b001/exe/a.out main rm -r $WORK/b001/\n它也有自己的编译器和链接器，只是它的目标文件通过-pack参数进行了打包，打包为一个个.a格式再进行链接。\n源码结构 汇编语言都是对内存的处理，其本身没有函数的概念，为了便于维护和写跳转之类的语句，就有了标签代表相应的内存地址，放在不同的section中。\n标签 global _start section .text main: mov rax, 60 xor rdi, rdi syscall _start: jmp main  上述源码中main与_start称为标签，可以使用jmp跳转至某个标签，或者call调用某个标签的内容。\n标签会被编译器翻译为内存地址，我们通过符号表也能看到它。使用global可以把这个标签声明为全局的标签。\n本地标签 section .text main: jmp .hello .hello: mov rax, 60 xor rdi, rdi syscall 以.开头的称为本地标签，例如上面的.hello，编译器会把它翻译为其前一个标签+本地标签，即main.hello，这样就形成了一种类似于名字空间的效果。让大段的逻辑分成多个片段，不需要担心命名上的冲突，属于汇编这门语言提供的一个功能。它和本地符号无关，main.hello也可以是一个全局的符号，代表的一种身份，而.hello依然是一个本地标签，相当于一个称谓。\n入口标签 GNU的链接器默认使用一个特殊符号_start当做程序的入口，如果我们没定义这样的名字或者把它改为一个其他名字，那么链接器链接的时候就会用一个默认的地址，这个地址可能是程序.text段的第一行，同时链接器会提示:ld: warning: cannot find entry symbol _start; defaulting to 00000000004000b0。链接器允许使用ld -e自行指定一个入口标签，当然这个标签必须是全局的。\n段标签与内存地址 可以使用$表示当前这行指令的内存地址，$$表示当前section的起始地址，同时我们也可以通过反汇编观察到跳转时标签和内存地址一一对应的关系: global _start section .text main: mov rax, main mov rbx, .exit mov rcx, $ mov rdx, $$ .exit: mov rax, 60 xor rdi, rdi syscall _start: jmp main\n[ubuntu] ~/.mac/assem $ nasm -g -F dwarf -f elf64 -o hello.o hello.s [ubuntu] ~/.mac/assem $ ld -o hello hello.o [ubuntu] ~/.mac/assem $ objdump -d -M intel hello hello: file format elf64-x86-64 Disassembly of section .text: 0000000000400080 \u0026lt;main\u0026gt;: 400080:\t48 b8 80 00 40 00 00 movabs rax,0x400080 400087:\t00 00 00 40008a:\t48 bb a8 00 40 00 00 movabs rbx,0x4000a8 400091:\t00 00 00 400094:\t48 b9 94 00 40 00 00 movabs rcx,0x400094 40009b:\t00 00 00 40009e:\t48 ba 80 00 40 00 00 movabs rdx,0x400080 4000a5:\t00 00 00 00000000004000a8 \u0026lt;main.exit\u0026gt;: 4000a8:\tb8 3c 00 00 00 mov eax,0x3c 4000ad:\t48 31 ff xor rdi,rdi 4000b0:\t0f 05 syscall 00000000004000b2 \u0026lt;_start\u0026gt;: 4000b2:\teb cc jmp 400080 \u0026lt;main\u0026gt; 语言规范 寻址方式 寻址方式就是通过什么方式确定目标所在的地址。我们把寄存器当成一个个的盒子，有以下几种寻址方式:\n 立即寻址，mov rax, 0x100，直接把值0x100放在一个盒子中 寄存器寻址，mov rax, rbx，把一个盒子中的值放在另一个盒子中 直接寻址，mov rax, [5]，把5#盒子中的值放在另一个盒子中，5代表内存地址 寄存器间接寻址，mov rax,[rbx]，rbx中存着内存地址，把这个地址对应的值放在盒子中 寄存器相对寻址，mov rax,[8+rbx]，先算出rbx+8，得到一个内存地址而已 基址变址，lea rax, [rbx+rcx]，把地址拿出来放到盒子里  mov rax, 0x100表示给rax赋值为0x100，mov rax, [0x100]表示给rax赋值内存0x100位置的值，lea rax, [0x100]表示直接去找[0x100]的地址即0x100，赋值给rax。mov是对于内容的操作，lea是对于地址的操作。mov是不能直接在两块内存之间进行复制的。[addr]这种表达方式属于NASM编译器对内存操作必须这么做，即便是一个变量名称（代表一个内存地址），例如x=100，也得用[x]才取的到它的值100。\n变量 可以在.data和.bss段中定义变量，定义示例: section .data x dq 0x8070605040302010 y db 1,2,3 z times 3 dw 1,2 leny equ $-y ;$为当前地址，所以减去y的地址，就是y的长度  s db \u0026#34;abcd\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;f\u0026#34; ; db*6  lens equ $-s ; equ定义的是常量，不会存储在.data中  section .bss xx resq 2 yy times 2 resb 8 x是变量名称，代表符号的地址，变量的起始地址；dq代表它的长度；0x8070605040302010代表它的初始化值。\n字符和它代表的长度如下表所示:\n   .data中 长度(bytes) .bss中     db 1 resb   dw 2 resw   dd 4 resd   dq 8 resq   dt 10 rest   do 16 reso   dy 32 resy   dz 64 resz    y db 1,2,3就表示从y这个内存地址开始，后面逗号分隔的有三块内存，每块内存都是db大小且值为对应的1、2、3。汇编语言中是没有字符串的，像\u0026quot;abcd\u0026quot;就是拿它的ASCII值把它当做字节序列。s db \u0026quot;abcd\u0026quot;, \u0026quot;e\u0026quot;, \u0026quot;f\u0026quot;中db放不下整个\u0026quot;abcd\u0026quot;，就用了4个db来放。equ是定义常量的方式，见后文描述。另外，数字有大小端和进制的问题。\n在.data中是定义，而在.bss中是预留。xx resq 2就表示从xx开始，预留resq大小的空间，预留2组。\ntimes类似于语法糖，用于重复定义数据或指令。yy times 2 resb 8就表示yy resb 8重复两次。\n常量 常量是不会存在.data段中的，尽管我们在那里定义，但它会被编译器展开，变为指令的一部分，保存在.text段中。\n汇编语言中常量有四种，即整数、浮点数、字符、字符串。整数常量的值有不同的写法:\n 十进制的，100, 0100, 100d, 0100d, 0d100 十六进制的，0h64, 0x64, $064, 64h 二进制的，0b101, 101b  字符代表的是其ASCII的常量值，支持转义，支持单双和反引号。字符串会被解析为ASCII的序列，从左依次排列。\n整型常量通过equ定义，例如leny equ $-y ，它常用来和$、$$配合计算长度，但不支持用它来定义浮点数。\n另一种常见的定义方式是使用%assign name value，它可以在任意位置定义，而且可以重复定义，使用时以最后一次的定义为准。这种定义方式属于使用宏，它是编译器在对代码预处理阶段就展开的。\n指令 常用的指令其实很少，如下所示，如果遇到其他复杂的指令也只需要搜索一下即可。\n 数据移动: mov, push, pop, lea 算术: inc, dec, add, sub, imul, idev 二进制逻辑运算: not, and, xor, or 位移: shl, shr 字节数组或字符串: rep, movsb, cmpsb, scasb, stomb  有时由于指令集的限制禁止一些操作，例如mov不能用于内存到内存的操作，这些都可以通过x86手册查看到。\n控制流 在汇编语言中，基本的控制流就是跳转和循环，其他的控制流也只是基于这两种的组合。高级语言里的控制流也只是看上去更方便，本质上在CPU眼里仍然是跳转和循环。\n跳转 跳转一般都是指跳转到某个label，分为三种，第一种jmp类似于goto，属于无条件跳转。\n第二种test则是针对其两个参数进行二进制AND逻辑操作，并根据结果设置标志寄存器的ZF标志位。之后配合jz(和je等价)、jnz(和jne等价)指令，它们会判断ZF标志位的值完成跳转。 _start: mov rax, 1 test rax, rax ; 如果AX为0，则把ZF设为1，否则把ZF设为0  jne .exit ; 如果ZF为0，则跳转至.exit标签\n第三种是使用cmp比较两个参数，比较的结果存到相应的状态寄存器中，根据状态寄存器的值再配合相关指令完成跳转:\n je (==), jne (!=), jz (==0), jnz (!=0) jg (\u0026gt;), jge (\u0026gt;=), jl (\u0026lt;), jle (\u0026lt;=)  _start: mov rax, 1 mov rbx, 2 cmp rax, rbx jne .exit 循环 循环需要先将循环多少次放到rcx寄存器中，然后执行循环体逻辑，最后调用loop指令，该指令在rcx寄存器大于0时会减一并跳转到其参数的位置，等于0时则会接着向下执行。 _start: xor rax, rax mov rcx, 3 .abc: inc rax loop .abc 类似于do(sth\u0026hellip;) until{rcx==0}。\n数据结构 字符串 汇编中会把字符串当做字节序列来处理，字节实际上是个整数，它的取值范围是0~255。当我们通过:\nstring db `\\u6c49\\xe5\\xad\\x97 \\u263a \\n` ; 汉字, ☺ -\u0026gt; UTF-8 定义字符串时，实际上就是定义了一个字节序列，只是抽象层面上可以理解为字符串。而对于这种字节序列，CPU也提供了专门的指令适用于更高效的移动它们，即rep movs。\n编译器支持\\u、\\x以及utf-8等方式的编码。字符串可以放在section .rodata(只读)或section .data中。\n数组 数组实际上就是一个连续的存储空间，里面只有元素，没有别的东西。数组定义时得告诉编译器其长度，编译器才好安排地址。汇编里没有数组这种语法，我们的做法只是保留一段内存空间，本质上我们对数组的操作就是对其内存地址的操作。 section .bss %assign num 10 %assign size 8 array resq num * size 通过num*size计算出数组的长度，array代表数组的起始地址，要拿到array[i]的地址就可以通过array+size*i。\n结构体 结构体实际上也是一个连续的存储空间，只是其内部字段的长度不同，在汇编中还是按照起始地址加偏移量去数格子定位到不同的字段。那么它还是一个编译器的语法糖，通过反汇编是看不到的。 struc User .name : resb 10 .age : resq 1 endstruc section .data u1 istruc User at User.name, db \u0026#34;user1\u0026#34; at User.age, dq 22 iend section .bss u2 resb User_size 这段代码先定义的是一个内存布局，成员字段代表的是偏移量。接着使用istruc在data段中去初始化一个变量u1。又使用u2定义了一个未初始化值的User，User_size也是编译器语法糖，帮助编译器算出User结构体的长度。\n宏 宏是在代码预处理阶段被展开的，相当于模板。\n%define 单行宏定义，和%assign只支持常量不同，%define可以支持参数。属于汇编语言的一种功能，和汇编不是一回事，因为汇编是目标语言。 section .text %define SYS_EXIT 60 %define DEMO(x) mov rax, [rbx+x] _start: DEMO(100) .exit: mov rax, SYS_EXIT xor rdi, rdi syscall\n%macro 有点像是定义函数，中间可以包含多行代码。\n%macro \u0026lt;name\u0026gt; \u0026lt;args_count\u0026gt; ... %endmacro 使用这样的方式，可以先给宏定义个名字，之后跟参数，参数可以是多个。在内容中可以使用%1、%2这样的方式去调用第x个参数。还可使用%%这样的语法在宏内定义本地标签，在宏展开后这些本地标签会被自动重命名。\n调用libc 汇编中虽然没有标准库，但可以通过混合编程调用C语言的标准库。\n这种方式需要使用main作为函数入口，并使用extern声明要用到的libc函数，然后用寄存器传参(依次为rdi,rsi,rdx,rcx,r8,r9)和接收返回值(rax)，且需要使用gcc作为链接器。\nglobal main extern printf section .data s db `hello world!\\n` section .text main: push rbp mov rbp, rsp ;保存现场  mov rdi, s ;传参  xor rax, rax ;清空rax，用于接收返回值，虽然printf函数没有返回值  call printf mov rax, 0 pop rbx ;恢复现场  ret 可以这样编译运行它，并查看它的依赖: [ubuntu] ~/.mac/assem $ nasm -g -F dwarf -f elf64 -o libc.o libc.s [ubuntu] ~/.mac/assem $ gcc -no-pie -o libc libc.o [ubuntu] ~/.mac/assem $ ./libc hello world! [ubuntu] ~/.mac/assem $ ldd libc linux-vdso.so.1 (0x00007ffc2f180000) libc.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fe329bdd000) /lib64/ld-linux-x86-64.so.2 (0x00007fe329fce000)\n"});index.add({'id':5,'href':'/docs/go/defer/','title':"defer实现方式",'content':"Defer延迟调用 defer是GO语言中独有的特性，在其他语言中可能采用try...finally这样的方式来实现，两者还是有很大区别的。finally是立即执行的，而defer会延迟执行，且defer可以分割很多的逻辑。延迟调用最大的优势是即便函数执行出错，依然能保证回收资源等操作得以执行。\n我们看到很多的文章中是这样描述defer执行方式的，参数首先会被复制进defer func中，然后执行原函数，然后执行defer func，最后再执行return。那么真的是这样么？这似乎解释不了如下示例: func test1() int { x := 100 defer func() { x++ }() return x } func test2() (x int) { x = 100 defer func() { x++ }() return 100 } func main() { println(\u0026#34;test1:\u0026#34;, test1()) println(\u0026#34;test2:\u0026#34;, test2()) } [ubuntu] ~/.mac $ go run test.go test1: 100 test2: 101\n按照这个观点，似乎test1()的执行过程应该是x等于100，然后x++，然后返回x=101；test2()应该是x等于100，然后x++，然后返回100。但执行结果却都和我们预想的不一样，带着这样的疑问，我们来深入了解defer的执行机制。\n我们先来看一个简单的例子: func test(a, b int) { println(\u0026#34;test: \u0026#34;, a, b) } func main() { a, b := 0x11, 0x22 defer test(a, b) a++ b++ println(\u0026#34;main: \u0026#34;, a, b) }\n然后反汇编看看它的执行过程: [ubuntu] ~/.mac $ go build test.go [ubuntu] ~/.mac $ go tool objdump -s \u0026#34;main\\.main\u0026#34; test TEXT main.main(SB) /root/.mac/test.go test.go:6\t0x4523b0\t64488b0c25f8ffffff\tMOVQ FS:0xfffffff8, CX test.go:6\t0x4523b9\t483b6110\tCMPQ 0x10(CX), SP test.go:6\t0x4523bd\t0f86ad000000\tJBE 0x452470 test.go:6\t0x4523c3\t4883ec58\tSUBQ $0x58, SP test.go:6\t0x4523c7\t48896c2450\tMOVQ BP, 0x50(SP) test.go:6\t0x4523cc\t488d6c2450\tLEAQ 0x50(SP), BP test.go:8\t0x4523d1\tc744241010000000\tMOVL $0x10, 0x10(SP) test.go:8\t0x4523d9\t488d05705a0200\tLEAQ 0x25a70(IP), AX test.go:8\t0x4523e0\t4889442428\tMOVQ AX, 0x28(SP) test.go:8\t0x4523e5\t48c744244011000000\tMOVQ $0x11, 0x40(SP) test.go:8\t0x4523ee\t48c744244822000000\tMOVQ $0x22, 0x48(SP) test.go:8\t0x4523f7\t488d442410\tLEAQ 0x10(SP), AX test.go:8\t0x4523fc\t48890424\tMOVQ AX, 0(SP) test.go:8\t0x452400\te87b16fdff\tCALL runtime.deferprocStack(SB)  test.go:8\t0x452405\t85c0\tTESTL AX, AX test.go:8\t0x452407\t7557\tJNE 0x452460 test.go:11\t0x452409\te8a230fdff\tCALL runtime.printlock(SB) test.go:11\t0x45240e\t488d0583130200\tLEAQ 0x21383(IP), AX test.go:11\t0x452415\t48890424\tMOVQ AX, 0(SP) test.go:11\t0x452419\t48c744240807000000\tMOVQ $0x7, 0x8(SP) test.go:11\t0x452422\te8c939fdff\tCALL runtime.printstring(SB) test.go:11\t0x452427\t48c7042412000000\tMOVQ $0x12, 0(SP) test.go:11\t0x45242f\te8fc37fdff\tCALL runtime.printint(SB) test.go:11\t0x452434\te8b732fdff\tCALL runtime.printsp(SB) test.go:11\t0x452439\t48c7042423000000\tMOVQ $0x23, 0(SP) test.go:11\t0x452441\te8ea37fdff\tCALL runtime.printint(SB) test.go:11\t0x452446\te8f532fdff\tCALL runtime.printnl(SB) test.go:11\t0x45244b\te8e030fdff\tCALL runtime.printunlock(SB) test.go:12\t0x452450\t90\tNOPL test.go:12\t0x452451\te82a1cfdff\tCALL runtime.deferreturn(SB)  test.go:12\t0x452456\t488b6c2450\tMOVQ 0x50(SP), BP test.go:12\t0x45245b\t4883c458\tADDQ $0x58, SP test.go:12\t0x45245f\tc3\tRET test.go:8\t0x452460\t90\tNOPL test.go:8\t0x452461\te81a1cfdff\tCALL runtime.deferreturn(SB)  test.go:8\t0x452466\t488b6c2450\tMOVQ 0x50(SP), BP test.go:8\t0x45246b\t4883c458\tADDQ $0x58, SP test.go:8\t0x45246f\tc3\tRET test.go:6\t0x452470\te82b7affff\tCALL runtime.morestack_noctxt(SB) test.go:6\t0x452475\te936ffffff\tJMP main.main(SB)\n我们发现defer test(a, b)实际上会被转化为CALL runtime.deferproc(SB)(Go1.13才使用deferprocStack，这里先以deferproc为例)，之后进行的a++已经不会影响到它，而在main函数执行完之后，才会去通过CALL runtime.deferreturn(SB)调用它。\n我们再来看看runtime.deferproc干了些什么，我在这里也把源码中重要的注释翻译了过来:\n// go/src/runtime/panic.go // siz表示fn方法中参数需要占用多少个字节，使用siz创建了一个deferred的方法fn // 编译器将一个defer语句转化为一个对此方法的调用 func deferproc(siz int32, fn *funcval) { // fn之后紧跟着fn的参数 \tif getg().m.curg != getg() { throw(\u0026#34;defer on system stack\u0026#34;) } //fn的参数处于一个危险的状态，deferproc的stack map并没有复制它们。所以我们不能让垃圾回收器或者栈复制触发，直到我们把这些参数复制到一个安全的地方。下面的内存复制会做到这一点。在复制完成前，我们只能调用nosplit routines。 \tsp := getcallersp() argp := uintptr(unsafe.Pointer(\u0026amp;fn)) + unsafe.Sizeof(fn) callerpc := getcallerpc() d := newdefer(siz) \tif d._panic != nil { throw(\u0026#34;deferproc: d.panic != nil after newdefer\u0026#34;) } d.fn = fn d.pc = callerpc d.sp = sp \tswitch siz { case 0: // Do nothing. \tcase sys.PtrSize: *(*uintptr)(deferArgs(d)) = *(*uintptr)(unsafe.Pointer(argp)) default: memmove(deferArgs(d), unsafe.Pointer(argp), uintptr(siz)) } return0() } 我们发现newdefer函数返回的是一个这样的结构体: // go/src/runtime/runtime2.go type _defer struct { siz int32 // includes both arguments and results \tstarted bool heap bool openDefer bool sp uintptr // sp at time of defer \tpc uintptr // pc at time of defer \tfn *funcval // can be nil for open-coded defers \t_panic *_panic // panic that is running defer \tlink *_defer fd unsafe.Pointer // funcdata for the function associated with the frame \tvarp uintptr // value of varp for the stack frame  framepc uintptr }\n鉴于篇幅，我删除了其注释，但可根据这些注释得出结论，defer func()这个语句会被保存在当前Goroutine中，把它的参数、所需要的栈大小等保存为一个_defer对象，把多个_defer形成一个链表，也就是一个FILO的队列。\n但是Goroutine和函数执行没什么直接的关系，如果是A嵌套B，B嵌套C，A、B、C都有各自的defer语句，那么它们都会被保存在这个Goroutine的_defer链表中，它怎么保证执行C的时候不把B的defer执行掉，这个秘密藏在CALL runtime.deferreturn(SB)中:\nfunc deferreturn(arg0 uintptr) { gp := getg() d := gp._defer if d == nil { return } sp := getcallersp() if d.sp != sp { \treturn } if d.openDefer { done := runOpenDeferFrame(gp, d) if !done { throw(\u0026#34;unfinished open-coded defers in deferreturn\u0026#34;) } gp._defer = d.link freedefer(d) return } switch d.siz { case 0: // Do nothing. \tcase sys.PtrSize: *(*uintptr)(unsafe.Pointer(\u0026amp;arg0)) = *(*uintptr)(deferArgs(d)) default: memmove(unsafe.Pointer(\u0026amp;arg0), deferArgs(d), uintptr(d.siz)) } fn := d.fn d.fn = nil gp._defer = d.link freedefer(d) jmpdefer(fn, uintptr(unsafe.Pointer(\u0026amp;arg0))) } 函数执行调用这个指令的时候，它先拿到当前Goroutine的_defer链表，然后依次检查它的SP就行了，这个SP是执行deferproc时存进去的当前这个函数的栈顶，只要不一致那肯定是父函数的栈了。\n回到最初的问题，我们发现反编译之后，函数的整个执行顺序是这样的，函数调用方已经分配好了被调用方的参数和返回值相对于栈顶的地址，然后执行函数，遇到defer语句时先存在Goroutine的_defer链表中接着执行函数，执行完函数后回过头来执行_defer的func，最后调用RET指令并恢复现场。套用到test1()中，就是先定义了返回值(return_val)是个整数并给它了个地址，然后执行x:=100，然后return x被翻译为了return_val=x，然后执行x++，最后调用RET指令。在test2()中，return_val直接叫x，然后给它赋值100，return 100已经没有意义，然后执行return_val_x++，最后调用RET指令。\n整个defer的执行核心过程如下图所示: 此外，我们在挖掘源码的时候发现defer是有很多堆上内存分配行为的，这会影响性能。在Go1.13中编译器会判断如果没有发生内存逃逸，就调用deferprocStack把_defer对象建在栈上，这个对象的heap属性就是描述它是否在堆上分配的。具体是如何判断的，初步了解是defer func是顶级函数时就分配到栈上，如果它外层有迭代循环之类的将会被分配到堆上，之后再详细了解。\n"});index.add({'id':6,'href':'/docs/','title':"Docs",'content':""});index.add({'id':7,'href':'/docs/other/git/','title':"Git原理和技巧",'content':"Git原理和技巧 Git本质上是一个内容寻址(content-addressable)文件系统，并在此之上提供了一个版本控制系统的用户界面。了解底层原理，可以更好的帮助我们理清思路，知道真正在操作什么，而不会迷失在大量的指令和参数上。\n原理 区域 工作区(Working Directory)，就是我们在电脑里看到的目录，我们对文件进行增、改、删都发生在这个目录中。\n在这里目录中，有一个隐藏目录.git就是git的版本库(Repository)。\n版本库中存了很多东西，其中还有一片区域，一般为.git/index文件，我们称为stage(或index)暂存区。\n再加上远程仓库，例如github上的repo，我们平时做的大量操作都是把文件在这四个区域之间相互移动。 对象 在git中，除了init、clone等我们常用的高层命令(被称为porcelain)之外，还有一些底层命令(被称为plumbing)。例如git hash-object把一个文件转换为一个git对象，git cat-file可以打印出一个git对象。\n那么git对象到底是什么呢？因为Git的核心是一个内容寻址文件系统，可以理解为一个简单的键值对数据库。当我们向它插入一个任意类型的内容时，它会返回一个键值对，通过键值对能够在任意时刻再次检索到该内容。\n当我们初始化时，.git中会有一个文件夹objects专门存储git对象: ➜ testgit git init Initialized empty Git repository in /home/hejl/testgit/.git/ ➜ testgit git:(master) ls .git HEAD branches config description hooks info objects refs\n当我们添加一项内容的时候，这个objects文件夹就会多出一个文件: ➜ testgit git:(master) echo \u0026#39;abc\u0026#39; \u0026gt; test.txt ➜ testgit git:(master) ✗ git add . ➜ testgit git:(master) ✗ tree .git/objects/ .git/objects/ ├── 8b │ └── aef1b4abc478178b004d62031cf7fe6db6f903 ├── info └── pack 3 directories, 1 file 它的过程实际上是通过sha1算法计算出文件内容也就是abc的hash值，是一个40位的16进制的字符串，字符串的前两位作为一个文件夹名称，后38位作为文件名称。因为大多数的文件系统都讨厌单个目录中包含太多的文件，这会减慢其爬取的速度，Git用这个方法使得第一级目录最多256个。文件本身就是Git object，它的头部定义了类型，紧跟着是一个ASCII的空格(0x20)，然后是对象的大小多少字节，紧跟着一个null(0x00)，最后是对象本身的内容。整个文件通过zlib压缩存储。\n有四种类型的对象，它们分别是blob,commit,tree,tag。\nblob 该种类型的对象存储的原始内容，例如刚才新增的对象就是这种类型: ➜ testgit git:(master) ✗ git cat-file -t 8bae blob ➜ testgit git:(master) ✗ git cat-file -p 8bae abc 但它也只存储内容，例如工作区中该文件的路径、文件名称、创建时间等都不存储在这种类型的git对象中。\ncommit 当我们进行一次提交操作之后，就会产生两种类型的对象，一个是tree对象稍后再说，另一个就是commit对象。它的内容包括: ➜ testgit git:(master) ✗ git commit -m \u0026#34;first commit\u0026#34; [master (root-commit) 37b766f] first commit 1 file changed, 1 insertion(+) create mode 100644 test.txt ➜ testgit git:(master) tree .git/objects/ .git/objects/ ├── 37 │ └── b766ff8084b9ea2e9a159bdb35b286a3406d3e ├── 8b │ └── aef1b4abc478178b004d62031cf7fe6db6f903 ├── 93 │ └── 4a610d6024005decae12f6ec4c242caa2a4de4 ├── info └── pack 5 directories, 3 files ➜ testgit git:(master) git cat-file -p 37b7 tree 934a610d6024005decae12f6ec4c242caa2a4de4 author hjlarry \u0026lt;hjlarry@163.com\u0026gt; 1582182460 +0800 committer hjlarry \u0026lt;hjlarry@163.com\u0026gt; 1582182460 +0800 first commit tree表示本次提交产生的另一个tree类型git对象的路径地址。author和committer大多数情况相同，但有时比如说我们把别人分支的一个commit通过cherry-pick加入我们的分支，这时committer是我们自己，author仍然是别人。这里author需要包含username、email(所以刚使用git时要求在gitconfig中设置用户名和邮箱)、时间戳。紧跟着是提交的message。\n实际上完整的commit对象的内容正是邮件的一种简单的格式，源于RFC2822。还包括一个parent，指向本次提交的父commit对象的路径地址，因为现在是第一次提交，没有parent。以及一个gpgsig，通过PGP签名了一下这个对象，通过cat-file看不到。\n也就是说我们通过git log查看提交日志的信息，就是一层层的递归查看父对象拿到的。\ntree 树对象解决的是文件名保存的问题，并能够将多个文件组织到一起。我们新建一次提交，添加更多内容为例: ➜ testgit git:(master) echo \u0026#39;abcdef\u0026#39; \u0026gt; test.txt ➜ testgit git:(master) ✗ mkdir adir ➜ testgit git:(master) ✗ echo \u0026#39;123\u0026#39; \u0026gt; adir/tt.txt ➜ testgit git:(master) ✗ git add . ➜ testgit git:(master) ✗ git commit -m \u0026#34;third commit\u0026#34; [master 79380b0] third commit 2 files changed, 2 insertions(+), 1 deletion(-) create mode 100644 adir/tt.txt ➜ testgit git:(master) git cat-file -p 1bc4 040000 tree f1af0a5ebfe47de9d2d6db753088462b797b2075 adir 100644 blob 0373d9336f8c8ee90faff225de842888e884a48b test.txt ➜ testgit git:(master) git cat-file -p f1af 100644 blob 190a18037c64c43e6b11489df4bf0b9eb6d2c9bf tt.txt 它会把当前的目录结构打一个快照，相当于以表格的形式记录该目录下每一个目标的权限、类型(通常是文件blob，或者是文件夹变成一个新的tree对象)、哈希值(也就相当于文件路径)、文件名。\n也就是说，当我们通过git add *时会把工作区文件的文件内容生成一个blob object，并把文件名和blob的sha1等其他信息更新到暂存区的index文件中；当我们通过git commit -m时，git会根据index信息生成一个tree object，并创建一个新的commit object关联到这个tree。commit object的parent指向了上一个commit，当前分支的指针也会移动到新的commit结点。\ntag git中还有一种对象类型就是tag，它通常和commit差不多。见下文标签引用。\n引用 引用本质上就是指向某个commit的指针，它被放在.gits/refs目录中。 ➜ testgit git:(master) tree .git/refs/ .git/refs/ ├── heads │ └── master └── tags 2 directories, 1 file ➜ testgit git:(master) cat .git/refs/heads/master 79380b0625150b1b71940cfac0b2a501793eac0c\n分支引用 当我们新建一个分支时，就会在.git/refs/heads文件夹下多一个名称为分支名称的文件，内容就是一个commit的sha。当我们提交一次commit时，当前分支的引用的commit就会自动发生改变。 ➜ testgit git:(6c27f42) git branch testbranch ➜ testgit git:(testbranch) cat .git/refs/heads/testbranch 6c27f425aae198e6c1e5098c13d352b3f27edfca\nHEAD引用 它是一个符号引用，指向当前所在的分支。它位于.git/HEAD文件。 ➜ testgit git:(master) cat .git/HEAD ref: refs/heads/master ➜ testgit git:(master) git checkout 6c27 Note: checking out \u0026#39;6c27\u0026#39;. You are in \u0026#39;detached HEAD\u0026#39; state. ➜ testgit git:(6c27f42) cat .git/HEAD 6c27f425aae198e6c1e5098c13d352b3f27edfca 当我们checkout某个commit时，HEAD会指向commit，这时候称为分离头指针(Detached HEAD)状态。\n标签引用 我们通常创建的都是轻量级标签，它只是一个引用，位于.gits/refs/tags文件夹下。但还可以创建另一种附注标签，它会额外创建一个tag object。 ➜ testgit git:(testbranch) git tag testmytag ➜ testgit git:(testbranch) cat .git/refs/tags/testmytag 6c27f425aae198e6c1e5098c13d352b3f27edfca ➜ testgit git:(testbranch) git tag -a v1.0 -m \u0026#34;test my tag\u0026#34; ➜ testgit git:(testbranch) cat .git/refs/tags/v1.0 0ee17848727b21f3086760c6bbc38cc9a12b5e08 ➜ testgit git:(testbranch) git cat-file -t 0ee1 tag ➜ testgit git:(testbranch) git cat-file -p 0ee1 object 6c27f425aae198e6c1e5098c13d352b3f27edfca type commit tag v1.0 tagger hjlarry \u0026lt;hjlarry@163.com\u0026gt; 1582267013 +0800 test my tag 标签和分支的主要区别是:\n 标签可以指向任意object，而分支只能指向commit object。 分支在每次提交更新时会自动更新，而标签不会。  远程引用 当我们添加一个远程仓库，或者是从远程库clone过来时，就会有远程引用，它位于.git/refs/remotes文件夹下。 ➜ testgit git:(testbranch) tree ~/my_git/.git/refs/remotes /home/hejl/my_git/.git/refs/remotes └── origin ├── HEAD └── master 1 directory, 2 files ➜ testgit git:(testbranch) cat ~/my_git/.git/refs/remotes/origin/HEAD ref: refs/remotes/origin/master ➜ testgit git:(testbranch) cat ~/my_git/.git/refs/remotes/origin/master 94985c6535a5493d493ce89631c7e417f5e7ecaa 远程引用和分支之间最主要的区别在于远程引用是只读的。虽然可以checkout到某个远程引用，但是Git并不会将HEAD引用指向该远程引用，这种情况仍然是分离头指针状态。\n常用操作 合并 FAST-FORWARD 当试图合并两个分支时，如果顺着一个分支一路走下去能到达另一个分支，那么Git的合并只是把指针往前推进，所以叫快进模式(即Fast-forward)。 ➜ testgit git:(master) ✗ git checkout -b fixbug Switched to a new branch \u0026#39;fixbug\u0026#39; ➜ testgit git:(fixbug) ✗ echo \u0026#39;123\u0026#39; \u0026gt; test.txt ➜ testgit git:(fixbug) ✗ git add . ➜ testgit git:(fixbug) ✗ git commit -m \u0026#34;9th commit\u0026#34; [fixbug 22a449d] 9th commit 1 file changed, 1 insertion(+) ➜ testgit git:(fixbug) git checkout master Switched to branch \u0026#39;master\u0026#39; ➜ testgit git:(master) git merge fixbug Updating c658c0b..22a449d Fast-forward test.txt | 1 + 1 file changed, 1 insertion(+) 合并时，会提示Fast-forward。\n另外，我们往往会把远程仓库的更新git pull下来，这背后实际上执行了两条指令，先git fetch再git merge，这种情况一般也属于Fast-forward合并。\n三方合并 非FAST-FORWARD情况时，就是一次三方合并。三方指的是当前分支节点、要合并的分支的节点以及它们的共同祖父节点。这种情况会把它们的内容合并起来，如果没有冲突的话会自动形成一个新的commit。 ➜ testgit git:(master) git checkout -b newfeature HEAD~2 Switched to a new branch \u0026#39;newfeature\u0026#39; ➜ testgit git:(newfeature) echo \u0026#39;newfeature\u0026#39; \u0026gt; newfeature.txt ➜ testgit git:(newfeature) ✗ git add . ➜ testgit git:(newfeature) ✗ git commit -m \u0026#34;add new feature\u0026#34; [newfeature 68212fe] add new feature 1 file changed, 1 insertion(+) create mode 100644 newfeature.txt ➜ testgit git:(newfeature) git checkout master Switched to branch \u0026#39;master\u0026#39; ➜ testgit git:(master) git merge newfeature Merge made by the \u0026#39;recursive\u0026#39; strategy. newfeature.txt | 1 + 1 file changed, 1 insertion(+) create mode 100644 newfeature.txt 通过git log --graph可以观察到日志: * commit 979309d67d62bd2fb3beeb009c20f750d362e93a (HEAD -\u0026gt; master) |\\  Merge: 22a449d 68212fe | | Author: hjlarry \u0026lt;hjlarry@163.com\u0026gt; | | Date: Sun Feb 23 21:46:55 2020 +0800 | | | | Merge branch \u0026#39;newfeature\u0026#39; | | | * commit 68212fef9f5e17091bcd14b4d9be713bfc2c763b (newfeature) | | Author: hjlarry \u0026lt;hjlarry@163.com\u0026gt; | | Date: Sun Feb 23 21:46:34 2020 +0800 | | | | add new feature | | * | commit 22a449d52fe269ed7c969c179c1788f89013ac2d | | Author: hjlarry \u0026lt;hjlarry@163.com\u0026gt; | | Date: Sun Feb 23 21:39:01 2020 +0800 | | | | 9th commit | | * | commit c658c0b8070ec1ab7dfe53351b64da79ae939e6d |/ Author: hjlarry \u0026lt;hjlarry@163.com\u0026gt; | Date: Sun Feb 23 16:57:12 2020 +0800 | | 8th commit 我们观察merge时的那个commit object会发现它是有两个parent的: ➜ testgit git:(master) git cat-file -p 9793 tree 88cab0838dc7d8ae476592dbd60b4bda86dafbd8 parent 22a449d52fe269ed7c969c179c1788f89013ac2d parent 68212fef9f5e17091bcd14b4d9be713bfc2c763b author hjlarry \u0026lt;hjlarry@163.com\u0026gt; 1582465615 +0800 committer hjlarry \u0026lt;hjlarry@163.com\u0026gt; 1582465615 +0800 Merge branch \u0026#39;newfeature\u0026#39;\n三方合并时，也经常会遇到发生冲突的情况。这时候git会暂停合并，给出提示，并在冲突的地方做出标记。我们需要手工处理，选择某个分支或者自行再做修改都可以，然后再自行git add和git commit即可。\n变基 基于之前三方合并的示例，还有一种合并分支的方法就是变基。它会在当前分支上重演一遍目标分支的历史，最后形成一个线性的提交历史。当前分支的commit object由于变更了其parent就会发生改变，而目标分支的commit object往往不会改变。 ➜ testgit git:(master) git checkout -b testrebase HEAD~ Switched to a new branch \u0026#39;testrebase\u0026#39; ➜ testgit git:(testrebase) echo \u0026#39;testrebase\u0026#39;\u0026gt;test.txt ➜ testgit git:(testrebase) ✗ git add . ➜ testgit git:(testrebase) ✗ git commit -m \u0026#34;test rebase\u0026#34; [testrebase 7f4088a] test rebase 1 file changed, 1 insertion(+), 3 deletions(-) ➜ testgit git:(testrebase) git checkout master Switched to branch \u0026#39;master\u0026#39; ➜ testgit git:(master) git log --graph ➜ testgit git:(master) git rebase testrebase First, rewinding head to replay your work on top of it... Applying: add new feature 依然观察日志: * commit cd2c246f0cfcd2d98717af0a405ac17fd23636bc (HEAD -\u0026gt; master) | Author: hjlarry \u0026lt;hjlarry@163.com\u0026gt; | Date: Sun Feb 23 21:46:34 2020 +0800 | | add new feature | * commit 7f4088a0254081c4349a253c2d3a74dd7a7f1234 (testrebase) | Author: hjlarry \u0026lt;hjlarry@163.com\u0026gt; | Date: Sun Feb 23 22:47:17 2020 +0800 | | test rebase | * commit 22a449d52fe269ed7c969c179c1788f89013ac2d (fixbug) | Author: hjlarry \u0026lt;hjlarry@163.com\u0026gt; | Date: Sun Feb 23 21:39:01 2020 +0800 | | 9th commit | * commit c658c0b8070ec1ab7dfe53351b64da79ae939e6d | Author: hjlarry \u0026lt;hjlarry@163.com\u0026gt; | Date: Sun Feb 23 16:57:12 2020 +0800 | | 8th commit\n它典型的使用场景，例如团队其他人维护的项目，我们在自己的分支上为其提供feature，然后把我们的分支变基到origin/master上，这样其他人只需要去FAST-FORWARD而无需人工整合。\n交互式变基 通过git rebase -i \u0026lt;commit_id\u0026gt;就能进入一个交互式界面: pick 2c70e0b second commit a pick c351a72 third commit # Rebase 37b766f..c351a72 onto 37b766f (2 commands) # # Commands: # p, pick = use commit # r, reword = use commit, but edit the commit message # e, edit = use commit, but stop for amending # s, squash = use commit, but meld into previous commit # f, fixup = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec = run command (the rest of the line) using shell # d, drop = remove commit # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # # Note that empty commits are commented out 它会列出这个commit_id(可以用commit的hash或者HEAD~3这样的形式)的child一直到当前分支的最后一个commit，我们可以在这个界面中编辑想对每一个commit做的操作：\n p，对这条commit不做任何变更 r，使用这条commit，但修改它的commit message e，先暂停rebase，把这条commit修改编辑以后再继续，继续时使用git rebase --continue即可 s，使用这条commit，但把它合并入前一条commit f, 和s相同，但丢弃掉它的commit message x, 在rebase过程中执行一些命令，例如npm test之类确保修改不会产生破坏性内容 d, 移除这条commit  我们在一些场景，例如修改老旧commit的msg、把连续或间隔的多个commit整理为1个等使用交互式变基都会比较方便。\n这种方式看起来没有办法修改最祖先的那条commit，实际上有这种场景时我们可以直接把祖先commit添加到头部即可。在交互式界面中也可以手动调整commit的顺序。有些操作例如修改commit msg，就会产生一个新的commit object，当然也会影响到它的所有child object，因为sha值变了，就得一层层的修改下去。\n常用命令    命令 意义     git diff 比较工作区和暂存区所含文件的差异   git diff HEAD 比较工作区和HEAD所含文件的差异   git diff --cached 比较暂存区和HEAD所含文件的差异   git diff -- \u0026lt;file\u0026gt; 比较工作区和HEAD某个文件的差异   git reset HEAD 暂存区的所有文件恢复的和HEAD一样   git reset HEAD \u0026lt;file\u0026gt; 暂存区某个文件恢复为HEAD那个文件   git checkout -- \u0026lt;file\u0026gt; 工作区某个文件恢复为暂存区那个文件   git reset --hard \u0026lt;commit\u0026gt; 工作区恢复为该commit，回滚和未来均可   git stash 暂存工作现场   git stash apply 恢复工作现场   git stash apply \u0026lt;index\u0026gt; 恢复到某个工作现场   git branch -av 查看所有本地和远程的分支及其对应的commit   git checkout -b \u0026lt;name\u0026gt; \u0026lt;commit\u0026gt; 创建一个分支并切换过去，commit可省略   git branch -f \u0026lt;name\u0026gt; \u0026lt;commit\u0026gt; 强制把某个分支移动到commit处去   git branch -u origin/A 将本地当前分支和远程A分支关联    其他技巧 cherry-pick cherry-pick类似于一个定制化的merge，它可以把其它分支上的commit一个个摘下来，合并到当前分支。\n它的使用方法是git cherry-pick \u0026lt;commid_id1\u0026gt; \u0026lt;commid_id2\u0026gt; ...，就会把每个挑选的commit提交一次生成一个新的commit id。也可以通过git cherry-pick -n \u0026lt;commid_id1\u0026gt; \u0026lt;commid_id2\u0026gt;挑选出相应的commit至暂存区而不提交，后续自己可以再手动提交。\nreflog 引用日志记录了用户在本地更改的完整历史记录，通过git reflog可以查看到类似这样的信息 e1b4a61 (HEAD) HEAD@{0}: revert: Revert \u0026#34;8th commit\u0026#34; 979309d HEAD@{1}: checkout: moving from master to HEAD@{11} c658c0b (master) HEAD@{2}: reset: moving to c658 5665150 HEAD@{3}: reset: moving to 5665 ... 翻译过来就是:\nHEAD@{0} 撤销操作: 撤销的消息 HEAD@{1} 切换操作: 从master切换至HEAD@{11} HEAD@{2} 重置操作: 重置至c658 HEAD@{3} 重置操作: 重置至5665 接着我们就可以使用git checkout HEAD@{1}这样的操作恢复到切换操作时的场景。\nsubmodule 使用场景，例如开发过程中有一些通用的部分希望抽出作为一个公共的库来维护，或者hugo中的某些皮肤也使用了submodule。\n包含子模块的项目，在clone主项目的时候需要带参数git clone \u0026lt;url\u0026gt; --recurse-submodules或者使用git submodule init \u0026amp;\u0026amp; git submodule update。\n如果子模块的内容我们做了变更，在主模块中使用git add/commit是无效的。如果子模块的远程仓库有更新，我们也需要进入子模块文件夹才能获取到更新。\n工作流 工作流(workflow)是指在多人协作的时候，团队以什么样的工作流程有效的合作。\nGit Flow 该工作流为项目设定了两个长期分支，即主分支master和开发分支develop。master存放了对外发布的版本，任何时候在这个上面拿到的都是稳定的发布版。develop用于日常开发，存放最新的开发版本。\n其次，项目根据不同的目的设定了三个短期分支，包括功能分支(feature branch)、补丁分支(hotfix branch)和预发分支(release branch)。一旦完成相应的开发，短期分支被合并入develop或master，然后删除该短期分支。\n这种工作流程使用起来会比较麻烦，因为维护了两个长期分支，可能需要经常切换。它比较适合软件项目，而不是网站项目，因为大多数网站是持续发布的，一有代码变动可能就会更新一次，这时候往往master和develop分支的区别不大，也就没有必要同时维护两套了。\nGithub Flow 这套工作流程在Git Flow上做了简化，只有一个长期分支master，适合于持续发布的场景，是github官方使用的工作流程，它们也做了相关的介绍。其具体流程是这样的:\n 你从master中拉出新分支，不区分是功能还是补丁 新分支开发完成后，就向master发起一个PR PR会让其他人注意到你的请求，也是一种对话机制，让大家都能来参与评审你的代码，对话过程中也可以不断提交代码 你的PR被接受并入master中，原本你拉出来的分支就会被删除  这种流程也有一个问题，它假设master分支和产品的发布是一致的。这在一些场景，例如苹果Appstore的发布可能因为审核要延迟，或有些产品是要指定时间发布的，一个master分支就显得不够了。\nGitlab Flow Gitlab结合了Git flow和Github flow的优点，既能适应不同开发环境的弹性，又仍然只需维护单一分支，官网也有相关介绍。\n它定义了一个原则即上游优先，只存在一个主分支master，它是其他分支的上游。只有上游分支变化了，才能应用到其他的分支。\n对于需要持续发布的项目，它建议在master之外，再根据不同的环境建立分支。例如开发环境定义为master是最上游，预开发环境定义为pre-production是开发环境的下游，生产环境定义为production是最下游。那么当生产环境出了bug，就要新建一个功能分支，先把它合并入master，确认没问题再cherry-pick至预开发环境，最终再进入生产环境。只有紧急情况才允许跳过上游直接并入下游。\n对于需要按版本发布的项目，建议的做法是每一个版本都要从master中拉出一个分支来，如2-3-stable。之后只有修补bug才允许将代码合并入这些分支，更新相应的小版本号。\nFAQ 每次commit，Git储存的是全新的文件快照还是储存文件的变更部分？ Git储存的是全新的文件快照，即使你只修改了文件的一行，也会产生一个新的blob对象。这种储存方式存储的对象格式被称为松散(loose)格式。\n这样势必会造成大量的空间浪费。但是，Git会时不时的把这些松散格式的文件打包成一个称为包文件(packfile)的二进制文件以节省空间和提升效率。手动执行git gc也可以达到这种效果。这也是./git/objects/info和./git/objects/pack两个文件夹的用途。\n为什么要有暂存区的概念，不能直接存储么？ 因为提交是需要原子性的，即一次提交下的文件，要么全部成功，要么全部失败。\n但在Git的命令行下，我们很难像SVN那样有一个图形界面，勾选要提交的文件，填入提交信息，点个按钮就能完成提交。需要git add这个命令帮助我们选择要提交的文件。\n使用merge还是rebase合并分支？ git merge和git rebase都被设计来将一个分支的更改并入另一个分支，但它们的方式却不太一样。\nmerge是一个安全的操作，现有的分支不会被更改。但另一方面，每次合并一个feature分支时都会引入一个外来的合并提交，当同时进行的feature过多时会使得整个树看起来非常杂乱，增加了开发者了解项目历史的成本。\nrebase最大的好处就是使项目的历史非常的整洁、线性，可以从项目的起点开始浏览到终点不需要任何的分叉。但是不合理的rebase会给团队其他人协同开发带来很大的困扰。此外，rebase不能在合并提交时附带message，也就不能像merge那样看到feature分支的并入带来了哪些更改。\n所在，绝不能在公共的分支使用变基，也不能使用git push -f强制推送去修改远程仓库的历史。合理的使用场景应该像下面描述的这样:\n基于上游分支master拉出来一个dev的分支，自行在dev上开发完成后可能master已经有了其他人开发的新的内容，这时应该在dev分支上使用git rebase master把master分支的内容先同步过来，然后在master分支上使用git merge dev把dev分支的内容放回去。\n此外，一般有远程仓库，那么相应的可能是通过git pull --rebase把远程的变更内容拿回来，然后通过PR的方式由远程仓库的管理者决定如何并入远程分支。\n使用revert、reset还是checkout回滚代码？ 代码的回滚可以分为回滚某次提交，或者回滚某些文件两个层面。\n对于回滚提交，应该使用reset和revert。\nreset的本质是把HEAD移动到某个commit的位置，那么该分支从新HEAD到末端的这部分就处于悬挂状态，如果上面没有什么tag或branch引用的话，再下次git进行垃圾回收的时候就会被删除。reset本身有参数，--mixed为默认选项，表示暂存区和将要reset的提交同步，而工作区不受影响；使用--hard表示暂存区和工作区都和将要reset的提交同步；使用--soft表示暂存区和工作区都不做改变。\n而revert是不会改变提交的历史的，它会创建一个新的提交，而这个提交的内容是撤回的部分。所以revert往往用于公共的分支上。\n对于文件提交，应该使用reset和checkout。区别在于checkout用于把工作区中的某个文件恢复为某个commit中的该文件，而reset用于把暂存区中的某个文件恢复至某个commit的该文件，--mixed、--soft、--hard对于恢复文件的场景是无效的参数。\n相关链接  图解git Pro git V2 Write yourself a Git! Dulwich\u0026mdash;Pure-Python Git implementation Oh Shit, Git!?! git可视化 LearnGitBranching  "});index.add({'id':8,'href':'/docs/go/alloc/','title':"Go内存分配",'content':"内存分配 三层结构 对于Go的内存分配器来讲，它有一些处理会比较麻烦，因为要支持高并发，分配的时候就会有一堆人去抢。这时候我们考虑的可能是分配的时候给每个人一个相对大块的内存来减少分配的次数，也就相应的减少了竞争的次数。同时还要考虑不用时需要进行内存回收来复用，我们可以用钢铁厂做个比方。每个人都需要用钢铁做东西，他们的用途可能不太相同，有人拿来做刀，有人拿来做剑，有人拿来做棍棒，有人拿来既做刀又做剑。面对这种情况，我们直接把钢铁厂的钢铁给用户自己去做就不太合适了，就需要在中间加一层生产商更合理。\n这样做的好处是原本需要都去钢铁厂竞争做这把刀的用户，现在在制刀厂竞争了，而且若是一个用户做剑、另一个用户做棍，现在则没有冲突了。商品生产商这一层分散了竞争效应，原本x个人需要竞争一个锁变成了可以竞争n个锁。同时仍然可以一次性买10把刀，来减少和其他人抢的概率，这10把刀可以用来接着内部分配就没有人会来抢，当然这里会有一定的浪费，属于空间换时间的做法。\n垃圾回收的时候，如果10把刀只用了2把，剩下的8把就可以返还给制刀厂，给其他人用。这实现了一级平衡，即在相同类型之间的平衡。也有可能由于种种原因出现刀冗余非常多的情况，这时候就可以把刀返还给钢铁厂全部熔了做其他东西，这属于二级平衡，在材料上的平衡。\n通过这三层结构，我们实现了两个级别的平衡，达到了一定程度上的复用效果。那么需要多少种商品生产商呢？不可能因为每个人需求不同就给设定相应的商品生产商，我们需要对商品进行分类。对于内存分配器来说，它关心的是商品大小，先以32KB为界，把对象分为大对象和小对象。对于大于32KB的大对象，用户代码中这种对象往往很少，分配和回收都可以进行特殊对待。对于小对象，我们按照8字节对齐，分为66种SizeClass，例如8字节、16字节、32字节、48字节等等，对于1个9字节的对象，就会给它分配16字节，这可能会造成一定的空间浪费，但不至于产生过多的内存碎片。\n现在，我们可以把钢铁厂叫做堆(Heap)，它向操作系统申请内存，负责管理原始材料。这66种商品生产商我们称为中间对象(Central)。再下面的人属于具体分配者，我们称为Cache，其实它就是缓存了一大批需要的东西接下来用于实际的分配。我们把每块从操作系统拿到的内存叫做Span，每个Span需要按一定规格进行切分，例如规格2就是按16字节来切分，切分后形成了若干个小块，每个小块我们称为Object。现在变成了这样:\n每个Central分配的时候给的是一个切好了的Span，每个Cache返还的时候也是还整个Span，即使其中有部分Object被用掉了也只是标记一下。\n接着还有一些其他问题，第一是操作系统虚拟地址分配的问题，我们希望是在某个固定的地址段之内紧凑的进行内存分配来避免内存碎片化。这样我们就需要先提前占用一段内存空间，做为保留空间，并不进行实际的分配动作，我们把这段空间叫arena。那么如何在进程中找到这样一段连续的地址空间呢？首先向操作系统申请内存，操作系统必然会给一个可用的虚拟内存地址；然后尝试按这个地址向右扩张，如果右边被堵住了就向左边扩张；如果两边都被堵住了就再次向操作系统申请内存，接着尝试向右向左扩张的操作。64位地址空间还是很大的，往往很容易找到这样一段空间。\n第二是每个Span还需要位图(bitmap)来标记哪些是可用的，我们所说的切分Object也只是便于理解上的切分，实际上我们要找到一个可用的Object，就是用这个Span的起始地址加上位图中可用对象的偏移量乘以SizeClass的大小，即base+offset*size。\n第三，我们还需要一个反查表，它记录了每个Span的起始地址。为什么需要这样一个表呢？假设某个Span里面有100个Object，我们只需要使用其中的10个Object，就可以根据反查表的信息把这个Span一分为二，把剩余的90个Object组成一个新的Span拿回来。拿回来之后还能通过反查表检查它左右相邻的Span是不是闲置的，如果闲置则可把他们合并为一个大的块。所以Span的大小可能不是固定的，根据需要可能会切分或合并。\n分配过程 现在我们可以整理一下整个内存分配的过程。首先堆Heap会向操作系统申请64MB内存，操作系统是机会主义的分配原则，实际上给你的是64MB的期货，之后以页为单位发生读写时分配物理内存。分配之后就有一大堆的Span需要去管理，Heap采用了树堆这种数据结构管理Span。树堆长得像树一样，同时增加了一些堆的特性，排序能按照地址来排序，它的好处是分配给Central时总是会尽可能找到一个大小合适而且地址靠前的Span，地址靠前使得内存相对来说更加的紧凑。Central拿到之后只是做一些属性的设置，重置一下Span的位图等。Cache通常会和P绑定，M需要内存的时候就去找P拿，P再找Cache，Cache再找Central。所以Cache内会有一个数组，数组内容是以SizeClass为索引的Span，P/M在Cache上分配内存时是无锁的。例如用户若需要一个7字节大小的内存，计算得出对应的SizeClass是1#，就会通过P/M去cache[1]中看有没有Span，没有就去Central中拿，如果已经有了就去看这个Span的位图中有没有空余的空间。而如果用户需要的是一个大于32KB的大对象，则跳过Central直接去堆上拿即可。\n小对象中还有两种特殊的对象，一种是长度为0的对象，另一种是微小对象。对于长度为0的对象，比如空结构体，我们不应该为其分配内存，但得给它一个合法的地址。Go专门有一个全局变量叫ZeroBase，不管是什么对象，只要它长度为0就会去指向这个全局变量的地址。\n// src/runtime/malloc.go // base address for all 0-byte allocations var zerobase uintptr func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { if gcphase == _GCmarktermination { throw(\u0026#34;mallocgc called with gcphase == _GCmarktermination\u0026#34;) } if size == 0 { return unsafe.Pointer(\u0026amp;zerobase) } ... } 微小对象则属于分配中比较常见的，例如短字符串等。如果发现需要分配一批微小对象，每个都占用一个1#Span中的Object可能不太合适有太多的浪费，就会从一个2#Span中提取出一个Object(16字节)，对它特殊记录并把多个微小对象都放进去，这有助于节约内存。但是这些微小对象中不能包含指针，因为它不能去引用其他地方，这样垃圾回收器才会把它当做一个整体去扫描。\n回收过程 回收的过程是这样的，垃圾回收启动时，会要求把Cache中的Span块都上交回Central。这种收回来的Span通过扫描位图会有两种情况，一种是里面已使用但有空位，那把它拿回来了就可以留给其他Cache用。另一种是整个Span都是没有人用的，这种就可以当成原材料交回给Heap。\n在Heap中也可能有一大堆Span闲置，读写过后不用了的，可能有几百兆、上千兆，就需要还给操作系统。还给操作系统有两种方式，第一种是主动方式，可能Central刚刚拿了一个大小为10MB的Span块，Heap就去找有没有恰好10MB的块来还给OS达到一种平衡；另一种是背后有一个Goroutine会每过一小段时间监测一次Heap上空闲的Span大小是否到达一个阈值，有就向操作系统申请释放。在Go1.13之前这个Goroutine是看若某Span块闲置超过5分钟则返还给操作系统，而1.13是动态调整监测的时间，比如第一次100微秒发现闲置Span不超过阈值，则下次就会间隔200微秒再去扫描。\n不同的操作系统对于内存回收这件事的处理方式也不太一样，对于Unix-Like的OS来说，是向操作系统发出建议，回收哪一段的内存，至于操作系统是否接受建议、怎么处理，操作系统可能会根据物理内存的剩余情况做决定。即便接受了回收，也只是把它变成了期货，它的虚拟地址空间一直是存在的。\n"});index.add({'id':9,'href':'/docs/go/goroutine/','title':"Go并发机制",'content':"Go并发调度 背景知识 GO和其他语言不同的就是我们很少在GO中听到多线程的概念，其提供的API中也没有创建线程这种东西。因为这门语言从用户写的第一行代码开始就是并发状态的。\n并发与并行 并发是指多个逻辑可以同时执行，把CPU时间分成不同的时间片段，这些时间片段分配给不同的逻辑，构成一个完整的CPU执行时间序列。 而并行是一种特殊的并发，不同逻辑由于CPU的多核，分配在不同的核上可以在物理时间上同时执行。这种状态其实很难实现，因为往往任一操作系统，它本身跑的程序非常多，远大于CPU核数。\n线程与协程 线程是执行单位，相当于工厂里的生产线。操作系统是按线程分配时间片，所以程序的线程越多获得的执行时间也就越长。线程是在系统空间实现的，而协程是在用户空间实现的，操作系统根本不知道协程。\n比如某个线程上有A、B两个任务，若A有死循环或者A等待网络响应等就会发生B被饿死的情况，为了避免这种情况，A就会主动让给B或者调度器去执行。这就是协程的工作方式，任务之间相互协商，属于协作式多任务系统，通常是在用户空间实现一个框架。而多线程是抢占式调度，不管某个程序会不会主动让出，当前时间片执行完就会被操作系统强迫分给其他线程。\n程序等于算法加数据，算法相当于一个解决问题的过程，数据又分为系统数据和用户数据。用户数据保存在用户堆栈上。操作系统为每个线程分配一个栈，大多用来保存局部变量，通常编译期就能确定，运行期通过寄存器访问，无需垃圾回收。而堆内存属于进程，进程内的线程共享，需要运行期动态分配以及垃圾回收。\n运行时 现代的编程语言创建一个线程往往是使用一个标准库或者第三方库提供API的，分配内存也往往会向操作系统提前申请一大块内存，通过这样一层抽象来减少用户态和内核态的切换来提升效率，我们把这层抽象叫做runtime(运行时)。它就像一个弱化版的操作系统，可以针对用户空间内的代码，结合当前语言的特性做大量的优化。\nGo运行时第一个抽象出的概念就是P(Processor)，相当于处理器。物理上有多少个CPU、有多少个核，runtime并不关心，它是在OS上的一层抽象，os才是在硬件的上一层抽象。runtime认为在当前的环境内只有一个程序，所以我们可以通过P来设定并发的数量，同时能执行这个程序内的多少个并发任务。\n第二个抽象是M(Machine)，对应了一个系统线程，是对线程的包装，也就是说P控制了同时有多少个M在执行。它是实际执行体，和P绑定，以调度循环方式不断执行G并发任务。\n第三个抽象就是G(Goroutine)，实际上就是任务载体，或者说资源包，包括了函数地址，需要的参数，所需的内存。当我们使用go func(){}()时，实际上就是创建了一个G对象。\n为什么G需要内存，按说M相当于线程也就应该有了栈内存？实际上它们都有自己的内存，G中的内存为G.stack(默认大小2KB)，M中的内存为G0。G在M上运行，就像是列车在线路上运行，线路本身也需要去投入资源维护。而把两块内存分开，是因为M所需的内存比较连续、相对固定、逻辑完整，G却会因为各种各样的原因或者异常可能会调度到别的M上去。\nG、M、P共同构成了多任务并发执行的基本模式，P用来控制同时有多少个并发任务执行，M对应到某个线程，G代表了go func语句翻译的一个任务包，最终还得有个调度器统合起来，把G放到合适的M上去执行。\n任务平衡 正向分析 当我们在一个for循环中创建了成千上万个并发任务时，它们并不是立即执行的，而是打包成一个个G对象保存在两个队列中(P本地队列和G全局队列)。\n假设当前只有4个P，在main函数执行的时候就需要一个P1/M1绑定体，main中创建的其他go func就会打包成G对象放在P1.queue中。也就是说任一M内创建的G都会保存在当前这个P的本地队列中，为什么不能放在P2、P3、P4的队列中？放在别的队列就需要去判断这个P是不是闲置的，还可能需要加锁等等，会变得很复杂。\n那么如果在main中创建了1000个G，它们就得等P1/M1中当前的任务执行完了才会得到执行，可能P2、P3、P4都是闲置的，这明显不合理。如何在多个P之间去平衡任务呢？使用了两种方法，一种是规定了每个P本地队列只能放256个G，一次放的过多时会按一定规则比如放一半到全局队列中去；另一种是某个P若闲置了就会在全局队列中去找(可能有很多P都在全局中找，就需要排队去找)，找到了就把一部分任务移动到自己的本地队列中，没有找到就会去其他P中偷一部分任务过来，从全局队里或其他P中偷都是需要加锁的，效率相对会低一些。\n这样的平衡方式也就决定了我们没有办法确定哪个方法先执行，哪个后执行，除非我们自己写逻辑去判断先后。我们再来看一个关于执行顺序的示例:\nfunc main() { runtime.GOMAXPROCS(1) // 设置P为1  for i := 0; i \u0026lt; 10; i++ { go func(id int) { // 创建10个G  time.Sleep(time.Second) fmt.Println(id) }(i) } time.Sleep(time.Second * 2) } 执行结果:\n[ubuntu] ~/.mac/gocode $ go run goroutine.go 9 0 1 2 3 4 5 6 7 8  为什么当P为1的时候，它不是顺序输出的，9总是在第一个？\n 每个P的本地队列中其实包含两个部分，runnext[1]和runq[256]。当我们每次添加一个任务的时候，它会先放在runnext中，再添加一个任务时，会把新添加的放在runnext，之前添加的放在runq中。runnext总是保留用户最后创建的任务，执行的时候先查runnext去执行。\n 为什么要有runnext的设计？\n 假设只创建了一个并发任务，也放在runq中让别的P去抢没有必要，而且大多数情况下我们不会去批量创建G；另外若runq既用来P1执行又让P2、P3去偷，那就又会涉及到加锁。\n 那么为什么是G9放在runnext，而不是G0？\n 因为放在runnext以后我们无法保证还有多少逻辑执行完才轮到它，就可能会runq中的任务都被偷走了且执行完了G0才会执行，这对G0很不公平。\n显然任务被分成了三个性能层次，runnext是完全私有的，runq属于原子操作(原子操作对CPU来讲也是锁，锁的是地址总线)，Global属于一定要加mutex锁的，这三个层次产生资源竞争的可能性逐步增大。\n逆向分析 在最开始的时候，我们先设计为一个循环队列，它底层结构可能就是一个数组。问题在于，当有多个人去竞争的时候，这个数组就会存在资源竞争效应，我们就会考虑加入锁，显然这种效率是最低的。\n假设现在有3个P/M，我们就可以把一个大的队列拆分成3个小的队列，让每个P/M持有一个私有的队列，这种优化策略使得锁的问题可以解决掉。但也带来新的问题，可能P1已执行完自己的任务，P2、P3还得执行很久，我们可能一开始按任务的数量平均分配至各个私有队列，但有的任务执行时间很长，有的任务很快就能执行完。\n因此，P1应该去P2、P3中拿取任务才是合理的，所有人有义务去完成整个系统的任务。P1直接去拿就会和P2、P3打起来形成竞争效应，第二步的优化策略就是保留一个全局队列，P1可以先去全局队列里找，而P2、P3有很大概率是在本地队列去找的，P1获得锁的概率就会更大，全局队列使得锁的压力被分摊，同时也使得P2、P3中若有多余的任务也可以放进去。\n当P1的本地队列已执行完，全局队列中的任务也被执行完时，它就会任选P2或P3，形成直接的竞争。这时候我们考虑的优化策略，就是把本地队列一分为二，上面是runnext用于本地执行，下面是runq[256]用来给P1偷的。\n这种结构很像CPU的存储结构，通过分散距离、增加存储层次来减少直接竞争冲突的概率。\n调度执行 P、M解绑 当我们创建一个G的时候，实际上是背后的调度器在当前M上的G0去执行的，它发现有新的任务出现时，会发出一个唤醒信号，去检查有没有P空闲的，以及有没有M是休眠状态的？若P空闲且没有休眠的M，就会去创建一个M对象。所以唤醒操作要有意义，就得有P闲着没事干。\n那么M是怎样变为休眠状态的？\n当一个P和M绑定之后，它会进入到一个调度程序(Schedule函数)，调度程序会去找G对象(按runnext、runq、Global、other P的顺序)，找到之后内存由G0上执行切换到G.stack上去执行，执行完成之后进入收尾阶段，清理现场把G当做一个包装对象让它能重复使用。然后重新回到Schedule函数形成一个调度循环。\n这个循环可能因为找不到G对象而中断，比如说当前就只有一个任务。那么P和M就会解绑，M会进入休眠状态。\n还有一种P和M解绑的情况，比如当前在进行一个系统调用，而这个系统调用花了很长时间，调度器就会把这个P拿走干别的事，而M压根不知道，因为它在内核态，等系统调用结束以后M发现找不到P，那它就没法继续执行，只能把当前的任务状态保存回G.stack，在把执行一半的任务重新放回队列，M再次进入休眠状态，执行一半的任务再下次遇到P/M时接着执行。\n这就可能导致一个问题，创建出大量的空闲的M，不会被回收。M是会在操作系统内核中创建一个线程，尽管这种休眠状态下的M不会被CPU分配时间片，但仍然会占用管理资源，另外每个M上都带着G0内存，相当于资源泄漏了。我们通过如下代码来模拟这种情况：\nfunc main(){ for i :=0;i\u0026lt;1000;i++{ go func(){ runtime.LockOSThread() //通过锁模拟系统调用  defer runtime.UnlockOSThread() time.Sleep(time.Second*5) }() } time.Sleep(time.Minute) } 通过go build test.go \u0026amp;\u0026amp; GODEBUG=schedtrace=1000 ./test运行：\nSCHED 0ms: gomaxprocs=4 idleprocs=2 threads=5 spinningthreads=1 idlethreads=2 runqueue=0 [0 0 0 0] SCHED 1002ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 2008ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 3013ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 4014ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 5015ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=127 runqueue=0 [0 0 0 0] SCHED 6017ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] SCHED 7025ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] SCHED 8027ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] SCHED 9029ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] SCHED 10031ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=1007 runqueue=0 [0 0 0 0] 我们发现任务开始的时候共创建了1010个线程，任务执行完以后，仍然有1007个休眠的线程。当我们把runtime.LockOSThread()注释掉，重新运行：\nSCHED 0ms: gomaxprocs=4 idleprocs=1 threads=5 spinningthreads=1 idlethreads=1 runqueue=0 [48 49 133 0] SCHED 1004ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 2008ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 3010ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 4015ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 5026ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=7 runqueue=0 [0 0 0 0] SCHED 6031ms: gomaxprocs=4 idleprocs=4 threads=9 spinningthreads=0 idlethreads=7 runqueue=0 [0 0 0 0] 发现没有系统调用，那就根本不会有那么多线程。我们再把runtime.LockOSThread()保留，defer runtime.UnlockOSThread()去掉，运行结果如下：\nSCHED 0ms: gomaxprocs=4 idleprocs=2 threads=5 spinningthreads=1 idlethreads=2 runqueue=0 [0 0 152 0] SCHED 1000ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 2001ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 3008ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 4016ms: gomaxprocs=4 idleprocs=4 threads=1010 spinningthreads=0 idlethreads=4 runqueue=0 [0 0 0 0] SCHED 5019ms: gomaxprocs=4 idleprocs=0 threads=938 spinningthreads=0 idlethreads=4 runqueue=0 [18 1 3 7] SCHED 6027ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] SCHED 7037ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] SCHED 8042ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] SCHED 9044ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] cSCHED 10047ms: gomaxprocs=4 idleprocs=4 threads=13 spinningthreads=0 idlethreads=10 runqueue=0 [0 0 0 0] 我们发现那些创建的线程是会被回收的，线程没有被解锁意味着线程的状态没有被解除而陷入了死锁状态，线程不能再去接收新的任务没有存在的意义自然会被杀掉。\n综上，我们发现P往往是恒定的，而G和M是可复用的，复用虽然可能造成资源的浪费，但它避免了重新创建时的可能造成的竞争效应。对于一些长期运行的东西，我们需要再创建还是释放之间做一些权衡。\n任务饿死 假设当前的P/M正在执行一个G，这时候G里面创建了一个G1，G1会被放到当前P的runnext中，但它可能迟迟得不到执行被饿死，因为G中可能还有大量的逻辑代码执行完才轮到runnext，这显然是不合理的。怎么解决这个问题呢？是否可以让当前这个P/M交替的执行G和G1？P不是真正的CPU，没法实现基于时间片的抢占式调度，只能实现类似于协程那样的协作式调度。很多语言里都使用类似于Gosched()这样的函数来主动交出执行权，但Go中却很少见；还有一种形式是runtime带一个计数器，每执行一个任务后累加计数，当到达一个指定的计数就会被认为是使用完了时间片，向当前执行的P/M发出一个抢占式的信号，然后G主动让出执行权限。Go到底是怎样做的？我们来看如下示例：\n// GODEBUG=schedtrace=1000,scheddetail=1 ./test 可查看运行期GMP状态 func main(){ runtime.GOMAXPROCS(1) for i:=0;i\u0026lt;3;i++{ go func(id int){ println(id) x := 0 for{ // 死循环  x++ //print()  } }(i) } time.Sleep(time.Second) } 我们模拟了只有一个P/M，这时候创建了3个G，让第一个G执行的过程中进入死循环，运行结果就是只打印出了任务0，其他G被饿死了。但当我们在死循环内x++后面加入一个函数，则任务0、1、2都会被打印出。问题就出在这个函数上。\n我们先使用一个简单的函数来观察：\n//go:noinline func test(){ println() } func main(){ test() } 使用go build \u0026amp;\u0026amp; go tool objdump -s \u0026quot;main\\.test\u0026quot; test反汇编：\nTEXT main.test(SB) /mnt/hgfs/disk/test.go test.go:5\t0x4525b0\t64488b0c25f8ffffff\tMOVQ FS:0xfffffff8, CX\ttest.go:5\t0x4525b9\t483b6110\tCMPQ 0x10(CX), SP\ttest.go:5\t0x4525bd\t7624\tJBE 0x4525e3\ttest.go:5\t0x4525bf\t4883ec08\tSUBQ $0x8, SP\ttest.go:5\t0x4525c3\t48892c24\tMOVQ BP, 0(SP)\ttest.go:5\t0x4525c7\t488d2c24\tLEAQ 0(SP), BP\ttest.go:6\t0x4525cb\te80031fdff\tCALL runtime.printlock(SB)\ttest.go:6\t0x4525d0\te88b33fdff\tCALL runtime.printnl(SB)\ttest.go:6\t0x4525d5\te87631fdff\tCALL runtime.printunlock(SB)\ttest.go:7\t0x4525da\t488b2c24\tMOVQ 0(SP), BP\ttest.go:7\t0x4525de\t4883c408\tADDQ $0x8, SP\ttest.go:7\t0x4525e2\tc3\tRET\ttest.go:5\t0x4525e3\te8187bffff\tCALL runtime.morestack_noctxt(SB)\ttest.go:5\t0x4525e8\tebc6\tJMP main.test(SB)\t 我们发现头部的三条指令和尾部的两条指令都是编译器插入的。runtime.morestack_noctxt会做两件事情，一是检查当前栈帧空间是否足够，如果不够可以帮助扩容；二是检查是否有人发出了抢占式调度信号，如果发现了信号，它就让出执行权限。函数前使用go:nosplit可以禁止编译器插入这样的指令。\n"});index.add({'id':10,'href':'/docs/mysql/theory/','title':"Mysql原理",'content':"Mysql的原理 查询执行过程 一条SQL查询语句在Mysql中是如何执行的呢？我们可以通过它的基本结构图看到各个模块在执行过程中起到的作用:\nServer层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖Mysql大多数核心服务功能，以及所有的内置函数、跨存储引擎的功能实现(如存储过程、触发器、视图等)。而存储引擎属于插件式架构，支持InnoDB、MyISAM、Memory等多个存储引擎，不同引擎共用一个Server层。\n连接器 客户端一般通过TCP与服务端建立连接，用户名密码认证通过后，连接器先到权限列表中查出你拥有的权限，之后这个连接里的权限判断逻辑都依赖于此时读取到的，也就是说对这个权限的修改不会影响到已经正在连接的用户。\n正在连接的客户端可以这样查看到: mysql\u0026gt; show processlist; +----+------+-----------------+---------+---------+------+----------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+------+-----------------+---------+---------+------+----------+------------------+ | 4 | root | localhost | awesome | Query | 0 | starting | show processlist | | 7 | root | localhost:58134 | boss | Sleep | 3 | | NULL | | 8 | root | localhost:58135 | NULL | Sleep | 2 | | NULL | +----+------+-----------------+---------+---------+------+----------+------------------+ 3 rows in set (0.00 sec) Command列中显示为Sleep就表示该连接当前是空闲的，如果连接空闲太长时间就会被连接器自动断开，默认是8小时，可通过wait_timeout控制。\n查询缓存 大多数情况下，我们往往不使用查询缓存，因为它是弊大于利的。它的失效非常的频繁，只要对一个表有更新，这个表上的所有查询缓存都会被清空。对于更新压力大的数据库来讲，查询缓存的命中效率很低。\nMysql8.0以上版本直接将该功能删掉了，所以我们的结构图上也只是把它画成一条支线。\n分析器 词法分析就是根据一些关键词判断出你要做什么，例如select表示这是一个查询语句。那么接下来就会把字符串T识别为表名T，字符串ID识别为列名ID。\n接着进行语法分析，就是判断输入的语句是否满足语法规则。语法错误的提示就是在这个阶段触发的，例如You have an error in your SQL syntax。\n优化器 优化器是在表里有多个索引的时候决定使用哪个索引；或者有多表关联的时候决定各个表的连接顺序。例如select * from t1 join t2 using(id) where t1.c=10 and t2.d=20，就可以有两种处理方式:\n 先从表t1中取出c=10的记录的id，根据id关联到表t2，判断t2中d的值是否为20 先从表t2中取出d=20的记录的id，根据id关联到表t1，判断t1中c的值是否为10  这两种方法执行的效率可能不同，优化器就是用来决定使用哪种方案更合理。\n执行器 执行时，先去判断该用户有没有对这个表的要做的操作的权限，如果没有会返回相应的错误。有权限的话则打开表继续执行，执行器会根据表的引擎定义，使用过这个引擎提供的接口来执行。\nInnoDB InnoDB是一个将表中的数据存储到磁盘上的存储引擎，真正处理数据的过程是发生在内存上的，所以需要把数据从磁盘加载到内存中，如果是处理写入或更新时，还需要把内存中的内容写回磁盘中。InnoDB将数据划分为若干个页，每页大小为16KB，以页做为硬盘和内存交互的基本单位，一般情况下，每次至少会读取或写回16KB的内容。\n数据页 这些页有很多的种类，例如存放空间头部信息的页、存放日志信息的页等等。我们先来了解存放记录的页，也就是数据页，官方称为索引页。\n数据页被分为7个部分，有的部分占用固定大小的空间，有的不固定:\n   名称 中文名 占用空间 简单描述     File Header 文件头部 38字节 页的一些通用信息   Page Header 页面头部 56字节 数据页专有的一些信息   Infimum + Supremum 最小和最大记录 26字节 两个虚拟的行记录   User Records 用户记录 不确定 实际存储的行记录内容   Free Space 空闲空间 不确定 页中尚未使用的空间   Page Directory 页面目录 不确定 页中的某些记录的相对位置   File Trailer 文件尾部 8字节 校验页是否完整    在⻚的7个组成部分中，我们自己存储的记录会按照我们指定的行格式存储到User Records中。但在一开始生成⻚的时候，其实并没有User Records这个部分，每当我们插入一条记录，都会从Free Space中申请一个记录大小的空间划分到User Records，当Free Space的空间全部被替换掉后，也就意味着这个⻚使用完 了，如果还有新的记录插入的话，就需要去申请新的⻚了。\n每条记录的头信息中有一个next_record属性，从而使页中的数据串联成一个单链表，链表中的各个节点按主键的值由小到大连接起来。Innodb会把这些记录分成若干个不同的组，每组的最后一条记录的地址偏移量会存放在Page Directory中，这样通过主键在一个页中查找到一条记录就会非常的快，首先通过二分法查到它应该在哪个组中，接着遍历这个组找到相应的记录。\nFile Header主要存了上一页和下一页的编号，使得所有的数据页构成一个双向链表。而File Trailer会加入一些效验值，以保证从内存至硬盘同步数据的完整性。\n行格式 每条用户记录在磁盘上的存放方式也被称为行格式或记录格式，行格式被分为四种，即Compact、Redundant、Dynamic和Compressed。它们原理上大体相同，所以我们以Compact格式为例来详细了解一下。\n如图所示，每条记录被分为两个部分，记录的真实数据和记录的额外信息。 Mysql支持一些变长的数据类型，如VARCHAR、各种TEXT、各种BLOB等类型，对于这类变长字段，除了存放它们真正的数据内容，还需要存它们占用了多大空间，在Compact中，会把它们占用多大空间按列的逆序存放在每条记录的头部。所以第一部分就是变长字段长度列表，它只存非NULL值的变长字段的列，如果表中没有变长字段，那就没有这一部分。但是如果当前表采用的字符集是变长字符集，那么对于CHAR类型的字段所占用的空间也会被加入到变长字段长度列表中。\n为了让NULL值不占用过多的空间，Compact把NULL值的列统一管理在一个地方。它首先会统计表中哪些列允许有NULL值，即忽略掉主键列和被NOT NULL修饰的列；其次将这些统计出来的列逆序的对应一个个二进制位，每位为1时就代表这列当前的值为NULL。同样的，若表中没有允许存储NULL的列，那么这部分也不存在。\n而记录的头信息都是一些二进制位，共计40位:\n   名称 大小(bit) 描述     预留位1 1 没有使用   预留位2 1 没有使用   delete_mask 1 标记该记录是否被删除   min_rec_mask 1 B+树的每层非叶子节点中的最小记录都会添加该标记   n_owned 4 表示当前记录拥有的记录数   heap_no 13 表示当前记录在记录堆的位置信息   record_type 3 表示当前记录的类型   next_record 16 表示下一条记录的相对位置    对于记录的真实数据部分，Mysql会为每条记录默认的添加一些列，也就是隐藏列，包括:\n   列名 是否必须 占用空间 描述     DB_ROW_ID 否 6字节 行ID，唯一标识一条记录   DB_TRX_ID 是 6字节 事务ID   DB_ROLL_PTR 是 7字节 回滚指针    对于主键，优先使用用户定义的，如果未定义则选取一个Unique键作为主键，如果没有Unique键则会添加一个DB_ROW_ID的隐藏列作为主键，所以这个隐藏列可能不存在。\n之前提到一个数据页只有16KB，也就是16384字节，而VARCHAR、CHAR、TEXT、BLOB等字段都有可能大于它，这就造成了一个页存放不了一条记录的情况。我们把这种现象称为行溢出。对于这种情况，Compact会在记录的真实数据部分只存储这条记录的一部分，剩余的数据分散在其他的页中，然后真实数据部分还有20个字节指向这些页的地址。Dynamic、Compressed的行格式和Compact很像，只是在处理行溢出时有些不同罢了，它们只在记录的真实数据处存其他页面的地址，数据都在其他页面。Compressed采用压缩算法对页面进行压缩以节省空间。Mysql5.7默认的行格式就是Dynamic，Redundant属于Mysql5.0之前的快被淘汰的格式。\n数据目录 InnoDB、MyISAM这样的存储引擎会把数据存储在硬盘上的数据目录中，它不是安装目录，可通过如下命令查看: mysql\u0026gt; SHOW VARIABLES LIKE \u0026#39;datadir\u0026#39;; +---------------+-----------------------+ | Variable_name | Value | +---------------+-----------------------+ | datadir | /usr/local/var/mysql/ | +---------------+-----------------------+ 1 row in set (0.00 sec)\n在这个目录中，我们每新建一个新的数据库，Mysql会帮我们创建一个同名的文件夹，并在该文件夹内创建一个db.opt的文件，它包含了这个数据库的属性，例如数据库的字符集和比较规则等。之后我们在某数据库创建一个表时，Mysql会为我们创建一个表名.frm的文件，它存储了表结构的定义；InnoDB会为我们创建一个表名.ibd的文件，它是一个独立的表空间文件，存储了一页页的数据。\nMysql有四个系统库，但information_schema库被特殊对待，没有相应的文件夹，它保存着MySQL服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引，都是一些元数据；mysql库存储了MySQL的用户账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等；performance_schema库主要保存MySQL服务器运行过程中的一些状态信息，算是对MySQL服务器的一个性能监控，包括统计最近执行了哪些语句，在执行过程的每个阶段都话费了多⻓时间，内存的使用情况等；sys库主要是通过视图的形式把information_schema和performance_schema结合起来，让程序员可以更方便的了解MySQL服务器的一些性能信息。\n此外，默认情况下，InnoDB还会在该目录下创建ibdata1这样一个文件，表示系统表空间。MySQL5.5.7到MySQL5.6.6之间的各版本，表中的数据都会被默认存储到这个系统表空间。该目录下还包含服务器进程文件，服务器日志文件，自动生成的RSA、SSL证书和密钥文件等。\nMysql的视图是虚拟表，也会在对应的库文件夹下创建一个frm文件存储。\n表空间 索引 在没有索引的情况下，我们无法快速定位到数据所在的页，只能从第一个页沿着双向链表依次向下找每个页，在每个页中如果查找的不是主键，还得依次去比对每条记录。显然，这种查询效率是非常低的。\n聚簇索引 我们先来考虑一种简单的索引方式，先把页的结构简化来看。\n数据页中我们暂时认为每页存储三条记录就满了，每条记录我们只关注record_type，0表示普通记录，2表示最小记录，3表示最大记录，以及next_record表示下一条记录。\n接下来对于数据的增删改操作，我们必须通过一些诸如记录移动的操作来始终保证这个状态一直成立:下一个数据⻚中用户记录的主键值必须大于上一个⻚中用户记录的主键值。这个过程称为⻚分裂。有了这个状态的保证，我们可以给每个页建立一个目录项，每个目录项包括其对应的页号以及页中用户记录的最小的主键值，大概是这样的:\n这形成了一个简单的索引方案，我们把这些目录项放到一个数组中，当通过主键查找时就能通过这个数组找到对应的数据页，在根据数据页的Page Directory和二分法就可以迅速找到记录。\n这个方案的问题是我们需要一段连续的物理空间来放这个存储目录项的数组，但Mysql只能保证页的数据是连续的，即16KB的连续空间。随着表中的数据越来越多，多到16KB根本放不下这些目录项怎么办？另一个问题是如果我们删除数据记录使得某一页中没有内容，那么这页就没必要存在，那么这页对应的目录项也没必要存在，把目录项删除后其后的目录项都得向前移动一下，这显然不是好的设计。\n因此InnoDB复用了数据页来存储目录项，每条记录就是一个目录项，只不过这条记录的record_type是1，表示这是一条目录项记录，现在变成了这样:\n如果一个目录页放满了，就新增一个目录页，同时在其上再加一层目录页记录这两个目录页。这种数据组织方式就是B+树。\n这种组织方式有两个特点:\n1、使用记录主键值的大小进行记录和⻚的排序，这包括三个方面的含义:\n ⻚内的记录是按照主键的大小顺序排成一个单向链表 各个存放用户记录的⻚是根据⻚中用户记录的主键大小顺序排成一个双向链表 存放目录项记录的⻚分为不同的层次，在同一层次中的⻚是根据⻚中目录项记录的主键大小顺序排成一个双向链表  2、B+树的叶子节点存储的是完整的用户记录，即记录中包含了所有列的值。\n我们把符合这两个特点的B+树称为聚簇索引，InnoDB会自动为我们创建聚簇索引，而由于所有的记录都在叶子节点上，也就是所谓的索引即数据，数据即索引。\n二级索引 上面的聚簇索引只在搜索条件是主键是才起作用，如果以别的列为搜索条件又怎么办呢？我们可以多建几颗B+树。效果如图所示:\n这颗B+树假设我们以x列去建立索引，那么每个数据页内的记录就是按照x列的大小顺序排列的，和上面的类似，不同的是这条记录只有一个x列的值和其对应的主键的值。所以，当我们去按x=3这样的搜索条件查找数据时，就会先根据这颗新的B+树确定x=3时对应的主键是什么，在根据主键去聚簇索引中查找到完整的一条记录。这个过程也被称为回表。二级索引(Secondary index)这个名称也正是因为需要两颗B+树，操作两次。\n我们观察到上图中存储目录项的记录只包含了x的值和页号，实际上这在二级索引中会存在bug，有可能很多条记录中x的值都是相同的，此时再插入一条记录就不知道要插在哪个位置了。因此这颗B+树中叶子节点每条记录是x的值和主键的值，x相同则按主键大小顺序排列，目录项节点的每条记录是x的值、主键的值、页的号码，x相同时也可按主键排序。\n联合索引 联合索引就是同时以多个列作为排序规则，比如列x和列y的联合索引就是先以x为排序依据，x相等时以y作为排序依据。只需要根据二级索引的B+树稍作改造即可，每条记录存放x、y和主键的值即可。\n使用场景 哪些情况能用到索引，哪些情况无法用到呢？我们通过一个例子来看: CREATE TABLE person_info( id INT NOT NULL auto_increment, name VARCHAR(100) NOT NULL, birthday DATE NOT NULL, phone_number CHAR(11) NOT NULL, country varchar(100) NOT NULL, PRIMARY KEY (id), KEY idx_name_birthday_phone_number (name, birthday, phone_number) ); 先建了一个表，其中有一个自动为主键id建立的聚簇索引，和一个二级索引idx_name_birthday_phone_number，它是由三个列组成的联合索引。如下情况可以使用到索引:\n全值匹配 当我们的搜索条件中的列和索引中的列一致时，如SELECT * FROM person_info WHERE name = 'Ashburn' AND birthday = '1990-09-27' AND phone_number = '15123983239';，若调换name、birthday、phone_number的顺序也是可以使用到索引的，因为Mysql的查询优化器会帮我们优化这种情况。\n匹配左边的列 在搜索语句中，也可以不包含全部索引的列，只匹配左边的部分列。如SELECT * FROM person_info WHERE name = 'Ashburn';是可以用到索引的，搜索条件中的列只要是从联合索引列的最左边开始的、连续的列就能匹配到。\n匹配列前缀 对于字符串而言，其排序的本质就是比较字符串的大小，一般的规则就是比较逐个字符的大小，也就是说只匹配字符串的前n个字符也是可以用到索引的，如SELECT * FROM person_info WHERE name LIKE 'As%';，但若没有从第一个字符开始匹配则用不到索引。有时候我们有匹配字符串后缀的需求，例如某一列是url，其前缀都是www，这种情况我们可以把表中的数据逆序存储，再使用匹配列前缀的方式就可以用到索引了。\n匹配范围值 当我们需要一个范围的值时也可以用到索引，因为所有记录都是按照索引列的值由小到大的顺序排列的。如SELECT * FROM person_info WHERE name \u0026gt; 'Asa' AND name \u0026lt; 'Barlow' AND birthday \u0026gt; '1980-01-01';可以用到name列的索引，但无法用到birthday的索引，因为name查出来的记录中可能并不是按birthday再排序过的。\n精确匹配某一列并范围匹配另外一列 对于同一个联合索引来说，虽然对多个列进行范围查找时只能用到最左边那个索引列，但如果左边的列是精确查找，则右边的列可以用范围查找，如SELECT * FROM person_info WHERE name = 'Ashburn' AND birthday \u0026gt; '1980-01-01' AND birthday \u0026lt; '2000- 12-31' AND phone_number \u0026gt; '15100000000';，name和birthday能用到索引，phone_number无法用到索引。\n用于排序 如果没有索引的话，我们会把所有的记录加载到内存中，然后通过一些排序算法例如快排等对这些记录排序，如果内存中放不下可能还会借助硬盘中的空间，最后排序完成后再返还给客户端。在Mysql中，把这种在内存中或硬盘中进行排序的方式称为文件排序(filesort)，是非常慢的。借助索引可以直接提取出数据，再进行回表拿到其他数据就可以了，例如SELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10;。但是，各个排序列的排序顺序要一致，某列asc、某列desc一起混用是无法索引的。另外，用于排序的多个列需要是同一个索引里的，索引列也不能是修饰过的形式，如SELECT * FROM person_info ORDER BY UPPER(name) LIMIT 10;。\n用于分组 其实和排序类似，如SELECT name, birthday, phone_number, COUNT(*) FROM person_info GROUP BY name, birthday, phone_number。\n代价 使用索引在空间和时间上都有代价，每建立一个索引都需要一颗B+树，大的B+树由很多数据页组成，算是不小的存储空间。每次对表进行增、删、改操作时，都可能要修改各个索引。B+树每层节点都是按照索引列的值按从小到大的顺序排序而组成了双向链表。不论是叶子节点的记录，还是内节点的记录都是按照索引列的值从小到大的顺序而形成了一个单向链表。而增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，⻚面分裂、⻚面回收等操作来维护好节点和记录的排序。所以说，一个表上索引建的越多，就会占用越多的存储空间，在增删改记录的时候性能就越差。\n此外，回表也是有代价的。二级索引B+树记录在磁盘上的数据是相连的，集中分布在一个或几个数据页中，我们可以很快的把它们读出来，这种读取方式也叫顺序读取；读取到之后，其对应的主键并不相连，要读取到完整记录就需要在不同的数据页中去找，这种读取方式叫随机读取。需要回表的记录越多，使用二级索引的效率就越低，甚至让某些查询宁愿使用全表扫描也不使用二级索引。比如name值在Asa~Barlow之间的用户记录数量占全部记录数量90%以上，那么如果使用idx_name_birthday_phone_number索引的话，有90%多的id值需要回表，就还不如全表扫描。查询优化器会帮我们判断何时该用全表扫描代替二级索引回表。\n优化策略 覆盖索引 为了避免回表时的损耗，最好在查询列表里只包含索引，如SELECT name, birthday, phone_number FROM person_info WHERE name \u0026gt; 'Asa' AND name \u0026lt; 'Barlow'。不鼓励使用*号查询列表，最好把需要查询的列依次标明。\n只为用于搜索、排序或分组的列创建索引 出现在查询列表中的列就没必要索引了。如SELECT birthday, country FROM person_name WHERE name = 'Ashburn'只需为name创建索引，birthday和country就不需要了。\n为列的基数大的列创建索引 列的基数是说该列中不重复的数的个数，比如性别这样的列，其基数也就2个，如果为其建立索引重复的值会特别的多，效果就不会好。\n索引列的类型尽量小 这里的类型指的是其表示的数据范围，例如整型分为TINYINT、MEDIUMINT、INT、BIGINT几种，在能表示出所需整数的前提下，能用INT就不要用BIGINT。因为数据类型越小，CPU做数字比较时就越快，同时索引占用的空间就越小，一个数据页中就能有更多的记录，缓存在内存中的数据也就越多。这点对于主键来说更是如此，因为二级索引也需要存储主键值。\n索引字符串值的前缀 也就是说在二级索引的记录中只保留字符串的前几个值，查找时虽不能精确的定位到记录的位置，但能定位到相应前缀的位置，在空间和时间上取得平衡。在字符串类型能存储的值较多的情况下，这种方式是非常鼓励的，如: CREATE TABLE person_info( name VARCHAR(100) NOT NULL, birthday DATE NOT NULL, phone_number CHAR(11) NOT NULL, KEY idx_name_birthday_phone_number (name(10), birthday) ); 就表示用name的前10个字符来做为索引。但这种方式不能用name列来排序了，如SELECT * FROM person_info ORDER BY name LIMIT 10;则用不到索引。\n让索引列在比较表达式中单独出现 例如WHERE col * 2 \u0026lt; 4就用不到索引，但若写成WHERE col \u0026lt; 4/2就能用到索引，所以如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出现的话，是用不到索引的。\n让主键自增 如果主键是自增(AUTO_INCREMENT)的，那我们每插满一个数据页就会去插下一个数据页。而如果插入的主键值忽大忽小，就可能会发生页分裂和记录移动，造成不必要的性能损耗。\n避免冗余重复索引 这往往发生在某个索引已经被联合索引包含到了，或者对某个列既建立了唯一索引和普通索引。\n访问方法 我们平时所写的查询语句本质上只是一种声明式语法，只是告诉MySQL我们要获取的数据符合哪些规则，至于MySQL背地里是怎么把查询结果搞出来的那是MySQL自己的事儿。我们把MySQL执行查询语句的方式称之为访问方法或者访问类型。同一个查询语句可能可以使用多种不同的访问方法来执行，虽然最后的查询结果都是一样的，但是执行的时间可能差距很大。\n我们以此表格为例，看看不同的访问方法: CREATE TABLE single_table ( id INT NOT NULL AUTO_INCREMENT, key1 VARCHAR(100), key2 INT, key3 VARCHAR(100), key_part1 VARCHAR(100), key_part2 VARCHAR(100), key_part3 VARCHAR(100), common_field VARCHAR(100), PRIMARY KEY (id), KEY idx_key1 (key1), UNIQUE KEY idx_key2 (key2), KEY idx_key3 (key3), KEY idx_key_part(key_part1, key_part2, key_part3) ) Engine=InnoDB CHARSET=utf8; 它有主键id、唯一二级索引key2、普通二级索引key1和key3、联合索引。\nconst 当我们可以直接通过主键列或唯一二级索引列来与常数的等值比较来定位到一条记录时，速度是非常快的，这种访问方法称为const。例如:SELECT * FROM single_table WHERE id = 1438;、SELECT * FROM single_table WHERE key2 = 3841;。主键列只需要一次定位，唯一索引列也只需要两次定位。\n对于唯一二级索引来说，查询该列为NULL值的情况比较特殊，因为唯一索引并不限制其列为NULL值的数量，所以使用SELECT * FROM single_table WHERE key2 IS NULL;查询时不会用const访问方法。\nref 对于某个普通二级索引列和常数值的等值比较，比如SELECT * FROM single_table WHERE key1 = 'abc';，由于普通索引并不限制索引列值的唯一性，所以可能找到多条对应的记录，那么这种方式的代价取决于匹配到的二级索引记录的条数，如果匹配的记录较少，则回表代价较低。这种方法称为ref，它的效率比const差了一些。\n如果最左边的连续索引列是与常数的等值比较就可能采用ref的方法，如SELECT * FROM single_table WHERE key_part1 ='god like'AND key_part2 = 'legendary';，但如果不全是等值比较的话，它的访问方法就不会是ref了，如SELECT * FROM single_table WHERE key_part1 ='god like'AND key_part2 \u0026gt; 'legendary';\n普通二级索引或唯一二级索引使用Key IS NULL这样的方式作为搜索条件时，可能使用ref的访问方法。\nref_or_null 当我们不仅想找出某个索引列的值等于某个常数的记录，还同时想找出该列为NULL的记录时，例如SELECT * FROM single_demo WHERE key1 = 'abc' OR key1 ISNULL;。这种查询使用的访问方法为ref_or_null。它的查询也会分为两个步骤，先分别定位key1=abc和key1是null的连续记录并找到这些记录对应的主键值，再从聚簇索引上根据主键找到完整的用户记录。\nrange 之前的方式都是和常数等值比较，但有时我们面对的搜索条件会更复杂，例如SELECT * FROM single_table WHERE key2 IN (1438,6328) OR (key2 \u0026gt;= 38AND key2 \u0026lt;= 79);，除了可能使用全表扫描的访问方法，也可能使用二级索引+回表的访问方法。如果采用回表的方式，索引列就需要匹配某个或某些范围的值，这种利用索引进行范围匹配的访问方法称为range。\n该例中，会分为三个范围，即key2=1438、key2=6328、key2∈[38,79]。范围一、范围二被称为单点区间，范围三称为连续范围空间。\nindex 看这个查询SELECT key_part1, key_part2, key_part3 FROMsingle_table WHERE key_part2 = 'abc';，由于key_part2不是联合索引idx_key_part的最左索引列，所以我们无法使用ref的访问方法来执行这个语句。但这个语句有两个特点，一是它的查询列表只有三个列key_part1、key_part2、key_part3且都被联合索引包含，二是搜索条件只有key_part2列也被包含在联合索引中。\n也就是说我们可以直接遍历idx_key_part这颗B+树的叶子节点来得到结果，而不需要回表，因为这棵树比聚簇索引的树小的多，它的成本也要小很多，我们把这种访问方法称为index。\nall 最直接的查询执行方式就是全表扫描，对于InnoDB来说就是直接扫描聚簇索引，这种访问方法称为all。\nEXPLAIN 一条查询语句在经过MySQL查询优化器的各种基于成本和规则的优化后会生成一个执行计划，这个执行计划展示了接下来具体执行查询的方式，比如多表连接的顺序是什么，对于每个表采用什么访问方法来具体执行查询等等。EXPLAIN能帮助我们查看到某个查询语句的具体执行计划。例如: mysql\u0026gt; explain select 1; +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+ | 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | No tables used | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+ 1 row in set, 1 warning (0.00 sec)\n各列的详细解释如下:\n   列名 描述     id 在一个查询语句中每个SELECT关键字都对应一个唯一id   select_type SELECT关键字对应的查询的类型   table 表名   partitions 匹配的分区信息   type 针对单表的访问方法   possible_keys 可能用到的索引   key 实际上使用的索引   key_len 实际使用到的索引长度   ref 当使用索引列等值查询时，与索引列进行等值匹配的对象信息   rows 预估的需要读取的记录条数   filtered 某个表经过搜索条件过滤后剩余记录条数的百分比   Extra 一些额外的信息    table mysql\u0026gt; explain select * from s1, s2; +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+ | 1 | SIMPLE | s1 | NULL | ALL | NULL | NULL | NULL | NULL | 1 | 100.00 | NULL | | 1 | SIMPLE | s2 | NULL | ALL | NULL | NULL | NULL | NULL | 1 | 100.00 | Using join buffer (Block Nested Loop) | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+ 2 rows in set, 1 warning (0.00 sec) 我们看到EXPLAIN语句输出的每条记录都对应着某个单表的访问方法，该条记录的table列代表了该表的表名。\nid 查询语句一般以select关键字开头，简单的查询语句只有一个select，但有两种情况会出现多个select:\n 查询语句包含子查询，如SELECT * FROM s1 WHERE key1 IN (SELECT * FROM s2); 查询语句包含UNION语句，如SELECT * FROM s1 UNION SELECT * FROM s2;  每多一个select关键字，就会给它分配一个唯一的id值。对于连接查询来说，这个id是相同的，出现在前面的就是驱动表，后面的是被驱动表。如: mysql\u0026gt; EXPLAIN SELECT * FROM s1 WHERE key1 IN(SELECT key1 FROM s2) OR key3 = \u0026#39;a\u0026#39;; +----+--------------------+-------+------------+----------------+---------------+----------+---------+------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+--------------------+-------+------------+----------------+---------------+----------+---------+------+------+----------+-------------+ | 1 | PRIMARY | s1 | NULL | ALL | idx_key3 | NULL | NULL | NULL | 1 | 100.00 | Using where | | 2 | DEPENDENT SUBQUERY | s2 | NULL | index_subquery | idx_key1 | idx_key1 | 303 | func | 1 | 100.00 | Using index | +----+--------------------+-------+------------+----------------+---------------+----------+---------+------+------+----------+-------------+ 2 rows in set, 1 warning (0.00 sec)\n但是查询优化器可能会将子查询转换为连接查询，所以会看到两个相同的id: mysql\u0026gt; EXPLAIN SELECT * FROM s1 WHERE key1 IN(SELECT key3 FROM s2 WHERE common_field = \u0026#39;a\u0026#39;); +----+-------------+-------+------------+------+---------------+----------+---------+-----------------+------+----------+-----------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+----------+---------+-----------------+------+----------+-----------------------------+ | 1 | SIMPLE | s1 | NULL | ALL | idx_key1 | NULL | NULL | NULL | 1 | 100.00 | Using where | | 1 | SIMPLE | s2 | NULL | ref | idx_key3 | idx_key3 | 303 | awesome.s1.key1 | 1 | 100.00 | Using where; FirstMatch(s1) | +----+-------------+-------+------------+------+---------------+----------+---------+-----------------+------+----------+-----------------------------+ 2 rows in set, 1 warning (0.00 sec)\nUNION子句会通过创建临时表把多个查询的结果合并起来进行去重，所以会有一条NULL的记录，UNION ALL不去重就不会有这条记录: mysql\u0026gt; EXPLAIN SELECT * FROM s1 UNION SELECT *FROM s2; +----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+ | 1 | PRIMARY | s1 | NULL | ALL | NULL | NULL | NULL | NULL | 1 | 100.00 | NULL | | 2 | UNION | s2 | NULL | ALL | NULL | NULL | NULL | NULL | 1 | 100.00 | NULL | | NULL | UNION RESULT | \u0026lt;union1,2\u0026gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | NULL | Using temporary | +----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+ 3 rows in set, 1 warning (0.00 sec)\nselect_type 每个select关键字都代表着一个小的查询语句，select_type就是描述这个小的查询语句在大的查询中扮演的角色，它的取值有这些可能:\n   名称 描述     SIMPLE 不包含UNION或子查询的话都是该类型   PRIMARY 对于大查询来说，最左边的小查询   UNION 对于包含UNION的大查询，除最左边的小查询以外的小查询   UNION RESULT 对于UNION会创建临时表，针对该临时表的查询   SUBQUERY 子查询是相关子查询时，它的第一个SELECT代表的查询   DEPENDENT SUBQUERY 子查询是不相关子查询时，它的第一个SELECT代表的查询   DEPENDENT UNION 包含UNION或UNION ALL的大查询，如果各小查询依赖外层查询，除最左边的小查询之外的小查询   DERIVED 对于采用物化方式执行的包含派生表的查询，对于派生表的子查询   MATERIALIZED 若查询优化器选择将子查询物化之后与外层查询进行连接查询   UNCACHEABLE SUBQUERY 不常用   UNCACHEABLE UNION 不常用    partitions 分区信息，一般该列值都为NULL。\ntype 代表Mysql对这个表执行查询时的访问方法，之前已经提到过部分，这列可能的值有:\n system，表中只有一条记录且该表使用的存储引擎的统计数据是精确的，比如MyISAM、Memory const，对应const eq_ref，连接查询时，若被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问的 ref，对应ref fulltext，全文索引 ref_or_null，对应ref_or_null index_merge，一般对某表的查询只能用一个索引，但某些场景可以使用Intersection、Union、Sort-Union这三种索引合并的方式 unique_subquery，在一些包含IN的子查询语句，若查询优化器决定将IN转换为EXISTS子查询且它可以用到主键进行等值匹配 index_subquery，和unique_subquery类似，只是访问子查询的表时使用的普通索引 range，对应range index，对应index ALL，对应all  possible_keys和key possible_keys表示一开始的查询语句可能使用到的索引，而key表示经过了查询优化器计算使用不同的索引成本之后，实际上会使用到的索引。例如: mysql\u0026gt; EXPLAIN SELECT * FROM s1 WHERE key1 \u0026gt; \u0026#39;z\u0026#39;AND key3 = \u0026#39;a\u0026#39;; +----+-------------+-------+------------+------+-------------------+----------+---------+-------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+-------------------+----------+---------+-------+------+----------+-------------+ | 1 | SIMPLE | s1 | NULL | ref | idx_key1,idx_key3 | idx_key3 | 303 | const | 1 | 100.00 | Using where | +----+-------------+-------+------------+------+-------------------+----------+---------+-------+------+----------+-------------+ 1 row in set, 1 warning (0.01 sec)\n有个特例是当使用index为访问方法时，possible_keys列是空的。此外，possible_keys列中的值越多，可能用到的索引就越多，查询优化器计算查询成本时就得花费更多的时间去比较，如果可能的话，尽量删除用不到的索引。\nkey_len 表示当查询优化器决定使用某个索引执行查询时，该索引记录的最大长度，这个最大长度是这样计算的:\n 对于使用固定长度类型的索引列来说，它实际占用的存储空间最大长度就是该固定值 对于指定字符集的变长类型的索引来说，比如VARCHAR(100)-UTF8，那么就是100*3=300字节 如果索引列可以存储NULL值，则key_len比不可以存储时多1个字节 对于变长字段，都会有2个字节的空间来存储该变长列的实际长度  ref 当使用索引列等值匹配的条件去执行查询时，即const、eq_ref、ref、ref_or_null、unique_subquery之一，该列会展示出与索引列做等值匹配的是一个常数或者是某个列。例如: mysql\u0026gt; EXPLAIN SELECT * FROM s1 WHERE key1 = \u0026#39;a\u0026#39;; +----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+ | 1 | SIMPLE | s1 | NULL | ref | idx_key1 | idx_key1 | 303 | const | 1 | 100.00 | NULL | +----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+ 1 row in set, 1 warning (0.00 sec) mysql\u0026gt; EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.id = s2.id; +----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+-------+ | 1 | SIMPLE | s1 | NULL | ALL | PRIMARY | NULL | NULL | NULL | 1 | 100.00 | NULL | | 1 | SIMPLE | s2 | NULL | eq_ref | PRIMARY | PRIMARY | 4 | awesome.s1.id | 1 | 100.00 | NULL | +----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+-------+ 2 rows in set, 1 warning (0.00 sec)\nrows  如果查询优化器决定使用全表扫描执行查询计划，rows列代表预计需要扫描的行数 如果查询优化器决定使用索引执行查询计划，rows列代表预计扫描的索引记录行数  filtered  如果查询优化器决定使用全表扫描执行单表查询，那么会估计出满足搜索条件的记录有多少条 如果查询优化器决定使用索引执行单表查询，那么会估计出满足除使用到对应索引的搜索条件外的其他搜索条件的记录有多少条。  对于单表查询，filtered列的值意义不大。但对于连接查询，例如: mysql\u0026gt; EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key1 WHERE s1.common_field = \u0026#39;a\u0026#39;; +----+-------------+-------+------------+------+---------------+----------+---------+-------------------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+----------+---------+-------------------+------+----------+-------------+ | 1 | SIMPLE | s1 | NULL | ALL | idx_key1 | NULL | NULL | NULL | 9688 | 10.00 | Using where | | 1 | SIMPLE | s2 | NULL | ref | idx_key1 | idx_key1 | 303 | awesome.s1.key1 | 1 | 100.00 | NULL | +----+-------------+-------+------------+------+---------------+----------+---------+-------------------+------+----------+-------------+ 2 rows in set, 1 warning (0.00 sec) 我们可以看到驱动表s1表的执行计划的rows列为9688， filtered列为10.00，这意味着驱动表s1的扇出值就是9688 × 10.00% = 968.8，这说明还要对被驱动表执行大约968次查询。\nextra 该列用来说明一些额外信息，有很多种，这里只列出比较常见的一些:\nNo tables used，当查询语句中没有FROM子句时，也就是不去读表时。\nImpossible WHERE，当WHERE子句永远为FALSE时提示。\nNo matching min/max row，查询列表处有MIN或MAX聚集函数，但是没有符合where子句中搜索条件的记录时，例如: mysql\u0026gt; EXPLAIN SELECT MIN(key1) FROM s1 WHERE key1 = \u0026#39;abcdefg\u0026#39;; +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------------+ | 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | No matching min/max row | +----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------------+ 1 row in set, 1 warning (0.00 sec)\nUsing index，出现索引覆盖而无需回表时。\nUsing index condition，当查询语句执行会用到索引下推时。例如: mysql\u0026gt; EXPLAIN SELECT * FROM s1 WHERE key1 \u0026gt;\u0026#39;z\u0026#39; AND key1 LIKE \u0026#39;%b\u0026#39;; +----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-----------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-----------------------+ | 1 | SIMPLE | s1 | NULL | range | idx_key1 | idx_key1 | 303 | NULL | 1 | 100.00 | Using index condition | +----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-----------------------+ 1 row in set, 1 warning (0.00 sec)\nkey1 \u0026gt;'z'能使用到索引，而key1 LIKE '%b'不能。它的执行过程是根据key1 \u0026gt;'z'这个条件，定位到二级索引idx_key1中对应的二级索引记录；对于这些记录先不去回表，而是先检测是否满足key1 LIKE '%b'这个条件；满足条件的才执行回表操作。这个过程就叫索引下推。\nUsing where，当全表扫描且where子句有针对该表的搜索条件时，或索引访问但where子句有索引列之外的其他搜索条件时。例如: mysql\u0026gt; EXPLAIN SELECT * FROM s1 WHERE key1 =\u0026#39;a\u0026#39; AND common_field = \u0026#39;a\u0026#39;; +----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------------+ | 1 | SIMPLE | s1 | NULL | ref | idx_key1 | idx_key1 | 303 | const | 1 | 100.00 | Using where | +----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------------+ 1 row in set, 1 warning (0.00 sec)\nUsing join buffer (Block Nested Loop)，连接查询时，被驱动表不能有效利用索引加快访问速度时，join buffer可以减少访问被驱动表的次数。\nNot exists，使用外连接时，where子句要求被驱动表某列为NULL，但该列不允许存NULL值时。\nUsing intersect(\u0026hellip;)、Using union(\u0026hellip;)、Usingsort_union(\u0026hellip;)，索引合并时会出现。\nZero limit，当我们的LIMIT子句的参数为0时，表示压根儿不打算从表中读出任何记录。\nUsing filesort，当无法使用索引排序，只能使用内存或硬盘排序时。\nUsing temporary，当查询执行可能借助临时表来完成一些功能，如去重、排序之类的时。\nStart temporary, End temporary，LooseScan，FirstMatch(tbl_name)，查询优化器会尝试将IN子查询转换成semi-join，当semi-join的执行策略为DuplicateWeedout时，驱动表显示Start temporary，被驱动表显示End temporary；当semi-join的执行策略是LooseScan时，就显示LooseScan；当semi-join的执行策略是FirstMatch时，就显示FirstMatch(tbl_name)。\n"});index.add({'id':11,'href':'/docs/mysql/query/','title':"Mysql查询",'content':"Mysql常用查询整理 数据准备 1、创建表格:\nCREATE TABLE student_info ( number INT PRIMARY KEY, name VARCHAR(5), sex ENUM(\u0026#39;男\u0026#39;, \u0026#39;女\u0026#39;), id_number CHAR(18), department VARCHAR(30), major VARCHAR(30), enrollment_time DATE, UNIQUE KEY (id_number) ); CREATE TABLE student_score ( number INT, subject VARCHAR(30), score TINYINT, PRIMARY KEY (number, subject), CONSTRAINT FOREIGN KEY(number) REFERENCES student_info(number) ); 2、填充数据: INSERT INTO student_info(number, name, sex, id_number, department, major, enrollment_time) VALUES (20180101, \u0026#39;杜子腾\u0026#39;, \u0026#39;男\u0026#39;, \u0026#39;158177199901044792\u0026#39;, \u0026#39;计算机学院\u0026#39;, \u0026#39;计算机科学与工程\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180102, \u0026#39;杜琦燕\u0026#39;, \u0026#39;女\u0026#39;, \u0026#39;151008199801178529\u0026#39;, \u0026#39;计算机学院\u0026#39;, \u0026#39;计算机科学与工程\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180103, \u0026#39;范统\u0026#39;, \u0026#39;男\u0026#39;, \u0026#39;17156319980116959X\u0026#39;, \u0026#39;计算机学院\u0026#39;, \u0026#39;软件工程\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180104, \u0026#39;史珍香\u0026#39;, \u0026#39;女\u0026#39;, \u0026#39;141992199701078600\u0026#39;, \u0026#39;计算机学院\u0026#39;, \u0026#39;软件工程\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180105, \u0026#39;范剑\u0026#39;, \u0026#39;男\u0026#39;, \u0026#39;181048199308156368\u0026#39;, \u0026#39;航天学院\u0026#39;, \u0026#39;飞行器设计\u0026#39;, \u0026#39;2018-09-01\u0026#39;), (20180106, \u0026#39;朱逸群\u0026#39;, \u0026#39;男\u0026#39;, \u0026#39;197995199501078445\u0026#39;, \u0026#39;航天学院\u0026#39;, \u0026#39;电子信息\u0026#39;, \u0026#39;2018-09-01\u0026#39;); INSERT INTO student_score (number, subject, score) VALUES (20180101, \u0026#39;母猪的产后护理\u0026#39;, 78), (20180101, \u0026#39;论萨达姆的战争准备\u0026#39;, 88), (20180102, \u0026#39;母猪的产后护理\u0026#39;, 100), (20180102, \u0026#39;论萨达姆的战争准备\u0026#39;, 98), (20180103, \u0026#39;母猪的产后护理\u0026#39;, 59), (20180103, \u0026#39;论萨达姆的战争准备\u0026#39;, 61), (20180104, \u0026#39;母猪的产后护理\u0026#39;, 55), (20180104, \u0026#39;论萨达姆的战争准备\u0026#39;, 46);\n3、填充结果:\nstudent_info表\n   number  name  sex id_number department  major  enrollment_time     20180101 杜子腾 男 158177199901044792 计算机学院 计算机科学与工程 2018-09-01   20180102 杜琦燕 女 151008199801178529 计算机学院 计算机科学与工程 2018-09-01   20180103 范统 男 17156319980116959X 计算机学院 软件工程 2018-09-01   20180104 史珍香 女 141992199701078600 计算机学院 软件工程 2018-09-01   20180105 范剑 男 181048199308156368 航天学院 飞行器设计 2018-09-01   20180106 朱逸群 男 197995199501078445 航天学院 电子信息 2018-09-01    student_score表\n   number subject score     20180101 母猪的产后护理 78   20180101 论萨达姆的战争准备 88   20180102 母猪的产后护理 100   20180102 论萨达姆的战争准备 98   20180103 母猪的产后护理 59   20180103 论萨达姆的战争准备 61   20180104 母猪的产后护理 55   20180104 论萨达姆的战争准备 46    基础查询 别名  方式一:select number as 学号 from student_score 方式二:select number 学号 from student_score  查询结果: mysql\u0026gt; select number 学号 from student_score; +----------+ | 学号 | +----------+ | 20180101 | | 20180101 | | 20180102 | | 20180102 | | 20180103 | | 20180103 | | 20180104 | | 20180104 | +----------+ 8 rows in set (0.00 sec)\n多列也可以: mysql\u0026gt; select number 学号, name 姓名 from student_info; +----------+-----------+ | 学号 | 姓名 | +----------+-----------+ | 20180101 | 杜子腾 | | 20180102 | 杜琦燕 | | 20180103 | 范统 | | 20180104 | 史珍香 | | 20180105 | 范剑 | | 20180106 | 朱逸群 | +----------+-----------+ 6 rows in set (0.00 sec)\n去重 单列去重: mysql\u0026gt; select distinct department from student_info; +-----------------+ | department | +-----------------+ | 计算机学院 | | 航天学院 | +-----------------+ 2 rows in set (0.00 sec)\n多列去重: mysql\u0026gt; select distinct department,major from student_info; +-----------------+--------------------------+ | department | major | +-----------------+--------------------------+ | 计算机学院 | 计算机科学与工程 | | 计算机学院 | 软件工程 | | 航天学院 | 飞行器设计 | | 航天学院 | 电子信息 | +-----------------+--------------------------+ 4 rows in set (0.00 sec)\n限制查询结果条数 使用limit 从哪开始，多少条，从哪开始可以省略，省略代表第0行。\nmysql\u0026gt; select * from student_info limit 3,8; +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ 3 rows in set (0.00 sec) 排序 多列排序: mysql\u0026gt; select * from student_info order by name asc, number desc; +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 6 rows in set (0.00 sec) mysql\u0026gt; select * from student_info order by name desc, number desc; +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 6 rows in set (0.00 sec)\n带条件查询 简单搜索条件 不等于可以使用\u0026lt;\u0026gt;或!= : mysql\u0026gt; select * from student_info where department \u0026lt;\u0026gt; \u0026#39;计算机学院\u0026#39;; +----------+-----------+------+--------------------+--------------+-----------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+--------------+-----------------+-----------------+ | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | +----------+-----------+------+--------------------+--------------+-----------------+-----------------+ 2 rows in set (0.00 sec)\n区间内使用between...and...，不在某区间使用not between...and...: mysql\u0026gt; select * from student_info where number between 20180103 and 20180105; +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+-----------------+-----------------+ 3 rows in set (0.01 sec) mysql\u0026gt; select * from student_info where number not between 20180103 and 20180105; +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 3 rows in set (0.00 sec)\n匹配列表中的元素 使用in (...)和not in筛选出在某个列表中的记录: mysql\u0026gt; select * from student_info where major in (\u0026#39;软件工程\u0026#39;, \u0026#39;电子信息\u0026#39;); +----------+-----------+------+--------------------+-----------------+--------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | | 20180106 | 朱逸群 | 男 | 197995199501078445 | 航天学院 | 电子信息 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------+-----------------+ 3 rows in set (0.00 sec)\n使用is null 和 is not null可筛选出某列是NULL的记录，而不能使用普通的操作符例如等号来进行比较，NULL代表没有值。\n多个搜索条件 AND优先级高于OR: mysql\u0026gt; SELECT * FROM student_score WHERE score \u0026gt; 95 OR score \u0026lt; 55 AND subject = \u0026#39;论萨达姆的战争准备\u0026#39;; +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180102 | 母猪的产后护理 | 100 | | 20180102 | 论萨达姆的战争准备 | 98 | | 20180104 | 论萨达姆的战争准备 | 46 | +----------+-----------------------------+-------+ 3 rows in set (0.00 sec)\n模糊查询 使用like和not like进行模糊匹配查询，%代表任意一个字符串，而_代表任意一个字符: mysql\u0026gt; select * from student_info where name like \u0026#39;杜_\u0026#39;; Empty set (0.00 sec) mysql\u0026gt; select * from student_info where name like \u0026#39;范_\u0026#39;; +----------+--------+------+--------------------+-----------------+-----------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+--------+------+--------------------+-----------------+-----------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180105 | 范剑 | 男 | 181048199308156368 | 航天学院 | 飞行器设计 | 2018-09-01 | +----------+--------+------+--------------------+-----------------+-----------------+-----------------+ 2 rows in set (0.00 sec) mysql\u0026gt; select * from student_info where name like \u0026#39;%杜%\u0026#39;; +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 2 rows in set (0.00 sec)\n函数和表达式 表达式 可以将表达式放在查询列表中: mysql\u0026gt; select number,subject,score+100 from student_score; +----------+-----------------------------+-----------+ | number | subject | score+100 | +----------+-----------------------------+-----------+ | 20180101 | 母猪的产后护理 | 178 | | 20180101 | 论萨达姆的战争准备 | 188 | | 20180102 | 母猪的产后护理 | 200 | | 20180102 | 论萨达姆的战争准备 | 198 | | 20180103 | 母猪的产后护理 | 159 | | 20180103 | 论萨达姆的战争准备 | 161 | | 20180104 | 母猪的产后护理 | 155 | | 20180104 | 论萨达姆的战争准备 | 146 | +----------+-----------------------------+-----------+ 8 rows in set (0.00 sec)\n也可以把表达式作为搜索的条件: mysql\u0026gt; select * from student_score where score%3=0; +----------+-----------------------+-------+ | number | subject | score | +----------+-----------------------+-------+ | 20180101 | 母猪的产后护理 | 78 | +----------+-----------------------+-------+ 1 row in set (0.00 sec)\n文本处理 连接字符串: mysql\u0026gt; select concat(\u0026#39;学号为\u0026#39;,number,\u0026#39;的学生在[\u0026#39;,subject,\u0026#39;]的成绩为\u0026#39;,score) from student_score; +--------------------------------------------------------------------------+ | concat(\u0026#39;学号为\u0026#39;,number,\u0026#39;的学生在[\u0026#39;,subject,\u0026#39;]的成绩为\u0026#39;,score) | +--------------------------------------------------------------------------+ | 学号为20180101的学生在[母猪的产后护理]的成绩为78 | | 学号为20180101的学生在[论萨达姆的战争准备]的成绩为88 | | 学号为20180102的学生在[母猪的产后护理]的成绩为100 | | 学号为20180102的学生在[论萨达姆的战争准备]的成绩为98 | | 学号为20180103的学生在[母猪的产后护理]的成绩为59 | | 学号为20180103的学生在[论萨达姆的战争准备]的成绩为61 | | 学号为20180104的学生在[母猪的产后护理]的成绩为55 | | 学号为20180104的学生在[论萨达姆的战争准备]的成绩为46 | +--------------------------------------------------------------------------+ 8 rows in set (0.00 sec)\n子串: mysql\u0026gt; select substring(number, 4, 5) as 学号尾号 from student_info; +--------------+ | 学号尾号 | +--------------+ | 80104 | | 80102 | | 80101 | | 80103 | | 80105 | | 80106 | +--------------+ 6 rows in set (0.00 sec)\n时间处理函数 时间间隔: mysql\u0026gt; select date_add(\u0026#39;2015-01-01 10:20:33\u0026#39;, interval 2 minute); +----------------------------------------------------+ | date_add(\u0026#39;2015-01-01 10:20:33\u0026#39;, interval 2 minute) | +----------------------------------------------------+ | 2015-01-01 10:22:33 | +----------------------------------------------------+ 1 row in set (0.00 sec)\n时间格式化: mysql\u0026gt; select date_format(now(), \u0026#39;%b/%d/%Y %h:%i:%s~%p\u0026#39;); +--------------------------------------------+ | date_format(now(), \u0026#39;%b/%d/%Y %h:%i:%s~%p\u0026#39;) | +--------------------------------------------+ | Dec/02/2019 04:57:31~PM | +--------------------------------------------+ 1 row in set (0.00 sec)\n聚集函数 COUNT用来统计行数\n COUNT(*)统计表中所有的行，包括NULL COUNT(列名)统计表中某列的所有行，不包括NULL  mysql\u0026gt; select count(*) from student_info; +----------+ | count(*) | +----------+ | 6 | +----------+ 1 row in set (0.00 sec) mysql\u0026gt; select count(distinct subject) from student_score; +-------------------------+ | count(distinct subject) | +-------------------------+ | 2 | +-------------------------+ 1 row in set (0.00 sec) SUM和AVG: mysql\u0026gt; select sum(score) from student_score; +------------+ | sum(score) | +------------+ | 585 | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; select avg(score) from student_score where subject=\u0026#34;论萨达姆的战争准备\u0026#34;; +------------+ | avg(score) | +------------+ | 73.2500 | +------------+ 1 row in set (0.00 sec)\n组合使用: mysql\u0026gt; select count(*) as 成绩记录总数, max(score) as 最高分, min(score) as 最低分,avg(score) as 平均分 from student_score; +--------------------+-----------+-----------+-----------+ | 成绩记录总数 | 最高分 | 最低分 | 平均分 | +--------------------+-----------+-----------+-----------+ | 8 | 100 | 46 | 73.1250 | +--------------------+-----------+-----------+-----------+ 1 row in set (0.00 sec)\n隐式类型转换 Mysql会尽量把值转换为表达式中需要的类型，而不是产生错误: mysql\u0026gt; select 1 + \u0026#39;2\u0026#39;; +---------+ | 1 + \u0026#39;2\u0026#39; | +---------+ | 3 | +---------+ 1 row in set (0.00 sec) mysql\u0026gt; select \u0026#39;23sds\u0026#39;+17; +------------+ | \u0026#39;23sds\u0026#39;+17 | +------------+ | 40 | +------------+ 1 row in set, 1 warning (0.00 sec)\n但这种转换不能用于存储数据: mysql\u0026gt; insert into student_score(score,number,subject) values (100,20180101,300); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into student_score(score,number,subject) values (\u0026#39;100\u0026#39;,20180101,400); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into student_score(score,number,subject) values (\u0026#39;asd\u0026#39;,20180101,400); ERROR 1366 (HY000): Incorrect integer value: \u0026#39;asd\u0026#39; for column \u0026#39;score\u0026#39; at row 1\n分组查询 基础查询 分组就是针对某个列，将该列的值相同的记录分到一个组中: mysql\u0026gt; select subject, sum(score) from student_score group by subject; +-----------------------------+------------+ | subject | sum(score) | +-----------------------------+------------+ | 母猪的产后护理 | 292 | | 论萨达姆的战争准备 | 293 | +-----------------------------+------------+ 2 rows in set (0.00 sec)\n把非分组列放入查询列表中会引起争议，导致结果不确定: mysql\u0026gt; select subject, sum(score),number from student_score group by subject; ERROR 1055 (42000): Expression #3 of SELECT list is not in GROUP BY clause and contains nonaggregated column \u0026#39;student.student_score.number\u0026#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by\n分组和过滤条件 是先过滤出符合条件的数据，在进行分组运算的: mysql\u0026gt; select subject, sum(score) from student_score where score\u0026gt;70 group by subject; +-----------------------------+------------+ | subject | sum(score) | +-----------------------------+------------+ | 母猪的产后护理 | 178 | | 论萨达姆的战争准备 | 186 | +-----------------------------+------------+ 2 rows in set (0.00 sec)\n也可以分组后，在筛选出合适的分组: mysql\u0026gt; select subject, sum(score) from student_score group by subject having max(score)\u0026gt;98; +-----------------------+------------+ | subject | sum(score) | +-----------------------+------------+ | 母猪的产后护理 | 292 | +-----------------------+------------+ 1 row in set (0.00 sec)\n分组和排序 mysql\u0026gt; select subject, sum(score) as sum_s from student_score group by subject order by sum_s desc; +-----------------------------+-------+ | subject | sum_s | +-----------------------------+-------+ | 论萨达姆的战争准备 | 293 | | 母猪的产后护理 | 292 | +-----------------------------+-------+ 2 rows in set (0.00 sec) 嵌套分组 如下例，可先按department分成大组，再按major分为小组: mysql\u0026gt; select department, major, count(*) from student_info group by department, major; +-----------------+--------------------------+----------+ | department | major | count(*) | +-----------------+--------------------------+----------+ | 航天学院 | 电子信息 | 1 | | 航天学院 | 飞行器设计 | 1 | | 计算机学院 | 计算机科学与工程 | 2 | | 计算机学院 | 软件工程 | 2 | +-----------------+--------------------------+----------+ 4 rows in set (0.00 sec)\n注意事项  如果分组列中有NULL值，那么NULL会作为一个独立的分组 如果是嵌套分组，聚集函数将作用在最后的分组列上 非分组列不能单独出现在检索列表中(可以被放到聚集函数中) GROUP BY子句后可以跟随表达式(但不能是聚集函数)  简单查询语句中各子句的顺序为: SELECT [DISTINCT] 查询列表 [FROM 表名] [WHERE 布尔表达式] [GROUP BY 分组列表 ] [HAVING 分组过滤条件] [ORDER BY 排序列表] [LIMIT 开始行, 限制条数]\n子查询 标量子查询 标量子查询单纯的代表一个值，可以作为表达式参与运算或作为搜索条件: mysql\u0026gt; select * from student_score where number=(select number from student_info where name=\u0026#39;范统\u0026#39;); +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180103 | 母猪的产后护理 | 59 | | 20180103 | 论萨达姆的战争准备 | 61 | +----------+-----------------------------+-------+ 2 rows in set (0.00 sec)\n列子查询 内层查询结果不是一个单独的值，而是一个列: mysql\u0026gt; select * from student_score where number=(select number from student_info where sex=\u0026#39;男\u0026#39;); ERROR 1242 (21000): Subquery returns more than 1 row mysql\u0026gt; select * from student_score where number in (select number from student_info where sex=\u0026#39;男\u0026#39;); +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180101 | 母猪的产后护理 | 78 | | 20180101 | 论萨达姆的战争准备 | 88 | | 20180103 | 母猪的产后护理 | 59 | | 20180103 | 论萨达姆的战争准备 | 61 | +----------+-----------------------------+-------+ 4 rows in set (0.00 sec)\n而行子查询、表子查询不常用，省略。\nEXISTS和相关子查询 EXISTS和NOT EXISTS单独看很像一个函数，返回查询结果是否为空集: mysql\u0026gt; select exists (select * from student_info where number=20180101); +-----------------------------------------------------------+ | exists (select * from student_info where number=20180101) | +-----------------------------------------------------------+ | 1 | +-----------------------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select not exists (select * from student_info where number=20180101); +---------------------------------------------------------------+ | not exists (select * from student_info where number=20180101) | +---------------------------------------------------------------+ | 0 | +---------------------------------------------------------------+ 1 row in set (0.00 sec)\n之前我们尝试的都是不相关子查询，而相关子查询就是内层查询语句要用到外层查询语句的值，比如我们查学生的基本信息并要求这些学生有成绩的记录: mysql\u0026gt; select * from student_info where exists(select * from student_score where student_score.number=student_info.number); +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ | 20180101 | 杜子腾 | 男 | 158177199901044792 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180102 | 杜琦燕 | 女 | 151008199801178529 | 计算机学院 | 计算机科学与工程 | 2018-09-01 | | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | +----------+-----------+------+--------------------+-----------------+--------------------------+-----------------+ 4 rows in set (0.00 sec)\n这个相关子查询的查询过程是:先执行外层查询获得到student_info表的第一条记录，发现它的number值是20180101。把20180101当作参数传入到子查询，此时子查询的意思是判断student_score表的number字段是否有20180101这个值存在，子查询的结果是该值存在，所以整个EXISTS表达式的值为TRUE，那么student_info表的第一条记录可以被加入到结果集。每条记录依次按这个过程执行。\n此外，子查询还可以应用于同一个表，比如我们去查student_score表中分数大于平均分的记录，第一印象可能是如下写法: mysql\u0026gt; select * from student_score where score \u0026gt; avg(score); ERROR 1111 (HY000): Invalid use of group function\n实际应该使用子查询来实现: mysql\u0026gt; select * from student_score where score \u0026gt; (select avg(score) from student_score); +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180101 | 母猪的产后护理 | 78 | | 20180101 | 论萨达姆的战争准备 | 88 | | 20180102 | 母猪的产后护理 | 100 | | 20180102 | 论萨达姆的战争准备 | 98 | +----------+-----------------------------+-------+ 4 rows in set (0.00 sec) 因为聚集函数不能用于WHERE子句，可以把上述写法看做是给student_score做了一个副本。\n连接查询 基础概念 连接的本质就是将各个表中的记录都拉取出来，依次匹配组合形成一个结果集，也就是笛卡尔积的方式。\n我们来看一个示例: mysql\u0026gt; create table t1(m1 int, n1 char(1)); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; create table t2(m2 int, n2 char(1)); Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; insert into t1 values(1, \u0026#39;a\u0026#39;),(2, \u0026#39;b\u0026#39;),(3, \u0026#39;c\u0026#39;); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0 mysql\u0026gt; insert into t2 values(2, \u0026#39;a\u0026#39;),(3, \u0026#39;b\u0026#39;),(4, \u0026#39;c\u0026#39;); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0\n新建了两个表，并各插入了三条数据，那么连接可以这样做: mysql\u0026gt; select * from t1,t2; +------+------+------+------+ | m1 | n1 | m2 | n2 | +------+------+------+------+ | 1 | a | 2 | a | | 2 | b | 2 | a | | 3 | c | 2 | a | | 1 | a | 3 | b | | 2 | b | 3 | b | | 3 | c | 3 | b | | 1 | a | 4 | c | | 2 | b | 4 | c | | 3 | c | 4 | c | +------+------+------+------+ 9 rows in set (0.00 sec)\n使用以下写法连接都是可以的:\n select t1.m1,t1.n1,t2.m2,t2.n2 from t1, t2 select m1,n1,m2,n2 from t1, t2 select t1.*,t2.* from t1, t2  内外连接 现在我们想通过一条语句既查到学生的基本信息，又查到他的成绩信息: mysql\u0026gt; select student_info.number,name,sex,subject,score from student_info, student_score where student_info.number = student_score.number; +----------+-----------+------+-----------------------------+-------+ | number | name | sex | subject | score | +----------+-----------+------+-----------------------------+-------+ | 20180101 | 杜子腾 | 男 | 母猪的产后护理 | 78 | | 20180101 | 杜子腾 | 男 | 论萨达姆的战争准备 | 88 | | 20180102 | 杜琦燕 | 女 | 母猪的产后护理 | 100 | | 20180102 | 杜琦燕 | 女 | 论萨达姆的战争准备 | 98 | | 20180103 | 范统 | 男 | 母猪的产后护理 | 59 | | 20180103 | 范统 | 男 | 论萨达姆的战争准备 | 61 | | 20180104 | 史珍香 | 女 | 母猪的产后护理 | 55 | | 20180104 | 史珍香 | 女 | 论萨达姆的战争准备 | 46 | +----------+-----------+------+-----------------------------+-------+ 8 rows in set (0.00 sec)\n这时候我们发现有两个人没有成绩，所以他们没有显示在查询结果中。为了有办法让其显示出，就有了内连接和外连接的概念:\n 内连接就是我们之前使用的，没有匹配的记录则结果不会加入到最后的结果集 对于外连接的两个表，驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集  而外连接又分为左外连接，即左侧的表为驱动表。右外连接，即右侧的表为驱动表。\n此外，WHERE子句不论内外连接，凡是不符合WHERE条件的记录都不会在最后的结果集中。而对于外连接的驱动表，ON可以将被驱动表中找不到记录的对应驱动表记录加入到结果集，内连接中WHERE子句和ON子句是等价的。所以我们一般会把WHERE用于涉及单表的过滤条件，ON用于涉及多表的过滤条件。\n外连接的标准语法为: select * from t1 left/right [outer] join t2 on 连接条件 [where 普通过滤条件]，outer和where可省略。\n上例中使用外连接的结果为: mysql\u0026gt; select student_info.number,name,sex,subject,score from student_info left join student_score on student_info.number = student_score.number; +----------+-----------+------+-----------------------------+-------+ | number | name | sex | subject | score | +----------+-----------+------+-----------------------------+-------+ | 20180101 | 杜子腾 | 男 | 母猪的产后护理 | 78 | | 20180101 | 杜子腾 | 男 | 论萨达姆的战争准备 | 88 | | 20180102 | 杜琦燕 | 女 | 母猪的产后护理 | 100 | | 20180102 | 杜琦燕 | 女 | 论萨达姆的战争准备 | 98 | | 20180103 | 范统 | 男 | 母猪的产后护理 | 59 | | 20180103 | 范统 | 男 | 论萨达姆的战争准备 | 61 | | 20180104 | 史珍香 | 女 | 母猪的产后护理 | 55 | | 20180104 | 史珍香 | 女 | 论萨达姆的战争准备 | 46 | | 20180105 | 范剑 | 男 | NULL | NULL | | 20180106 | 朱逸群 | 男 | NULL | NULL | +----------+-----------+------+-----------------------------+-------+ 10 rows in set (0.00 sec)\n内连接以下的写法是等价的:\n select * from t1, t2 select * from t1 join t2 select * from t1 inner join t2 select * from t1 cross join t2  综上，我们总结以下三种连接的结果差异: mysql\u0026gt; select * from t1 inner join t2 on t1.m1=t2.m2; +------+------+------+------+ | m1 | n1 | m2 | n2 | +------+------+------+------+ | 2 | b | 2 | a | | 3 | c | 3 | b | +------+------+------+------+ 2 rows in set (0.00 sec) mysql\u0026gt; select * from t1 left join t2 on t1.m1=t2.m2; +------+------+------+------+ | m1 | n1 | m2 | n2 | +------+------+------+------+ | 2 | b | 2 | a | | 3 | c | 3 | b | | 1 | a | NULL | NULL | +------+------+------+------+ 3 rows in set (0.00 sec) mysql\u0026gt; select * from t1 right join t2 on t1.m1=t2.m2; +------+------+------+------+ | m1 | n1 | m2 | n2 | +------+------+------+------+ | 2 | b | 2 | a | | 3 | c | 3 | b | | NULL | NULL | 4 | c | +------+------+------+------+ 3 rows in set (0.00 sec)\n多表连接 我们可以连接任意数量的表，我们再加入一张表试验: mysql\u0026gt; create table t3(m3 int, n3 char(1)); Query OK, 0 rows affected (0.07 sec) mysql\u0026gt; insert into t3 values(3, \u0026#39;a\u0026#39;),(3, \u0026#39;b\u0026#39;),(4, \u0026#39;c\u0026#39;); Query OK, 3 rows affected (0.01 sec) Records: 3 Duplicates: 0 Warnings: 0\n我们使用下面的语法查询是等价的:\n select * from t1 inner join t2 inner join t3 where t1.m1=t2.m2 and t2.m2=t3.m3; select * from t1 inner join t2 on t1.m1=t2.m2 inner join t3 on t1.m1=t3.m3;  查询结果: mysql\u0026gt; select * from t1 inner join t2 on t1.m1=t2.m2 inner join t3 on t1.m1=t3.m3; +------+------+------+------+------+------+ | m1 | n1 | m2 | n2 | m3 | n3 | +------+------+------+------+------+------+ | 3 | c | 3 | b | 3 | a | | 3 | c | 3 | b | 3 | b | +------+------+------+------+------+------+ 2 rows in set (0.00 sec) 也可以用伪代码来描述:\nfor each_row in t1{ for each_row in t2 which t1.m1=t2.m2{ for each_row in t3 which t2.m2=t3.m3{ add_result(each_row) } } } 自连接 我们无法直接自连接，但可以通过别名: mysql\u0026gt; select * from t1, t1; ERROR 1066 (42000): Not unique table/alias: \u0026#39;t1\u0026#39; mysql\u0026gt; select * from t1 as table1, t1 as table2; +------+------+------+------+ | m1 | n1 | m1 | n1 | +------+------+------+------+ | 1 | a | 1 | a | | 2 | b | 1 | a | | 3 | c | 1 | a | | 1 | a | 2 | b | | 2 | b | 2 | b | | 3 | c | 2 | b | | 1 | a | 3 | c | | 2 | b | 3 | c | | 3 | c | 3 | c | +------+------+------+------+ 9 rows in set (0.00 sec)\n而自连接的意义，比如要查询与'范统'的专业相同的同学: mysql\u0026gt; select * from student_info as s1, student_info as s2 where s1.name=\u0026#39;范统\u0026#39; and s1.major=s2.major; +----------+--------+------+--------------------+-----------------+--------------+-----------------+----------+-----------+------+--------------------+-----------------+--------------+-----------------+ | number | name | sex | id_number | department | major | enrollment_time | number | name | sex | id_number | department | major | enrollment_time | +----------+--------+------+--------------------+-----------------+--------------+-----------------+----------+-----------+------+--------------------+-----------------+--------------+-----------------+ | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | | 20180103 | 范统 | 男 | 17156319980116959X | 计算机学院 | 软件工程 | 2018-09-01 | 20180104 | 史珍香 | 女 | 141992199701078600 | 计算机学院 | 软件工程 | 2018-09-01 | +----------+--------+------+--------------------+-----------------+--------------+-----------------+----------+-----------+------+--------------------+-----------------+--------------+-----------------+ 2 rows in set (0.00 sec)\n与子查询转换 有的需求既可以用连接查询，也可以用子查询: mysql\u0026gt; select * from student_score where number in (select number from student_info where major=\u0026#39;软件工程\u0026#39;); +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180103 | 母猪的产后护理 | 59 | | 20180103 | 论萨达姆的战争准备 | 61 | | 20180104 | 母猪的产后护理 | 55 | | 20180104 | 论萨达姆的战争准备 | 46 | +----------+-----------------------------+-------+ 4 rows in set (0.00 sec) mysql\u0026gt; select s2.* from student_score as s2, student_info as s1 where s1.number=s2.number and s1.major=\u0026#39;软件工程\u0026#39;; +----------+-----------------------------+-------+ | number | subject | score | +----------+-----------------------------+-------+ | 20180103 | 母猪的产后护理 | 59 | | 20180103 | 论萨达姆的战争准备 | 61 | | 20180104 | 母猪的产后护理 | 55 | | 20180104 | 论萨达姆的战争准备 | 46 | +----------+-----------------------------+-------+ 4 rows in set (0.00 sec)\n"});index.add({'id':12,'href':'/docs/python/tools/','title':"Python常用工具",'content':"Python常用工具 IPython 通过%quickref可以查看功能导览，通过%lsmagic可以列出ipython中支持的魔法函数: In [9]: %lsmagic Out[9]: Available line magics: %alias %alias_magic %autoawait %autocall %autoindent %automagic %bookmark %cat %cd %clear %colors %conda %config %cp %cpaste %debug %dhist %dirs %doctest_mode %ed %edit %env %gui %hist %history %killbgscripts %ldir %less %lf %lk %ll %load %load_ext %loadpy %logoff %logon %logstart %logstate %logstop %ls %lsmagic %lx %macro %magic %man %matplotlib %mkdir %more %mv %notebook %page %paste %pastebin %pdb %pdef %pdoc %pfile %pinfo %pinfo2 %pip %popd %pprint %precision %prun %psearch %psource %pushd %pwd %pycat %pylab %quickref %recall %rehashx %reload_ext %rep %rerun %reset %reset_selective %rm %rmdir %run %save %sc %set_env %store %sx %system %tb %time %timeit %unalias %unload_ext %who %who_ls %whos %xdel %xmode Available cell magics: %%! %%HTML %%SVG %%bash %%capture %%debug %%file %%html %%javascript %%js %%latex %%markdown %%perl %%prun %%pypy %%python %%python2 %%python3 %%ruby %%script %%sh %%svg %%sx %%system %%time %%timeit %%writefile 接着可通过给某个魔法函数前加问号的方式例如?alias来查看它的具体使用方法。单个%表示执行当前行的内容，%%用于支持把多行内容作用于该魔法函数。\n自省 在ipython中，通常使用?\u0026lt;object\u0026gt;的方式查看一个对象是什么，当输入某个对象后可以按下tab键查看其成员，通过%pdoc可查看其docstring，%psource可查看某个目标对象的源码(如果对象是module，需要用%pfile)，%who和%whos查看当前环境中的对象列表。 In [1]: import demo In [2]: ?demo Type: module String form: \u0026lt;module \u0026#39;demo\u0026#39; from \u0026#39;/home/hejl/demo.py\u0026#39;\u0026gt; File: ~/demo.py Docstring: test for doc module In [3]: %pdoc demo Class docstring: test for doc module In [4]: %psource demo.b def b(): print(\u0026#34;helloworld!\u0026#34;) In [5]: %pfile demo \u0026#34;\u0026#34;\u0026#34; test for doc module \u0026#34;\u0026#34;\u0026#34; a = 1 def b(): print(\u0026#34;helloworld!\u0026#34;) In [6]: c = 2 In [7]: %who c demo In [8]: %whos Variable Type Data/Info ------------------------------ c int 2 demo module \u0026lt;module \u0026#39;demo\u0026#39; from \u0026#39;/home/hejl/demo.py\u0026#39;\u0026gt;\n搜索 ipython支持搜索可用的函数，以及当前环境下的对象: In [1]: import sys In [2]: ?sys.get* sys.get_asyncgen_hooks sys.get_coroutine_wrapper sys.getallocatedblocks sys.getcheckinterval sys.getdefaultencoding sys.getdlopenflags sys.getfilesystemencodeerrors sys.getfilesystemencoding sys.getprofile sys.getrecursionlimit sys.getrefcount sys.getsizeof sys.getswitchinterval sys.gettrace In [3]: ?sys.get*of sys.getsizeof In [4]: ?s* set setattr slice sorted staticmethod str sum super sys\n历史 通过%history -n可用查看在ipython中全部输入的历史，也可以通过_i查看上一个，_ii和_iii查看上两个和三个，_i\u0026lt;n\u0026gt;查看上n个: In [6]: _i2 Out[6]: \u0026#39;?sys.get*\u0026#39; In [7]: %history -n 1: import sys 2: ?sys.get* 3: ?sys.get*of 4: ?s * 5: ?s* 6: _i2 7: %history -n In [8]: _i, _ii, _iii Out[8]: (\u0026#39;%history -n\u0026#39;, \u0026#39;_i2\u0026#39;, \u0026#39;?s*\u0026#39;)\n还可以把历史命令中的某些行编写为一个宏，通过宏可以重复调用，下例中把第9至第10行、外加第12行编写入了一个宏: In [9]: x,y=1,2 In [10]: print(x+y) 3 In [11]: y=10 In [12]: print(x+y) 11 In [13]: %macro tes 9-10 12 Macro `tes` created. To execute, type its name (without quotes). === Macro contents: === x,y=1,2 print(x+y) print(x+y) In [14]: tes 3 3\n还可以使用%save把宏或者某些行保存在一个文件中: In [15]: %save test.py tes The following commands were written to file `test.py`: x,y=1,2 print(x+y) print(x+y) In [16]: %save test.py 9-10 File `test.py` exists. Overwrite (y/[N])? y The following commands were written to file `test.py`: x,y=1,2 print(x+y)\n命令 可以通过!执行shell中的命令，命令执行结果可以直接赋值给python变量，也可以将python变量传入shell: In [26]: !ls 6.824 basic dump.rdb get-pip.py my_git test.py MIT-6.824 cliu8siteprivate.key fastapi-vue-cms helloworld.key practise-go __pycache__ demo.py flask-shop hjlarry.github.io practise-py In [27]: a = !ls In [28]: a Out[28]: [\u0026#39;6.824\u0026#39;, \u0026#39;MIT-6.824\u0026#39;, \u0026#39;__pycache__\u0026#39;, ...] In [31]: x=100 In [32]: !echo \u0026#34;python.x={x+20}\u0026#34; python.x=120\n"});index.add({'id':13,'href':'/docs/go/gc/','title':"垃圾回收器",'content':"垃圾回收器的设计 背景知识 垃圾回收器的首要任务就是节约内存，尽可能的节约内存也意味着要尽可能的增加执行频率，这样就会影响性能。如果不想影响用户代码的性能，就得尽量隔久一些执行一次垃圾回收，这就可能导致大量内存无法回收，空间浪费严重。所以垃圾回收器的设计难点就是在这两者间取得平衡，很难做到完美。\n我们说垃圾回收通常是针对堆上的垃圾，堆内存都是要释放的，区别只是有的语言需要手动释放，有的语言由垃圾回收器来释放，不释放就是内存泄漏了。而栈内存是绑定在线程上，在Go中也就是M(G0)以及G，默认的2KB会当做一个对象来处理，垃圾回收器通常不会介入。\nGo中的垃圾回收属于很传统的策略，基于标记清理，标记出死了的对象然后清理掉，但它不会压缩内存，有的语言会压缩好处在于可以空出大量的连续内存空间，但Go由于支持指针不会这样做。\n另外，由于Go需要支持垃圾回收和用户逻辑的并发，也让垃圾回收这件事复杂了很多。就像我们要打扫一条街，那把街两头堵住打扫完了再打开是最方便的，但现在要在打扫的同时不能影响游客游览，这就可能这条街永远打扫不干净。\n即便是并发，也会有一个短暂的暂停行为，被称为STW(stop the world)。需要在这个时间内去通知所有的P，我要开始垃圾回收了，并做一些相关的状态设置，用户代码被冻结。所以有时候用户程序对垃圾回收器不友好是可能造成卡顿的，比如说在极短的时间内大量创建了微小对象，逼的垃圾回收器执行频率升高，卡顿就会明显，这种情况就要考虑用对象池等方式来优化。\n垃圾回收的过程主要涉及怎么触发、怎么启动、怎么标记、怎么清理这些问题，我们下面来详细了解这些问题。\n触发 有三种情况会触发垃圾回收，通过自动触发，手工触发，系统监控程序来触发。\n自动触发是有一个阈值(nextGC)，默认可能是4MB或者8MB，当在堆上分配的内存超过该阈值，则自动启动回收，每次启动后调整下次阈值翻倍。\n手工强制使用runtime.GC这样的代码来执行垃圾回收，这种方式不会去检查阈值，往往用来模拟和测试。\n为什么还需要系统监控程序触发呢？假设某段时间有个热点，内存突然使用了100MB，那么自动触发的阈值就会被推高到200MB，这时候热点消失内存只使用了50MB时，可能在50~200之间一直没法触发自动回收而产生大量垃圾。系统监控程序会检查上次垃圾回收若已经超过2分钟，则强制执行一次垃圾回收，这种方式也不会检查阈值。\n那么自动触发时如何检查阈值是否达到呢？正常想法可能是每次执行malloc(size)函数的时候累加其size并检查一次，这种效率会很低，每次分配都去检查，且这个函数被所有的P/M共享就涉及到需要加锁。Go中采用的优化策略是不在malloc(size)时检查，只有在大对象分配的时候才检查，因为内存分配只有两种情况，要么从操作系统拿回一大块内存来分配给某个大对象，要么拿回一大块内存切成N多小块复用。\n启动 启动的第一步就是开启STW，让所有的P/M进入到一种特殊的状态。其实开启STW之前还要做一件事情，上一个垃圾回收周期的清理工作。然后垃圾回收的相关指令和函数会被打包为一个个worker，进而作为G对象交给调度器执行，垃圾回收代码和用户代码都是G对象从而实现了并发。\nworker worker分为三种，第一种属于正式工，专门做垃圾回收；第二种属于小时工，执行一段时间垃圾回收就释放P/M执行用户逻辑；第三种是临时工，没有用户G的时候，P/M会闲置，就可能有临时工来执行一段时间。如果没有正式工，小时工和临时工随时都可能因为抢占式调度去执行用户代码，可能导致垃圾回收无法结束；如果都是正式工也不行，正式工不会被抢占，用户逻辑可能被饿死；所以有了小时工和临时工，小时工算是辅助正式工来加快垃圾回收的效率，而临时工更不靠谱，只有在P/M闲置时才可能来帮忙。\n这种种措施就是要保证:\n 垃圾回收一定能够完成 垃圾回收尽可能快的完成 垃圾回收不能影响用户代码的执行  controller 在一个垃圾回收的周期内，会有一个controller来收集信息，它会收集完成这个周期花了多少物理时间，花了多少CPU时间，开始和结束的时候堆的大小，使用的正式工、临时工、小时工的数量。通过这些信息，controller就会去推算下一个周期垃圾回收的阈值应升高还是降低，比如nextGC当前是4MB，下一次就应该是8MB，通过controller推算出应该降低10%，那最终触发的阈值就是7.2MB；另外，controller也会去推算多少正式工、临时工、小时工参与是合理的。这些推算都是概率问题，属于局部性原则的一种应用，本次垃圾回收的压力大，那么下次垃圾回收压力大的概率就高一些。这种简单的策略为垃圾回收增加了一些灵活性，比僵化的阈值设定要好一些。\n标记 三色标记 启动之后就要开始执行标记操作，标记有一个基本的规则叫三色标记原则。\n我们把任一段代码编译之后，会发现编译器插入一些例如PCDATA这样的指令，它属于伪指令，是为了在编译时记录对象的相关信息以及一些元数据信息，这些信息可以用来给内存分配器提供参考:当在堆上分配一个对象的时候，除了去分配相应的内存(比如起始位置0x100100)，还会在一个位图中查找到索引0x100100的位置，按照元数据中的类型信息标记出该对象的第几个位置是指针。\n而一个对象要么是从全局变量引用下来，要么是从栈上引用下来，自然就会有根对象，这个根对象就是位图中的指针。垃圾回收的时候就是先去查看位图有没有指针，根据指针一路追踪扫描下去。\n在一次扫描开始时，会认为所有的对象是白色的。根对象一定是活的，那么被它引用的对象也一定是活的，就把它标记为灰色的，并把它的引用放在一个队列中去。接着把这个队列的灰色对象依次拿出来，比如先拿出了灰色的A，看A引用的对象是什么，把A引用的对象重新加到队列中去，并把A标记为黑色。重复执行这个过程，那么最终就只会剩下两种对象，黑色的和白色的，黑色的是活着的，白色的是死掉的。\n写屏障 但还有个问题没有解决，标记的同时用户代码也在执行，如果已经标记为黑色的对象又引用了一个白色对象C怎么办，因为不会对黑色对象进行二次扫描，在最终清理时就会把这个C也误杀掉。为了解决这个问题，在编译期编译器就会对指针写操作的语句插入一段写屏障代码，这段代码会判断如果当前正在垃圾回收，指针的写操作不会立即执行，而是先执行写屏障逻辑。写屏障逻辑会判断这个指针若是黑色的，就把它重新变成灰色的加入队列进行二次扫描。\n具体如何加入写屏障的，我们可以看如下示例: var x *int func main(){ x = new(int) println(x) }\n然后我们编译并反汇编: [ubuntu] ~/.mac $ go tool objdump -s \u0026#34;main\\.main\u0026#34; test TEXT main.main(SB) /root/.mac/test.go test.go:5\t0x452330\t64488b0c25f8ffffff\tMOVQ FS:0xfffffff8, CX test.go:5\t0x452339\t483b6110\tCMPQ 0x10(CX), SP test.go:5\t0x45233d\t766a\tJBE 0x4523a9 test.go:5\t0x45233f\t4883ec18\tSUBQ $0x18, SP test.go:5\t0x452343\t48896c2410\tMOVQ BP, 0x10(SP) test.go:5\t0x452348\t488d6c2410\tLEAQ 0x10(SP), BP test.go:6\t0x45234d\t488d052cbc0000\tLEAQ 0xbc2c(IP), AX test.go:6\t0x452354\t48890424\tMOVQ AX, 0(SP) test.go:6\t0x452358\te8038afbff\tCALL runtime.newobject(SB) test.go:6\t0x45235d\t488b442408\tMOVQ 0x8(SP), AX test.go:6\t0x452362\t833d37dd080000\tCMPL $0x0, runtime.writeBarrier(SB) test.go:6\t0x452369\t7530\tJNE 0x45239b  test.go:6\t0x45236b\t4889058e270700\tMOVQ AX, main.x(SB) test.go:7\t0x452372\te83931fdff\tCALL runtime.printlock(SB) test.go:7\t0x452377\t488b0582270700\tMOVQ main.x(SB), AX test.go:7\t0x45237e\t48890424\tMOVQ AX, 0(SP) test.go:7\t0x452382\te8293afdff\tCALL runtime.printpointer(SB) test.go:7\t0x452387\te8b433fdff\tCALL runtime.printnl(SB) test.go:7\t0x45238c\te89f31fdff\tCALL runtime.printunlock(SB) test.go:8\t0x452391\t488b6c2410\tMOVQ 0x10(SP), BP test.go:8\t0x452396\t4883c418\tADDQ $0x18, SP test.go:8\t0x45239a\tc3\tRET test.go:6\t0x45239b\t488d3d5e270700\tLEAQ main.x(SB), DI test.go:6\t0x4523a2\te8f998ffff\tCALL runtime.gcWriteBarrier(SB) test.go:6\t0x4523a7\tebc9\tJMP 0x452372  test.go:5\t0x4523a9\te8f27affff\tCALL runtime.morestack_noctxt(SB) test.go:5\t0x4523ae\teb80\tJMP main.main(SB)\n我们看到new(int)对应CALL runtime.newobject(SB)，之后通过CMPL $0x0, runtime.writeBarrier(SB)进行比较，比较结果为真则跳转至下面的CALL runtime.gcWriteBarrier(SB)，执行完了再跳转回去继续赋值。\n// src/runtime/mgc.go var writeBarrier struct { enabled bool // compiler emits a check of this before calling write barrier \tpad [3]byte // compiler uses 32-bit load for \u0026#34;enabled\u0026#34; field \tneeded bool // whether we need a write barrier for current GC phase \tcgo bool // whether we need a write barrier for a cgo check \talignme uint64 // guarantee alignment so that compiler can use a 32 or 64-bit load } 我们通过写屏障的定义也就知道了$0x0是和这里的enabled进行比较的，这种简单的比较对性能的影响是非常小的。\n挣工分 还有一个问题，用户代码中分配对象的速度远大于回收的速度，造成垃圾回收无法结束。这种情况如何处理呢？\n每次分配对象的时候，会去检查若当前正在垃圾回收，则每个G对象都会有一个信用值，分配一个size大小的对象，就把这个信用值减去size，直到这个信用值为负数，则把这个执行一半的G暂停并保存上下文丢回给调度器，其绑定的P/M来帮助进行垃圾回收挣工分，工分挣到一定程度比如3倍的信用值则接着去执行用户代码(这个可能就不会接着之前暂停的G、可能是任意G)。\n但是仅这种挣工分来还债再接着执行用户代码的方式效率可能会很低，因为本身垃圾回收器就有worker，这些worker可能突然执行效率很高，导致来协助挣工分的P/M挣不到，于是就有了一个公用的信用值来存储垃圾回收器中workder挣的工分。所以当公用的信用值还有额度的时候，说明垃圾回收的压力还不大，用户G会先去尝试扣减这个公用信用值，如果不够扣才会去帮助垃圾回收。\n清理 标记完之后如何清理呢？内存是分块的，每个大块下又分了很多小块，每个小块可能代表一个对象。它还有一份元数据，是一个位图，位图和这些内存块一一对应。所谓的回收清理只是标记出在这个位图中哪些块是死了的，告诉内存分配器哪些块是可以合并的等，以便于下一次能直接复用。\n清理操作也是和用户代码并发的，但要清理的这些对象和用户逻辑之间没有任何干扰，互相不影响，相对比较容易。\n总结 在研究垃圾回收器的设计过程中，我们发现整个处理过程是比较复杂的。垃圾回收器的设计中有大量的细节处理是在找平衡，在执行效率和空间占用中找到平衡。\n"});index.add({'id':14,'href':'/docs/go/map/','title':"字典",'content':"字典 现代编程语言，例如Python和Go中都有字典，其作为一种常见数据结构使用频率非常高。一般作为内置类型，解释器或者编译器都会对其特别的照顾，做相当多的优化，它的设计也需要在通用和性能上找到平衡，当然也是我们非常好的学习案例。\n要存储一批数据，我们最先想到的就是用数组，因为它对所有的存储器亲和性是最好的，内存可以看成是一个大的字节数组，CPU cache line也是一个64字节的数组。但数组有个问题，即索引效率低，我们往往是通过排序然后进行二分查找来提高索引的效率。可是如果我们的数据需要频繁的编辑(插入、删除、修改)时，这种排序就可能造成我们需要频繁的对其中的局部进行重排，这时候延伸出了大小堆、树堆等各种各样的结构来解决这些问题。其中有一种数据结构，也就是我们今天要提到的字典(map/dict)，它在各方面效率做到了很好的平衡，它的经典实现方式是hash table，也有很多其它实现方式，但不管是怎样实现的，映射在内存层面仍然是数组，那么它是怎样实现的呢？\n首先，我们不考虑value，仅看key是怎么映射到数组上的。数组通过下标数字访问，不管key是什么类型，我们都需要把它通过哈希函数转换为一个数字，若得到的数字很大超过了数组的长度，我们就可以通过取模(n%len)的方式来得到它在数组中的位置。所以任何一个可哈希的Key我们都能把它映射到数组上的某个位置，那么我们就可以把key-value打包为一个struct放在数组中某个位置，解决了高效的查找和编辑的问题。\n接下来的问题就是哈希碰撞了。当两个key哈希并取模后的结果是相同的数字时，有一个简单的处理方式就是用链表链起来，即链表法，把一个横向的大的数组转化为了多个纵向的小的链表，Go采用的这种方式。另外一种方法就是若发现冲突，则把新的key加上一个magic_number计算得出一个新的位置，横向的填充到这个空位，称为开放寻址法，Python采用这种方式。\n链表法的问题就在于链表的访问效率差，如何优化？当CPU去读取数据时，它会基于空间局部性原则将附近的数据从内存读入L3，然后是L2、L1。那么我们基于这个原则，应当把链表转换为数组，把原有的一个个的item放入一个桶中:\n把每8(或8的倍数)个item当做一个桶，一个桶链接另一个桶。当我们需要根据某个查询条件查询数据的时候，我们可以把整个桶拿出来遍历查找，很可能整个桶是被L1或者L3缓存过的，这个访问效率就可能比在内存中去读取快上百倍。\n那么针对这个桶是否还有优化空间呢？我们发现遍历的时候是去判断它的key是否相等，并不需要知道它的value。按照当前这种结构value就占用了缓存器的空间:\n我们应该尽可能的缓存更多的keys，于是可以把桶分为上下两个部分:\n那么还能进一步优化吗？我们发现keys的数据类型不知道，如果是个整数倒还很容易和查询条件做比较，但若是个字符串，两个字符串的比较效率是非常低的。针对这种情况，我们可以再做一层访问拦截:\n这层数组放入keys的哈希值，只有当某个位置的哈希值和查询条件匹配时，我们才会去进一步比对keys数组中对应位置的key。这样我们就通过一个整数型数组拦截掉了很多的预判。甚至这个整数数组也无需使用int64，我们只取hashcode的高位构成一个int8类型，[8]int8形成一个64位的数组正好能被一个寄存器存下。\n另外这层数组像一个位图，还能用来判断这个桶中还有没有空位，插入数据时先看数组中是否有空位就可以相应的在keys和values中找到空位，删除数据时也不会进行收缩，只是在相应的位置上做标记。\n现在，我们经过一层层的优化，字典变成了这个样子:\n只要哈希算法分布的很平均，那么基础数组越长，桶的链表就越短，访问效率也越高，这就涉及到一个扩容的问题。随着数据的插入，键值对的总个数和基础数组的长度有一个比例，当这个比例达到一个阈值，就会触发扩容操作。扩容时我们不能直接新建个基础数组，然后把原数组数据一次性搬过去，这种方式会导致某次操作的时间过长使应用卡死。而应该在触发时，设定一个标志，之后对这个字典的每次查询、修改、插入、删除都先去检查这个标志，若标志为真且本次操作的数据在旧字典中，则将它及附近的一段数据都迁移至新字典，这叫随机迁移。同时，为防止每次操作都发生在新字典中，其内部还有个计数器，让其迁移时能够从旧字典的头部再顺序迁移一部分数据，也就是顺序迁移。这样就能保证所有的数据都被迁移过去，迁移完成后，旧字典整个被释放掉。\n当删除字典元素时，对于Go这种关注性能的语言，字典的内存不会被压缩，可能会造成内存浪费。如果有大量删除元素的情况，只能新建一个字典，把旧字典的数据手工搬过去，让垃圾回收器回收旧字典。基于这个原因，我们在桶中应该去存储keys和values的内容而不是它们的指针。因为key和value的生命周期是和整个map相同的，不存指针也就意味着减轻了垃圾回收期的压力，原本需要检查回收1(map)+n(keys)+n(values)个对象变为了只需检查1个map对象。所以Go中做了如下设定，如果key和value的长度小于128字节，同时key和value本身不是指针，那么它们会被嵌入到字典内部。\n通过以上，我们了解到任何一个看似简单的东西背后可能都隐藏了复杂的设计。\n"});index.add({'id':15,'href':'/docs/other/tools/','title':"常用工具整理",'content':"常用工具整理 体检工具 生产环境不同于开发环境，生产环境往往是一个很干净的、只保留了相关依赖的环境，而且需要运行很长的时间。而开发环境属于实验室性质的，类库比较齐全，只跑个单元测试或者benchmark之类的，运行时间很短。所以开发环境中很小的问题比如内存泄漏几KB，在生产环境随着时间的累积或者成千上万的访问，可能会把垃圾回收器搞崩溃。这种情况如果我们不擅于使用工具可能找不到任何问题。\n另外，开发环境我们可以使用100%的资源，但生产环境一定要预留一些资源用来做调度、预警之类的。\ndstat 它能实时查看一些基本信息，默认情况下它会包括:\n CPU基本信息(用户使用时间、系统使用时间、空闲时间等) 磁盘基本信息(读、写) 网络基本信息(接受、发送) 换入换出信息 系统基本信息(中断的次数、上下文切换的次数)  如下所示: [ubuntu] ~/.mac $ dstat You did not select any stats, using -cdngy by default. --total-cpu-usage-- -dsk/total- -net/total- ---paging-- ---system-- usr sys idl wai stl| read writ| recv send| in out | int csw 0 0 100 0 0|2797B 597B| 0 0 | 0 0 | 90 236 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 140 323 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 163 376 0 1 100 0 0| 0 0 | 0 0 | 0 0 | 169 391\n生产环境下我们程序出错的时候，应该先从大的方面入手定位到具体是哪个方面的问题，看看当前的系统环境有没有问题，是不是我们的程序在当前的系统环境下水土不服。比如程序是IO密集型的，系统中有另一个程序在和它抢磁盘资源等。可以通过dstat --list查看它能对哪些细分项目查看其情况。查看更多使用示例\nsysstat 通过定位了系统中哪个方面的问题之后，接着我们应该去定位我们自己程序哪个方面有问题。sysstat可以根据单个进程去检查它的各个方面，比如说我们定位到是内存方面的问题，接着去看自己程序中内存的问题: [ubuntu] ~/.mac $ pidstat -r -p `pidof tmux` 2 Linux 4.9.184-linuxkit (cabd4e519687) 12/09/19 _x86_64_\t(2 CPU) 10:02:38 UID PID minflt/s majflt/s VSZ RSS %MEM Command 10:02:40 0 35 0.00 0.00 27424 4000 0.20 tmux: server 10:02:42 0 35 0.00 0.00 27424 4000 0.20 tmux: server 10:02:44 0 35 0.00 0.00 27424 4000 0.20 tmux: server 10:02:46 0 35 0.00 0.00 27424 4000 0.20 tmux: server 我们把tmux当做是自己写的某个程序，每2秒输出一次信息。minflt/s就代表一些小范围的缺页异常，可能是一些数据不需要了只要补上相应的物理内存即可。而majflt/s代表了需要从硬盘换入内存，这可能就意味着我们程序是不是有的任务优先级太低被操作系统换出到硬盘上了，我们可能需要通过系统调用告诉操作系统把某段内存锁死。\n更详细的使用方法，请参考官方文档。\nstrace 接着我们可以深入到自己程序的逻辑中去，比如使用strace检查我们程序的系统调用。可能只是一个简单的程序: package main func main() { println(\u0026#34;hello world!\u0026#34;) }\n却涉及到大量的系统调用: [ubuntu] ~/.mac $ go build test.go [ubuntu] ~/.mac $ strace ~/.mac/test execve(\u0026#34;/root/.mac/test\u0026#34;, [\u0026#34;/root/.mac/test\u0026#34;], 0x7ffec1a0b740 /* 14 vars */) = 0 arch_prctl(ARCH_SET_FS, 0x4c5650) = 0 sched_getaffinity(0, 8192, [0, 1]) = 16 openat(AT_FDCWD, \u0026#34;/sys/kernel/mm/transparent_hugepage/hpage_pmd_size\u0026#34;, O_RDONLY) = -1 ENOENT (No such file or directory) mmap(NULL, 262144, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd246a01000 mmap(0xc000000000, 67108864, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xc000000000 mmap(0xc000000000, 67108864, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0xc000000000 mmap(NULL, 33554432, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd244a01000 mmap(NULL, 2164736, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd2447f0000 mmap(NULL, 65536, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd2447e0000 mmap(NULL, 65536, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fd2447d0000 rt_sigprocmask(SIG_SETMASK, NULL, [], 8) = 0 sigaltstack(NULL, {ss_sp=NULL, ss_flags=SS_DISABLE, ss_size=0}) = 0 sigaltstack({ss_sp=0xc000002000, ss_flags=0, ss_size=32768}, NULL) = 0 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0 gettid() = 394 rt_sigaction(SIGHUP, NULL, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, 8) = 0 rt_sigaction(SIGHUP, {sa_handler=0x44d8f0, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x44da20}, NULL, 8) = 0 rt_sigaction(SIGINT, NULL, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=0}, 8) = 0 rt_sigaction(SIGINT, {sa_handler=0x44d8f0, sa_mask=~[], sa_flags=SA_RESTORER|SA_ONSTACK|SA_RESTART|SA_SIGINFO, sa_restorer=0x44da20}, NULL, 8) = 0 ......\n打印输入输出必然会涉及系统调用，但如果我们使用一些第三方库时发现系统调用仍然很多，就可以去查找有没有优化替代的方案。\n一般，我们查看一些摘要信息即可: [ubuntu] ~/.mac $ strace -c ~/.mac/test hello world! % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 0.00 0.000000 0 1 write 0.00 0.000000 0 7 mmap 0.00 0.000000 0 114 rt_sigaction 0.00 0.000000 0 6 rt_sigprocmask 0.00 0.000000 0 2 clone 0.00 0.000000 0 1 execve 0.00 0.000000 0 2 sigaltstack 0.00 0.000000 0 1 arch_prctl 0.00 0.000000 0 1 gettid 0.00 0.000000 0 3 futex 0.00 0.000000 0 1 sched_getaffinity 0.00 0.000000 0 1 1 openat ------ ----------- ----------- --------- --------- ---------------- 100.00 0.000000 140 1 total\n开发工具 GNU通用的开发工具，也叫binutils，是一个标准，属于随身带的瑞士军刀，任何语言编写的程序都适用，但可能与语言自带的工具链细节上有些出入。官方网站\n它主要包括:\n readelf : 查看ELF文件信息。 objdump : 查看⽬标文件 (ELF/COFF) 信息。 addr2line : 将地址转换为文件行号信息。 nm : 查看符号表。 strip : 删除符号表。 objcopy : 拷⻉数据到⽬标文件。 strings : 输出字符串。 size : 查看各段⼤小。  当我们不熟悉一门语言写的程序时，我们可以把它翻译成汇编语言，在把汇编语言翻译成C语言，也许这个C语言无法运行，但方便了我们阅读和理解程序的思路。\nreadelf 查看elf文件的头部信息: [ubuntu] ~/.mac/assem $ readelf -h hello ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 // 魔法数，可以快速读取出来用于预判整个文件是不是一个合法的内容 Class: ELF64 // ELF文件的格式 Data: 2\u0026#39;s complement, little endian // 大小端情况 Version: 1 (current) OS/ABI: UNIX - System V // 哪个平台使用 ABI Version: 0 Type: EXEC (Executable file) // 哪种类型，可执行的还是需重定位的等 Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x4000b0 //入口地址 Start of program headers: 64 (bytes into file) Start of section headers: 736 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 2 Size of section headers: 64 (bytes) Number of section headers: 8 Section header string table index: 7\n查看其执行时需要向内存(进程)中载入哪些信息: [ubuntu] ~/.mac/assem $ readelf -l hello Elf file type is EXEC (Executable file) Entry point 0x4000b0 There are 2 program headers, starting at offset 64 Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align LOAD 0x0000000000000000 0x0000000000400000 0x0000000000400000 0x00000000000000d5 0x00000000000000d5 R E 0x200000 LOAD 0x00000000000000d8 0x00000000006000d8 0x00000000006000d8 0x000000000000000e 0x000000000000000e RW 0x200000 Section to Segment mapping: Segment Sections... 00 .text 01 .data\n查看其本身的section信息: [ubuntu] ~/.mac/assem $ readelf -S hello There are 8 section headers, starting at offset 0x2e0: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 00000000004000b0 000000b0 0000000000000025 0000000000000000 AX 0 0 16 [ 2] .data PROGBITS 00000000006000d8 000000d8 000000000000000e 0000000000000000 WA 0 0 4 [ 3] .stab PROGBITS 0000000000000000 000000e8 0000000000000084 0000000000000014 4 0 4 [ 4] .stabstr STRTAB 0000000000000000 0000016c 0000000000000009 0000000000000000 0 0 1 [ 5] .symtab SYMTAB 0000000000000000 00000178 0000000000000108 0000000000000018 6 7 8 [ 6] .strtab STRTAB 0000000000000000 00000280 0000000000000027 0000000000000000 0 0 1 [ 7] .shstrtab STRTAB 0000000000000000 000002a7 0000000000000036 0000000000000000 0 0 1 Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), l (large), p (processor specific)\n查看其section的内容，例如我们想看其.data段的，它是第2个段，可以使用16进制和字符串的方式: [ubuntu] ~/.mac/assem $ readelf -x 2 hello Hex dump of section \u0026#39;.data\u0026#39;: 0x006000d8 68656c6c 6f2c2077 6f726c64 210a hello, world!. [ubuntu] ~/.mac/assem $ readelf -p 2 hello String dump of section \u0026#39;.data\u0026#39;: [ 0] hello, world!\n查看其符号表信息: [ubuntu] ~/.mac/assem $ readelf -s hello Symbol table \u0026#39;.symtab\u0026#39; contains 11 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 00000000004000b0 0 SECTION LOCAL DEFAULT 1 2: 00000000006000d8 0 SECTION LOCAL DEFAULT 2 3: 0000000000000000 0 SECTION LOCAL DEFAULT 3 4: 0000000000000000 0 SECTION LOCAL DEFAULT 4 5: 0000000000000000 0 FILE LOCAL DEFAULT ABS hello.s 6: 00000000006000d8 1 OBJECT LOCAL DEFAULT 2 hello 7: 00000000004000b0 0 NOTYPE GLOBAL DEFAULT 1 _start 8: 00000000006000e6 0 NOTYPE GLOBAL DEFAULT 2 __bss_start 9: 00000000006000e6 0 NOTYPE GLOBAL DEFAULT 2 _edata 10: 00000000006000e8 0 NOTYPE GLOBAL DEFAULT 2 _end 此外，-e代表同时加上-h -l -S三个参数。\nnm 使用nm也可查看其符号表信息:\n[ubuntu] ~/.mac/assem $ nm hello 00000000006000e6 D __bss_start 00000000006000e6 D _edata 00000000006000e8 D _end 00000000004000b0 T _start 00000000006000d8 d hello 其中，00000000006000e6表示链接器安排给这个符号的虚拟内存地址；D表示它的类型，大写是全局的、可以跨文件访问到的，小写表示本地的。\nstrip 使用strip可以剔除其符号表，减少文件本身的大小。默认为-s剔除的符号，也可以-S仅剔除掉调试用的符号。 [ubuntu] ~/.mac/assem $ strip -S hello [ubuntu] ~/.mac/assem $ readelf -s hello Symbol table \u0026#39;.symtab\u0026#39; contains 8 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 00000000006000d8 1 OBJECT LOCAL DEFAULT 2 hello 2: 00000000004000b0 0 SECTION LOCAL DEFAULT 1 3: 00000000006000d8 0 SECTION LOCAL DEFAULT 2 4: 00000000004000b0 0 NOTYPE GLOBAL DEFAULT 1 _start 5: 00000000006000e6 0 NOTYPE GLOBAL DEFAULT 2 __bss_start 6: 00000000006000e6 0 NOTYPE GLOBAL DEFAULT 2 _edata 7: 00000000006000e8 0 NOTYPE GLOBAL DEFAULT 2 _end [ubuntu] ~/.mac/assem $ strip -s hello [ubuntu] ~/.mac/assem $ readelf -s hello [ubuntu] ~/.mac/assem $ nm hello nm: hello: no symbols\nobjcopy 可以在可执行文件中自己创建section，藏一些东西，比如背景mp3文件等。我们就可以用到objcopy工具:\n[ubuntu] ~/.mac/assem $ objcopy --add-section .abc=addr.c --set-section-flags .abc=noload,readonly hello hello2 [ubuntu] ~/.mac/assem $ readelf -S hello2 There are 5 section headers, starting at offset 0x190: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 00000000004000b0 000000b0 0000000000000025 0000000000000000 AX 0 0 16 [ 2] .data PROGBITS 00000000006000d8 000000d8 000000000000000e 0000000000000000 WA 0 0 4 [ 3] .abc PROGBITS 0000000000000000 000000e6 0000000000000088 0000000000000000 0 0 1 [ 4] .shstrtab STRTAB 0000000000000000 0000016e 000000000000001c 0000000000000000 0 0 1 [ubuntu] ~/.mac/assem $ readelf -p .abc hello2 String dump of section \u0026#39;.abc\u0026#39;: [ 0] // 查看基址变址的寻址方式^J#include \u0026lt;stdio.h\u0026gt;^J^Jint main(){^J int x[3];^J for(int i=0;i\u0026lt;3;i++){^J x[i]= 0x22;^J 我们为可执行文件hello新增了一个.abc的段，它的内容读取自addr.c文件，它的权限是只读的且无需载入的，并且把它另存为了hello2。此外，我们也可以使用别的文件的内容来更新某个section，或者对section进行重命名、删除等操作: [ubuntu] ~/.mac/assem $ objcopy --rename-section .abc=.demo hello2 [ubuntu] ~/.mac/assem $ objcopy --update-section .demo=makefile hello2 [ubuntu] ~/.mac/assem $ objcopy --remove-section .demo hello2\nobjdump 主要用来查看反汇编代码，使用objdump -d \u0026lt;file\u0026gt;反汇编某文件.text段的内容，默认为att格式，可使用-M指定其他格式。 [ubuntu] ~/.mac/assem $ objdump -M intel -d fr fr: file format elf64-x86-64 Disassembly of section .text: 00000000004000b0 \u0026lt;_start\u0026gt;: 4000b0:\tb8 01 00 00 00 mov eax,0x1 4000b5:\t48 85 c0 test rax,rax 4000b8:\t75 1b jne 4000d5 \u0026lt;_start.exit\u0026gt; 00000000004000ba \u0026lt;_start.hello\u0026gt;: 4000ba:\tb8 01 00 00 00 mov eax,0x1 4000bf:\tbf 01 00 00 00 mov edi,0x1 4000c4:\t48 be e0 00 60 00 00 movabs rsi,0x6000e0 4000cb:\t00 00 00 4000ce:\tba 0e 00 00 00 mov edx,0xe 4000d3:\t0f 05 syscall 00000000004000d5 \u0026lt;_start.exit\u0026gt;: 4000d5:\tb8 3c 00 00 00 mov eax,0x3c 4000da:\t48 31 ff xor rdi,rdi 4000dd:\t0f 05 syscall\n调试工具 GNU通用的调试工具，也叫gdb。binutils属于静态的观察，而gdb就可以动态的观察到每一个汇编指令的执行。官方网站\n也可以使用一些带图形界面的类似工具，例如gdbgui。还有些cheatsheet很好用。\n常用指令\n   指令 作用     info r 查看寄存器   info f 查看栈帧   info files 查看文件的各个段的起始地址   info var 查看全局变量   info locals 查看局部变量   info breakpoints 查看断点信息   bt 显示程序的栈   set disassembly-flavor intel 设置反汇编的风格为intel或att   disass 查看反汇编   layout src 显示源码窗口   display [var] 每次停下来时都会输出变量var的值，var可以设为寄存器   l [n] 查看第N行代码的上下五行   c 运行至下一断点或程序结束   p/x $[var] 以16进制输出变量var的值，也可输出表达式，不加/x为十进制   x/10xb [addr] 查看内存地址addr开始的10组数据，16进制的，单位是字节    构建工具 GNU的自动构建工具为make，有些像脚本语言，把一堆命令放一起批量执行。使用它做编译属于增量编译，即通过对比修改时间来判断是否需要重新执行。官方网站\nhello: hello.s nasm -g -f elf64 -o hello.o hello.s ld -o $@ hello.o clean: -rm *.o -rm hello .PHONY: clean  对于这段构建代码，hello:后的部分就是告诉它要去检查哪些文件的修改时间；$@就表示当前这段的目标hello，$\u0026lt;表示这段的第一个依赖项，$^表示这段的所有依赖项；命令前加-表示该命令如有错误则忽略；PHONY表示没有目标，没有依赖，总是执行规则，在该例中，若恰好文件夹内有一个名为clean的文件，没有PHONY时则make clean不会执行；另外，由于历史原因makefile只能使用tab来缩进，不能使用空格。\n"});index.add({'id':16,'href':'/docs/sicp/hardware/','title':"硬件部分",'content':"计算机科学基础知识之硬件部分 现代计算机体系的基础理论部分仍然是70年代就已经产生的，这些年来一直没有多大突破，只是制造水平和加工工艺在逐步提升。未来除非是量子计算、生物计算等发展成熟，才可能使得计算机基础理论获得革命性突破。\n我们在应用软件开发领域，往往非常善于创造包装一些名词，但它们的本质就是那么回事，学习计算机体系的理论有助于我们抓住这些本质。\n体系结构 CPU要运行一个程序，它需要指令和数据，指令相当于你要干什么，数据是干这件事所需要的材料。\n冯诺依曼结构 冯诺依曼结构就是把指令也当做数据，把指令和数据放在一起。好处就是设计上会简单一些，可以使用一条总线集中存储；另外它还采用了二进制编码的线性地址空间。缺点就是它的数据传输效率远低于CPU的运算效率，因此需要缓存来提升效率。\n它的CPU有两套单元：\n ALU：算术逻辑单元，实现多组算术和逻辑运算。由与门和或门组成，进行二进制的算术运算，包括加、减、乘、与、或、非、异或。 CU：控制单元，用于程序流程的管理。从内存中取指令放入指令寄存器中分析并执行。  PS：在系统层面上，我们说的内存并不是指物理上的两根内存条，那个叫主存。比如硬盘上的缓存也是内存、打印机上也有缓存等等。\n哈佛结构 哈佛结构将指令和数据分开处理，指令和数据拥有不同的总线和地址空间，并行能力非常强，早期的大型计算机就采用这种结构。缺点就是早期电子电路昂贵，成本的问题使得它不适合于通用计算机没有推广开来。 现在纯粹的哈佛结构多用于数字信号处理器(DSP)、单片机等特定领域，它们的指令相对简单也没有缓存。\n对比总结 实际上现代计算机是对两种架构做了一些折中的。在内存中指令和数据是在一起的，在CPU的L1缓存中，会区分指令缓存和数据缓存，最终执行的时候指令和数据是从两个不同的地方出来的。另外冯诺依曼统一的地址空间也便于我们实现操作系统内存的管理、动态加载程序、JIT等。\n总线 我们通常所说的总线未必是电路板上一条条线路，它只是一种方式，可能是软件的，也可能是硬件的，代表了一整套的规范体系。就像高速公路交通网，包括了公路、收费站、加油站、维护人员、交通规则、信号灯指示牌，总线也是一样，除了数据通道，还包括了数据交换方式，比如从何处取(内存)，从哪开始从哪结束有多长，取出来的是数据还是地址等。\n现在主流的总线标准为PCI/PCIe，该标准的带宽高，能探测硬件变更，支持热插拔。\n总线结构 按照不同的传输速度，我们会把总线分开，通过不同的速度来进行分流，使快速的部分拥有更多的流量带宽。北桥芯片处理快速设备，例如CPU、内存、显卡等，南桥芯片处理慢速设备，例如硬盘、网卡等。\n前端总线(FSB)负责CPU与北桥芯片的数据传输，代表CPU与外界数据的通讯速度，相当于CPU能处理的最高能力。而后端总线(BSB)负责与CPU内核通讯，其速度高于FSB。现在的芯片集成度越来越高的趋势也正是因为想减少各样的总线来提升各部件之间传输的速度。\n中央处理器 中央处理器是用来解释指令、处理数据的。编程实质上就是针对CPU而言的。例如我们往硬盘里写一个文件，就要知道文件名称、写在哪个地址、写入的长度等，即使这些工作不全是由CPU完成，CPU至少也要完成其中的调度工作。\n主频、外频 主频是内核工作频率，表达脉冲信号的震荡速度，与CPU的实际运算能力没有直接关系。而外频是内核与主板间的同步速度，同时也是内存和主板之间的同步速度。\n对现代的CPU而言，衡量其运算速度和性能要看各方面的性能指标，例如缓存、指令集等。很可能出现主频较高的CPU实际运算速度较低的情况。\n指令集 指令集是包含了基本数据类型、指令、寄存器、寻址模式、存储体系、中断和异常处理等打包的一套规范，是CPU真正能够理解的东西。\n我们通常分为精简指令集(RISC)和复杂指令集(CISC)。\n典型的复杂指令集就是x86，它的指令特别多，功能丰富，但每条指令的字长不等，也就造成了它需要先读出指令才知道后面的数据/参数有多长，执行速度相对较慢。而有一些虚拟机内会把指令设置为定长的，默认就是两个参数，这样它的缓存亲和性好，效率就高。x86这么设计有一些历史原因，当时还没有CPU缓存的概念。而精简指令集在早期反而是一种高大上的东西，它的指令和寻址方式少，格式统一，并行速度快，主要用于大型机和中高档服务器中。\nIntel认为自己定义的x86指令集由于历史原因等不好，于是在64位时代定义了IA-64指令集，但这种指令集和以前的x86并不兼容，它采用了模拟的方式去运行x86，这种方式在当时的windows2000等系统上运行的不好，所以微软持反对态度。此时AMD抓住了机会，它基于原有的386/IA-32标准做了扩充，也就有了现在的x86-64指令集，也可以叫做x64或AMD64。后来，Intel迫于其他厂商的压力，也去使用AMD64指令集，并在后来发展出了兼容的Intel 64，这种指令集和AMD64大部分是相同的。\n32位处理器的最大寻址为4GB(2的32次方)，但64位处理器的最大寻址却不是2的64次方。我们知道存储单位的级别从小到大分别为Bytes、KB、MB、GB、TB、PB、EB，每级都等于前一级*1024，所以AMD64理论上可以访问16EB的地址空间，但目前的操作系统只支持到48位，也就是256TB的最大寻址，这种设定的根本原因就是能降低成本。\n此外，AMD64里增加了R8-R15的通用寄存器。\n寄存器和缓存 寄存器是所有存储体里最快的一个，因为数量少，所以可以直接给每个寄存器取个名字，而无需用地址。\n早期，数据由硬盘到内存，再经过前端总线直接到寄存器，因为前端总线传输的效率远低于CPU运算的效率，为了提高性能，我们在CPU内部，寄存器和内存之间增加了一层cache，使得前端总线每次传输更多的内容进入CPU。早期的CPU缓存只有L1，它将指令和数据分开；后来发展至L2，L2不区分指令和数据；再后来多核时代有了L3，能在一个物理处理器的多个核中共享。\n缓存只是解决性能问题的一个媒介，它本身有易丢失、易覆盖的特性，不能像寄存器和主存一样当做目标存储器使用。当CPU需要一个数据时，它会先去L1找，找不到则去L2，再找不到去L3找，再找不到就会去系统总线，找到以后批量的传到L3，再把命中的一部分填充至L2，再填充至L1，再返回给处理器。所以L1里有的数据L2、L3肯定有，每级缓存数据都是下一级的一部分。\n同时，基于时间局部性(正在被访问的数据可能近期再次被访问)、空间局部性(临近地址数据可能即将被访问)、顺序局部性(大部分指令是顺序执行)，可以让缓存有较高的命中率。(PS:我们宏观世界的缓存例如web服务中的memcache往往只是基于时间局部性，因为CPU是针对指令和字节的才去讨论其空间局部性和顺序局部性)。\n我们写程序要尽可能的让其缓存亲和性更高，数据连续性更高，比如按一定长度对齐某些数据；对于性能要求高的程序，向操作系统申请锁死主存的一部分，避免被交换到硬盘当中去；甚至对于性能要求极致的场景，可以使用汇编以尽可能的使用寄存器。\n缓存由多个块组成，每个块我们称为cache line，每行的数据是连续的，每行的大小通常是64字节，行与行之间可能不连续，所以我们对齐数据的时候也是按行来对齐。同时，缓存中有很多的标志位，通过这些标志位去检查缓存是否更新，以决定是否需要置换回内存。\n多核 在一个处理器内集成多个独立实体物理内核即为多核。我们提及Core1、Core2的时候就表示多核，而CPU1、CPU2的时候则是多个CPU。多核能更好的在成本和性能上做出平衡，也不一定比多CPU慢，这主要看软件层面的优化。多核之间可以通过内部的L3缓存进行通讯或数据共享，而多CPU只能通过前端总线或额外建立其他外部通讯机制。\n多核架构又分为两种：\n对称多处理架构(SMP)，多用于桌面端。每个处理器(在多核心处理器的例子中，对称多处理架构，将每一个核心都当成是独立的处理器)的地位是平等的，对资源的使用权限相同。好处是体系简单，缺点就是由于只有一个内存控制器，存在资源竞争的问题，一般是通过软硬件锁的机制解决，但随着处理器数量增加访问冲突就会增加，效率就会下降。\n非统一内存访问架构(NUMA)，是一种为多处理器的电脑设计的内存架构。它将内存分散给多个处理器，处理器访问它自己的本地内存的速度比非本地内存(内存位于另一个处理器，或者是处理器之间共享的内存)快一些。它的扩展性更好，更适用于服务器，针对这种架构去编写程序效率也会更高。\n超线程 对于IO密集型任务，会出现CPU等待时间长的情况。那么超线程就是利用特殊的指令，在单个物理核内虚拟出多个逻辑处理器，在指令等待时做别的任务来减少闲置的时间，当然也需要额外的地方(AS，architectural state)保存当前上下文以切换任务。\n一般语言里提供的CPU数量都是逻辑处理器的数量，会将超线程虚拟的也算进去。例如python的multiprocessing.cpu_count()，或Go的runtime.NumCPU()。\n超线程多数时候可提升执行效率，但在有些情况下可能会导致性能下降，例如一些CPU密集的场合可能会对垃圾回收器造成负担；或者资源冲突时，依然需要等待，类似于同步锁。\n内存 内存严格来说叫内部存储器，不止包括物理上的内存条(即主存)，硬盘、打印机等缓存也算作内部存储器。\n这里说的是主存，即随机存取存储器(RAM，Random Access Memory)，它是与CPU直接交换数据的内部存储器。它可以随时读写，且速度很快，通常做为操作系统的临时数据存储介质。所谓的随机存取，是指当存储器的消息被读取或写入时，所需要的时间与这段信息所在的位置无关。\nDRAM 动态随机存取存储器。它具有结构简单，空间小，需要刷新的特点，往往被用于作为主存。\n需要刷新，是指电容器充满电后代表1，未充电的代表0。由于电容器或多或少有漏电的情形，若不作特别处理，电荷会渐渐随时间流失而使数据发生错误。刷新是指重新为电容器充电，弥补流失了的电荷。\nDDR是指具有双倍数据传输率的SDRAM(动态随机存取存储器)，其数据传输速度为系统时脉的两倍。\nSRAM 静态随机存取存储器。它具有结构复杂，成本高，速度快的特点，一个典型的应用就是缓存。\n所谓的“静态”，是指这种存储器只要保持通电，里面储存的数据就可以恒常保持。相对之下，DRAM里面所储存的数据就需要周期性地更新。\n双通道 它在北桥内使用两个内存控制器分别控制一个通道，从而增加寻址和存储带宽，但是由于缓存的存在，并不需要这样的带宽，所以它对性能的提升往往感受不出来。在集成显卡的场景下会有一定帮助，因为集成显卡用内存作为显存，可以专门使用一条通道。\n显卡 显卡用于转换显示信息，向显示器提供扫描信号。\n 2D芯片处理3D时需要CPU参与，称作软加速。 3D芯片自己完成，称作硬加速。  GPU是专门用来执行复杂的数学和几何计算的，它和CPU有什么区别呢？\nCPU需要很强的通用性来处理各种不同的数据类型，同时又要逻辑判断又会引入大量的分支跳转和中断的处理。这些都使得CPU的内部结构异常复杂。而GPU面对的则是类型高度统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境。GPU的核数远超CPU，被称为众核(NVIDIA Fermi有512个核)。每个核拥有的缓存大小相对小，数字逻辑运算单元也少而简单。\n当程序员为CPU编写程序时，他们倾向于利用复杂的逻辑结构优化算法从而减少计算任务的运行时间，即Latency。当程序员为GPU编写程序时，则利用其处理海量数据的优势，通过提高总的数据吞吐量(Throughput)来掩盖Latency。\n硬盘 主要的持久化存储媒介。\n分为固态硬盘(SSD)和机械硬盘(HDD)。SSD使⽤非易失性内存NAND Flash存储数据，无须电⼒维持。又分为单层SLC、双层MLC、三层TLC。单层最快，寿命最⻓，成本也最⾼。现在多使⽤MLC，TLC常作为U盘。\n其接口又分为SATA和SCSI。SATA是串行ATA，PC的标准接口。SCSI多用于小型机。\n其工作模式在BIOS可以设置，早期大多使用PIO，即通过CPU执行IO指令读写数据，CPU要持续参与。现在多使用DMA，CPU只需要在开始和结束时参与，中间由DMA控制器来完成。\nIO cpu如何访问一大堆的设备？分为PMIO和MMIO。\nPMIO(Port Mapped I/O)是指端口映射输入输出，早期的时候会把主存和其他设备分开，分别用不同的CPU指令读写。因为使用了不同的地址总线，南桥一些慢速设备的访问不会拖累主存访问的效率。\n后来发现这种方式不好，64位时代内存地址空间充裕了就使用了MMIO(Memory Mapped I/O)，它把内存地址空间分段，某一段设备用、程序用、操作系统用等，CPU使用相同的指令不同的地址就可操作设备，所有的设备都在监控地址总线，发现自己被访问就通过自身的缓存和MMU建立连接。\nBIOS 基本输入输出系统，启动后加载的第一个程序。\n最早没有操作系统的时候，写的程序就是面向BIOS的，BIOS在完成硬件初始化之后，会去执行硬盘上某个特定扇区的指令，所以只要把程序放在特定位置程序就可以启动。后来操作系统就放在那个位置，我们写的程序面向操作系统。\n它向操作系统提供系统参数、引导操作系统，但现代的操作系统比如mac就没有BIOS，而是直接控制硬件。\n"});index.add({'id':17,'href':'/docs/other/protocol/','title':"网络协议",'content':"网络协议 TCP TCP是一种可靠的网络协议，很多应用层协议都依赖它。\n包头格式 如图所示，源端口号和目标端口号用来确定发送和接收数据的双方。\n包的序号为了解决包的先后顺序问题，确认序号为了确认发出去的包对方是否已经收到，如果没有收到就会有不断重传机制来确保不会丢包。\n接下来是一些状态位，例如SYN表示发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接等。TCP是面向连接的，因而双方都要维护连接的状态，这些带状态位的包的发送会引起双方状态的变更。\n下面是窗口大小，因为TCP要做流量控制和拥塞控制，通信的双方需要各声明一个窗口来标识自己当前的数据处理能力。\n三次握手 TCP建立连接的过程，请求\u0026gt;应答\u0026gt;应答之应答，我们常称为三次握手。也经常会有人问，为什么不是两次？为什么不是四次？\n连接过程 当A发起一个连接请求，会有很多种可能，比如包丢了、超时了、B没有响应等等。A无法确认结果，只能重复发送，即使B收到了，但A不知道，还是可能再发。\nB收到以后，就知道了A的存在，以及A想和它建立连接。B若愿意建立连接的话，就需要发送一个应答包，但它若不能确定这个应答包A收到了，也就不能认为当前的连接以及建立好了。所以两次握手肯定是不行的。\nA接收到应答包之后，对于A来说它的消息有去有回，A可以认为连接是建立的，它再发送应答之应答，到了B之后，B才认为它的消息也是有去有回的，B才能确认连接是建立的。\n初始化序列号 网络的不确定性会导致数据包的丢失、顺序颠倒、重复发送等问题，为了解决这些问题，TCP协议就要求发送方在数据包种加入序列号字段，有了序列号，接收方就可以通过序列号来对数据包去重和排序，发送方就可以在对应的数据包未被ACK时进行重复发送。\n既然序列号的意义如此重要，那么在建立连接的时候就需要把序列号初始化好。A和B双方都需要向对方发送SYN控制消息并携带自己期望的初始化序列号SEQ，对方在收到SYN消息后会回复ACK控制消息以及SEQ+1来进行确认。这个过程可以表示为: 我们需要四条消息才能把序列号初始化好，由于TCP消息头的设计，B向A发送时可以一次性发送SYN和ACK消息，所以基于初始化序列号，我们也是需要三次握手的。\n历史连接 此外，A多次发送建立连接的请求，当网络状况较差时，B只能接受或拒绝A的请求，如果只有两次握手，B并不清楚这一次的请求是不是由于网络阻塞而早已过期的请求。\nTCP在连接时引入了RST消息，当接收方发回给发送方ACK, seq+1时，发送方就可以根据时间来判断这是不是一条过期超时的消息，如果是，发送方就会发RST来中止这一次连接。\n所以，三次握手和RST才能让发送的双方有足够的信息去判断当前的连接是否是错误的或者过期的。\n四次挥手 TCP关闭连接的过程可以用状态时序图表示为: 和建立连接不同，关闭连接需要四步。A作为主动关闭方，先发送FIN，收到B的ACK后，A进入半关闭状态不能再发送传输数据。此时，B进入到了CLOSE_WAIT状态，这个状态是为了让B发送还未传输完的数据，传完之后B才能发出FIN，等到A回的ACK，B关闭连接。\n但此时A进入TIME_WAIT状态，因为它没法知道ACK是否到达B。它等的结果无非是两种，要么B没有收到ACK，那么B就一定会为它的FIN消息进行超时重传，A就需要收到FIN之后再次发送ACK；要么B收到ACK了，那么A就可以关闭了，等待时间至少是B的timeout+FIN的传输时间，为保证可靠，采用了更加保守的等待时间2MSL(Maximum Segment Life)。\n状态机 将建立连接和关闭连接的两个时序图合起来就是著名的TCP状态机： 流量控制 拥塞控制 UDP 包头格式 和TCP相比，UDP具有非常简单的包头格式，可以说除了端口号就没有什么了。它不会去建立连接，只要监听相应的端口号，谁都可以传给他数据，他也可以传给任何人数据，甚至可以同时传给多个人数据。\n与TCP比较 TCP是面向连接的，而UDP是面向无连接的。所谓建立连接，就是为了在客户端和服务端之间维护连接，通过一定的数据结构来维持双方交互的状态，来保证面向连接的特性。\nTCP提供的是可靠交付，通过序号可以保证包不丢失、不重复、按序到达，但UDP是不保证不丢失，也不保证按顺序到达。\nTCP面向字节流，发送的时候发的是一个流，没头没尾。而UDP继承IP包的特性，基于数据报，一个个地发，一个个地收。\nTCP是可以进行拥塞控制的，它会根据网络环境调整自己发送的快慢，而UDP就不会。\nTCP是有状态的，UDP是无状态的。\n使用场景 基于UDP的特点，它适合于这些使用场景:\n 需要资源少，在网络情况较好的内网或者对于丢包不敏感的应用 无需一对一沟通，建立连接，而是可以广播的应用 需要处理速度快，时延低，可以容忍少数丢包，但要求即便拥塞也一往无前的时候  Socket Socket在Linux中以文件的形式存在，它是一种特殊的文件，是对打开open –\u0026gt; 读写write/read –\u0026gt; 关闭close模式的一个实现。\n在服务端和客户端通信之前，双方都要建立一个Socket，指定是IPv4还是IPv6，是基于数据流SOCK_STREAM的(TCP)还是基于数据报SOCK_DGRAM的(UDP)。\n基于TCP 基于TCP协议的Socket程序函数的调用过程如下图所示:\n服务端先调用bind函数为该socket赋予一个IP地址和端口，有了它就可以调用listen函数进入监听状态，客户端就可以发起连接。\n服务端内核为每个Socket维护了两个队列。一个队列是已经建立了连接的，三次握手已完成，处于ESTABLISHED状态；另一个是还没有完全建立连接的，处于SYN_RCVD状态。\n接着，服务端调用accept函数时，会拿出一个已完成的连接进行处理。如果没有已完成的连接，就要等着。服务端等待的时候，客户端可以通过connect函数发起连接，socket函数中声明要连接的IP地址和端口号，然后发起三次握手，一旦握手成功，服务端的accept函数会返回另一个socket。\n所以，服务端监听用的socket和真正用来传输数据的socket是两个，分别叫做监听Socket和已连接Socket。连接建立成功后，双方开始通过read和write函数读写数据。\n内核中既然socket是一个文件，那就有对应的文件描述符。每个进程中有个task_struct数组，里面指向该进程打开的所有文件，文件描述符可以理解为数组的index。每个文件又会有一个inode，socket对应的inode不像普通文件放在硬盘上，而是在内存中，这个inode指向了socket在内核中的Socket结构:\n这个Socket结构主要是两个队列，发送队列和接收队列，队列里面保存的是缓存sk_buff，每个sk_buff就能看到完整的包的结构。\n基于UDP 由于UDP的过程非常简单，没有建立连接，没有三次握手，只需要绑定IP和端口号。而且无需维护连接状态，服务端也就不需为每对连接建立一组socket，只需要一个socket就能和多个客户端通信，而且每次通信的时候通过调用sendto和recvfrom还能再传入IP地址和端口。\n并发处理 通过之前的基于TCP或UDP的socket函数建立连接之后，需要一个while循环，客户端和服务端不断的接收数据，就构成了一个基本的网络交互程序。但这个程序是一对一的，如何让服务端能服务更多的客户端呢？\n多进程 当建立连接之后，就会有一个已连接的socket，这时候可以fork出一个子进程，把接下来的数据接收的事情交给子进程来做。在Linux内核，子进程会复制文件描述符的列表，以及内存空间，还有当前执行到程序的哪一条语句。之前父进程accept之后创建的已连接socket也是一个文件描述符，就会被子进程获得。子进程通信完毕后，就需要退出，需要父进程通过子进程PID来查看它是否需要退出。\n多线程 每次和一个客户端连接就创建一个进程是很奢侈的事情，相对而言，创建一个线程就要轻量级很多。这些线程共享文件描述符列表、进程空间，也可以通过已连接的socket来处理客户端请求。\n但是一台机器无法创建过多的进程或线程，著名的C10K问题就是指单机操作系统无法维护过多的进程或线程，在早期成为一个瓶颈。为了解决这个问题，就发明了IO多路复用的方式。\nIO多路复用，select select的方式是有一个线程专门去监控所有的socket，因为socket是文件描述符，所有的socket都可以放在一个叫做fd_set的集合中，然后select函数来监听这个集合是否有变化。一旦有变化，就依次查看每个文件描述符，那些发生变化的文件描述符在fd_set中对应的位会设为1，表示socket可读或可写，从而可以进行读写操作。接着再次调用select函数，进入下一轮变化的监听。\n但是select仍然有个问题，就是当连接过多的时候，每次都通过轮询查看一遍fd_set效率不高。它虽然比多线程效率高很多，但仍然没有完全解决C10K的问题，于是有了epoll的方案。\n示例程序\nIO多路复用，epoll epoll通过注册callback函数，当某个文件描述符发生变化的时候，就会主动通知。\nepoll_create会创建一个epoll对象，它也是一个文件，对应一个文件描述符，它里面有一个红黑树，这个红黑树中就保存着要监听的所有socket。当epoll_ctl添加一个socket时，就是把它加入这个红黑树，同时红黑树中的节点指向一个结构，并将这个结构挂在被监听的socket事件列表中。当一个socket发生一个事件的时候，可以从这个列表中得到epoll对象，并调用callback通知它。\nepoll并非在所有情况都比select高效，例如在少于1024个文件描述符监听，且大多数socket都是处于活跃繁忙状态的时候，select会比epoll更高效，因为epoll会有更多次的系统调用，内核态和用户态的切换更为频繁。\n示例程序\nHTTP 请求准备 当我们输入一个域名，按下回车键时，浏览器会将它发送给DNS服务器，让它解析为IP地址。接着就可以通过三次握手建立TCP连接了。如果是HTTP1.1的协议，它开启了Keep-Alive，这样建立的TCP连接会在多次请求中复用，从而减少了不断建立连接和断开连接的消耗。\n请求构建 连接建立以后，就开始构建这样格式的请求:\n请求行 方法常用的有GET、POST、PUT、DELETE、HEAD、OPTIONS等。HEAD和GET请求同一个URL时服务端返回的响应头信息应该相同，只是对于HEAD服务端响应时不返回消息体，常用于测试该URL的有效性、是否有更新等。OPTIONS属于预检请求，常用于确认服务端该资源是否支持跨域以及支持哪些请求方法等。GET和HEAD属于安全的方法，GET、PUT、DELETE、HEAD、OPTIONS都是幂等的。\nURL一般是相对路径。版本一般是HTTP/1.1。\n请求头 请求头都是一行行key-value的字段，比较重要的有：\n Host，HTTP/1.1中的必需字段，服务器的域名和端口号(80可忽略) User-Agent，浏览器身份标识字符串 Content-Type，请求体的MIME类型(POST和PUT请求中) Authorization，认证信息  请求发送 HTTP协议基于TCP协议，所以它使用面向连接的方式发送请求，通过stream二进制流的方式传给对方。在TCP层，二进制了会变成一个个报文段发送给服务器，发送时要求对方有一个回应的ACK，没有回应就会重新传输直到可达。\nTCP层发送每个报文时都会加上自己的地址和目标的地址，把这两个信息放在IP头里交给IP层传输。IP层查看目标地址是否和自己在一个局域网，如果是，就发送ARP协议来请求目标地址对应的MAC地址，然后将源MAC和目标MAC放入MAC头，发送出去即可；如果不在，就先多一步发送到网关，在通过ARP得到网关的MAC地址，把源MAC和网关MAC放入MAC头发出。\n网关收到包发现MAC符合就取出目标IP地址，根据路由协议找到下一跳的路由器，获取下一跳的路由器MAC并将包发过去。这样一跳一跳最终到达目标的局域网，在这个局域网上发送ARP就可以获得目标地址的MAC，并将包发出去。\n服务器发现MAC地址符合，根据IP头中的协议项知道是TCP协议，然后解析TCP头，根据里面的序号确定是要回ACK还是丢弃掉。TCP头里面有端口号，HTTP进程正在监听，于是服务器最终把包交给这个进程去处理。\n返回构建 返回也有自己的格式:\n状态码有五种可能的取值:\n 1**，指示信息，表示请求已接收，需请求者继续处理 2**，成功，操作被重新接收并处理 3**，重定向，要完成请求必须进行更进一步的操作 4**，客户端错误，请求语法错误或请求无法实现 5**，服务端错误，服务器处理请求过程中发生了错误  响应头重要的字段有:\n Content-Type，响应体的MIME类型 Content-Length，响应体的长度 Access-Control-Allow-Origin，指定哪些网站可参与到跨资源共享过程中 Allow，对于该资源有效的动作(HTTP方法) Cache-Control，向从服务器直到客户端在内的所有缓存机制告知，它们是否可以缓存这个对象。如Cache-Control: max-age=3600 Expires，超过该时间则认为此回应已过期 Last-Modified，所请求的对象最后修改日期 Location，用于重定向 Refresh，设定可定时的重定向，例如Refresh: 5; url=http://a.com设定了5秒后跳转至a.com Set-Cookie，设置Cookie  响应构建好之后，也只是把请求发送的过程逆向来发送回去。\nHTTP 2.0 HTTP1.1在应用层是以纯文本的方式通信的，每次通信都要带上HTTP头部，在不考虑pipeline模式的情况下，每次的过程都是一去一回，这样在实时性和并发性上都有问题。\n为了解决这些问题，HTTP 2.0对HTTP头进行了压缩，将原来每次都要携带的头部key-value在两端都建立了一个索引表，对相同的字段只发送表中的索引即可。\n另外，HTTP 2.0还将一个TCP连接分为若干个流，每个流中可以传输若干消息，每个消息由若干最小的二进制帧组成。常见的帧有Header帧，用于传输Header内容，并且会开启一个新的流；还有Data帧，用来传输正文实体，多个Data帧属于同一个流。\n通过这两种机制，HTTP 2.0的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。例如:\nHTTP 2.0其实就是将三个请求变成三个流，将数据分成帧，乱序发送到一个TCP连接中。\nHTTPS HTTP协议最大的问题就是相当于在互联网上裸奔，任何一个中间人都可以截获客户端和服务端传输的数据包，没有任何隐私可言。HTTPS就是解决这个问题的，怎么解决？只能加密。\n对称加密 在对称加密算法中，加密和解密使用相同的一个密钥。它的优点是加密解密的效率很高，但是密钥若被窃取存在安全风险。因此，保证数据安全只要去保证双方约定好的密钥没有其他人知道就行了。\n那么新的问题就是，在http这个场景中，怎样让客户端和服务端约定一个密钥而不被中间人知晓？我们会发现，无论怎样设计，除非是线下传输，否则仅靠对称加密没有办法可靠的把密钥发送给对方。\n非对称加密 这时候我们想到了可以引入非对称加密的算法，它将密钥分为公钥和私钥。使用公钥加密的数据只能用私钥才能解开，使用私钥加密的数据也只有用公钥才能解开。它的优点是安全性高一些，缺点就是加解密的效率相比于对称加密就要差很多了。\n这时，我们想往服务端传递一段信息，就可以使用服务端提供的公钥加密，这样其他人都解不开，只有服务端自己有私钥才能解开。我们传递的这段信息既然是安全的，就可以让这段信息是一个随机生成的对称加密算法的密钥，这样双方之后的通信都可以基于对称加密对于工作效率的提升就很大了。\n证书 这样看起来好像没有问题，但是我们怎样才能获取到服务端的公钥呢？公钥虽然是公开的数据，但我们在通过网络传输获取的过程中，被别人篡改了怎么办？\n这时，只能引入一个新的第三方:CA机构，它作为一个权威机构专门给各个网站颁发证书(Certificate)。\n网站管理员用自己的公钥、域名、有效时长等信息向CA申请制作证书，证书做好以后经由CA机构的私钥进行加密得到一个字符串，网站管理员把这个字符串放在服务端。我们每次访问网站时，服务端把这个字符串给浏览器，浏览器使用CA提供的公钥进行解密，若解密成功就会得到这个证书，证书内又包含有服务端的公钥，就可以按之前说的方式继续通信了。\n问题从如何安全获取服务端的公钥变为如何安全获取CA机构的公钥了，这个就好解决了，我们无法把成千上万个网站的公钥内置在系统中，但可以把有限的几个CA机构的公钥内置进来，所以只要我们用正版的操作系统就好了。\n中间人此时能不能做个假网站，也去CA机构申请一个证书，然后在双方通信的时候用自己的字符串替换掉服务端返回的字符串呢？这样浏览器去CA解密也可以成功，但证书包含了网站的域名，依然是会被浏览器识破的。\n工作过程 HTTPS可以理解为在HTTP和TCP之间加了一层TLS/SSL，它的工作过程可以用下图表示:\n当我们登录一个网站的时候，客户端先发送Client Hello消息到服务端，以明文传输TLS版本信息、加密套件候选列表、压缩算法候选列表等信息，还包括一个随机数，用于之后协商对称密钥。\n服务端收到以后返回Server Hello消息，并附带服务器选择使用的协议版本、加密套件、压缩算法等，同样也会有一个随机数之后协商对称密钥用。然后再发送一个服务端的证书，并附带Server Hello Done表示信息都发完了。\n客户端拿到证书以后就从自己信任的CA仓库中，拿CA里的公钥去解密这个证书，如果能够成功，则说明证书是可信的，那么也就得到了证书中包含的服务端的公钥。接着通过计算产生随机数字Pre-master，发送Client Key Exchange，并用服务端公钥加密发送过去。\n现在，客户端和服务端都有了三个随机数字，分别是自己的、对端的以及刚刚生成的Pre-master。通过它们就可以在服务端和客户端之间生成相同的对称密钥了。\n有了对称密钥，客户端会发送Change Cipher Spec意思是之后可以用该密钥来加密通信了，并附带一条Encrypted Handshake Message发送给服务端用于数据与握手验证。服务端也做类似的事情，之后过程就和HTTP一样了。\n以上是大多数的场景，只需单向认证。在一些特殊场合，有更加严格要求时，也可能启动双向认证，双方互相验证证书。\nRPC "});index.add({'id':18,'href':'/docs/sicp/software/','title':"软件部分",'content':"计算机科学基础知识之软件部分 操作系统 操作系统是计算机体系的内核和基石，管理计算机硬件与软件资源。分为:\n 个人机: Windows, macOS, Linux/BSD 大型机: Linux, Unix 嵌入式: VxWorks 移动端: Android, Windows CE  因为Unix商业版权的原因，必须完全符合UNIX标准才能称为UNIX系统，其他的BSD/Linux只能称为UNIX-like。学术上的操作系统和我们日常口中说的操作系统不太一样，我们一般说的windows严格来说属于一个操作系统产品或者说一个操作系统的发行版，它是系统本身和一些软件(浏览器、扫雷)的打包，而学术上的操作系统指的是内核和一些必要的服务。\n现代操作系统的基本功能包括:\n 内存管理(memory management) 进程管理(process management) 中断处理(interrupt handling) 文件系统(file system) 安全机制(protection and security) 进程通信(inter-process communications) 设备驱动(device driver)  内核 微内核就是把最核心、最基础的部分单独作为内核，其他功能围绕它处理。包括地址空间、线程处理、进程通信等。这类东西它们需要以特权模式运行，其他基础服务当做普通应用程序独立运行。\n在内核中运行的程序使用的内存，叫内核空间，也叫内核态。其他程序运行在用户空间，也叫用户态。用户态的代码需要在内核态运行时，并不是直接放在内核态中运行的，这样安全没法保证，首先会做权限检查，通过之后相当于提交了申请，内核运行完成以后返回结果唤醒用户态的程序，这就又涉及到了上下文切换和状态保存。所以用户态和内核态的切换会消耗大量的资源。\n微内核的优点就是内核很小，裁剪起来方便，裁剪不同的基础服务就可以形成不同的版本面向不同的用户，另外就是其中某个服务崩溃的话不会影响到内核，内核可以重启改服务。当然缺点就是由于处于不同的地址空间，基础服务和内核通信时得使用类似于IPC(Inter-Process Communication)的方式通讯，效率相对会差一些。\n微内核的典型代表是学术上的windows和macOS，而不是Linux，早期的Linux为了性能考虑采用了宏内核。\n宏内核也叫单一内核，把核心和基础服务放在一个地址空间内均以特权模式运行，好处就是调用一些基础服务的时候相当于函数调用，不需要通讯，性能很高。缺点就是复杂度和耦合度很高，虽然代码是模块化的，但其中某个模块崩溃都可能导致整个系统崩溃，也不方便裁剪和移植。\n现代的操作系统往往是采用混合内核的，并不是泾渭分明的。\n系统调用 系统调用是内核对外的接口，内核态的一些内核函数。应用程序只要和硬件打交道都会涉及到系统调用，向操作系统申请并等待回复，应该尽量避免系统调用或考虑其他方式优化，比如有些场景可以使用在用户空间的带buffer的文件替代操作系统提供的文件读写API。\n典型的系统调用汇编代码: global _start section .data hello : db `hello, world!\\n` section .text _start: mov rax, 1 ; system call number should be store in rax  mov rdi, 1 ; argument #1 in rdi: where to write (descriptor)?  mov rsi, hello ; argument #2 in rsi: where does the string start?  mov rdx, 14 ; argument #3 in rdx: how many bytes to write?  syscall ; this instruction invokes a system call  mov rax, 60 ; \u0026#39;exit\u0026#39; syscall number  xor rdi, rdi syscall C语言、Go语言通过标准库进行系统调用，他们的标准库中的函数也只是在汇编之上的一种包装。在汇编语言中通过在不同寄存器中放不同的参数，再执行syscall这条指令就可以进行系统调用。syscall是64位操作系统改进的一条指令，x86下是int 0x80，这种改进效率上也更高一些。\nRAX寄存器存放不同系统调用的序号，相当于函数名称；RDI、RSI、RDX、R10、R8、R9依次存放参数；再用RAX存返回值。这是系统调用的调用约定。可以通过这里查看到系统调用函数有哪些，分别是如何传参的。\n进程 基础概念 程序和进程有什么区别？\n某个程序里包含了某个进程所需要的数据，但在某个时间点，进程中的内容未必和程序中的内容是一一对应的。我们开发一个程序，不仅包括可执行的代码，还有周边的素材等等，程序运行的时候，也未必会把全部内容都载入到内存。而进程指的是程序运行时，在内存当中受操作系统管理的部分。程序就像是蓝图，我们可以是照着同一份蓝图启动多个进程。\n进程不是执行单位，而是一个资源边界。相当于在内存这个世界里面，进程圈了一块地，这块地有很多的属性，比如虚拟地址空间、PID等，而地上的工人、流水线才是执行单位，我们称为线程。所以每个进程都有一个主线程。\n 进程是程序的运行期实例(但不同操作系统对进程定义可能不同) 是系统动态执行基本单元 是系统资源分配单位 是线程的容器 是指令、数据及相关资源的集合 是程序运行过程的抽象  状态  ready:除分配CPU外，其他准备就绪(按优先级排队调度) running:占用处理器资源，正在执行 waiting:因IO blocking、sync等原因⽆无法继续执⾏  调度 采用**抢占式调度，**CPU分配时间片，时间片结束则强制性切换并保存上下文。另外一种调度模式叫协作式调度，一般是在用户空间实现的。\n线程 也称轻量级进程(LWP)，是进程中的实际执行单位，由程序计数器、寄存器、栈内存组成。\n 进程拥有一到多个线程 线程是调度和时间片的分配单位，更多线程理论上会获得更多的CPU资源 线程共享进程的资源 同一程序的多个线程是可以在多核处理器上并行执行来提高执行吞吐率的，这个要看操作系统的调度策略  协程只是在用户空间的线程里实现的一种策略，本身和线程有很大的区别。\n内核线程和用户线程是有区别的，我们一般使用的线程都是被包装过的，很少通过系统调用来使用线程。用户线程可能是系统线程的包装体，它们是一对一关系；也可能是多个用户线程对应一个系统线程，多个用户线程分享一个时间片，这是多对一关系；还有一种可能是多对多关系，类似于Go的机制，某个时刻一个用户线程必然对应一个系统线程，但总体来看用户线程可能比系统线程更多或者更少。\n虚拟存储器 基础概念 操作系统会有一个很大的地址空间，也叫虚拟地址空间。这个空间的前面一大段是操作系统用的，之后的每个进程也都会有一个独立的很大的地址空间。这样不同的程序可以使用相同的虚拟地址，当程序在运行时访问某个地址就是访问进程内的虚拟地址，通过内存管理单元(MMU)翻译映射到一个物理地址。这样的好处就是无论在程序内的地址空间怎么折腾都不会影响到其他的程序，对编译器也更友好更方便，可以提前分配。\n我们在编译时看到的都是虚拟地址，物理地址在运行期才能看到。虚拟地址空间未必会全部映射到主存中，也会给各个设备保留一段空间。\n虚拟存储器可以看成硬盘保存的一个字节数组，虚拟地址空间有256TB，而实际的物理内存可能只有8GB，有这么大的虚拟地址空间就不能阻止程序去使用，不够的物理存储体我们就通过硬盘上的交换分区来弥补。也有可能物理内存加上交换分区都不够程序使用，在Linux中就会引发OOM机制。\n内存分配过程 假设某个程序需要内存分配器分配10MB的内存，那么操作系统会怎么做呢？首先会划分出一个虚拟地址范围，然后返回起始地址的指针。它此时没有必要通过MMU分配真实的物理内存，因为有可能这段内存后续根本没有读写发生。接下来若写入数据，也只会以页(8KB)为单位一点点的去写，每次写入的时候操作系统再去补物理内存，采用一种按需分配的机会主义原则。具体如何实现呢？当向一个虚拟地址写入数据时，就会去MMU找对应的物理地址，没有找到就说明没有建立映射关系还没有分配物理内存，就会引发一个缺页异常(page fault)，操作系统内有专门的程序把这一页补上，来实现按需分配。\n我们通过程序可以模拟这种虚拟内存和物理内存的关系: #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt; // gcc -g -O0 -o test test.c // ./test int main() { const size_t length = 1024 * 1024 * 100; const size_t pause = length / 10; unsigned char *p = malloc(length); // 分配100MB内存  unsigned char *x = p; for (int i = 0; i \u0026lt; (int)length; i++) // 循环写入数据  { *x = 1; x++; if (i % (int)pause == 0) // 隔一段时间暂停一下便于观察  { printf(\u0026#34;%d\\n\u0026#34;, i); getchar(); // 可以让用户在命令行中随时控制运行进度  } } free(p); return EXIT_SUCCESS; }\n观察运行结果: [ubuntu] ~/.mac $ pidstat -r -p `pidof test` 1 │Linux 4.9.184-linuxkit (cabd4e519687) 12/06/19 _x86_64_ (2 CPU)│ │11:10:18 UID PID minflt/s majflt/s VSZ RSS %MEM Command │11:10:19 0 180 0.00 0.00 106908 21624 1.06 test │11:10:20 0 180 0.00 0.00 106908 21624 1.06 test │11:10:21 0 180 0.00 0.00 106908 21624 1.06 test │11:10:22 0 180 2560.00 0.00 106908 31920 1.56 test │11:10:23 0 180 0.00 0.00 106908 31920 1.56 test │11:10:24 0 180 2534.65 0.00 106908 42216 2.06 test │11:10:25 0 180 0.00 0.00 106908 42216 2.06 test │11:10:26 0 180 2560.00 0.00 106908 52512 2.57 test │11:10:27 0 180 0.00 0.00 106908 52512 2.57 test │11:10:28 0 180 0.00 0.00 106908 52512 2.57 test │11:10:29 0 180 0.00 0.00 106908 52512 2.57 test │11:10:30 0 180 2560.00 0.00 106908 62544 3.06 test VSZ表示虚拟内存，RSS表示物理内存，可以看到随用户的控制，数据不断写入，物理内存增加。\n换入换出 假设这10MB内存已经分配下来，该程序却长时间不用，操作系统就会把这10MB内存的数据保存到硬盘的交换分区上，并对这些内存页的状态做变更，MMU的映射地址做变更，这些内存就可以去给别的程序用，这就叫换出(swap out)。下次重新激活该程序时，会把硬盘上交换分区的数据重新放回某些空闲的页并重新建立映射，这就是换入(swap in)。我们可以通过监控工具观察到系统内的换入换出情况: [ubuntu] ~ $ dstat You did not select any stats, using -cdngy by default. --total-cpu-usage-- -dsk/total- -net/total- ---paging-- ---system-- usr sys idl wai stl| read writ| recv send| in out | int csw 3 4 77 16 0| 12M 101k| 0 0 | 0 0 |1464 2562 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 175 408 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 148 345 0 0 100 0 0| 0 0 | 0 0 | 0 0 | 143 341 // paging的in和out即为当前换入换出大小,int表示当前有多少中断,csw表示当前有多少上下文切换 当程序运行需要的内存大于机器的物理内存时，就可能造成频繁的换入换出，产生颠簸效应(thrashing)。\n性能相关 如果程序需要性能更高、速度要有保障，就需要向操作系统申请锁死这段内存。同时，缺页异常属于内核级别的，有一定的开销，所以为了追求性能的极致，有的C程序会先进行一个初始化操作，缺页异常仍然会有只是会提前，在执行具体的算法时就会更高效不受缺页异常的影响，而一些高级语言可能会由于编译器的优化使得提前初始化写入被优化忽略掉。\n物理内存分配还采用了写入时复制(copy-on-write)的机制，即A若引用一块内存，那么复制A到B的时候并不会复制这块内存，只有当去写入A或B的时候才会去复制这块内存，起到节约内存的目的。\n对于服务器来讲，假设物理内存有8G，当前运行的程序只有4G，操作系统就会拿另外4G当做自己的cache用，比如缓存文件读写等，程序需要使用时再从cache里还回来。但对于桌面端用户来讲，GUI程序居多，占用内存也多，所以往往会有足够的内存来让用户载入一个程序的速度更快。服务器往往运行的程序数量和时间更长更稳定，所以不同操作系统的分配内存策略也不同。\n某种角度上，假设所有数据都交换到硬盘上，我们可以认为所有的数据保存在硬盘上，内存上只保存活跃数据，内存可以看成是硬盘的缓存或者说L4，虚拟存储器就可以看成硬盘上一个巨大的数组。\n寄存器 由于寄存器数量很少，我们就给每个寄存器起了个名字，并分为:\n 通用寄存器:AX,BX,CX,DX,SI,DI,SP,BP,R8-R15 指令寄存器:IP(也叫PC)，用于读取程序执行的下一条指令地址 标志寄存器:FR，用于存放处理器的状态和运算结果  通用寄存器 我们在寄存器名称前加个R，表示64位的寄存器；加个E，表示32位的；不加表示16位的；同时AH表示AX的高位；AL表示AX的地位。可以通过gdb观察到这些寄存器的值。\n(gdb) info registers rax 0x66\t102 rbx 0x0\t0 rcx 0x22\t34 rdx 0x33\t51 rsi 0x22\t34 rdi 0x11\t17 rbp 0x7fffffffe580\t0x7fffffffe580 rsp 0x7fffffffe550\t0x7fffffffe550 r8 0x7ffff7dd0d80\t140737351847296 r9 0x7ffff7dd0d80\t140737351847296 r10 0x0\t0 r11 0x0\t0 r12 0x555555554540\t93824992232768 r13 0x7fffffffe660\t140737488348768 r14 0x0\t0 r15 0x0\t0 rip 0x5555555546b2\t0x5555555546b2 \u0026lt;main+68\u0026gt; eflags 0x206\t[ PF IF ] cs 0x33\t51 ss 0x2b\t43 ds 0x0\t0 es 0x0\t0 fs 0x0\t0 gs 0x0\t0 (gdb) set $rbx=0x8070605040302010 (gdb) p/x $ebx $1 = 0x40302010 (gdb) p/x $bx $2 = 0x2010 (gdb) p/x $bh $3 = 0x20 (gdb) p/x $bl $4 = 0x10 所以有了这些访问的手段，一个寄存器是可以分割为不同的部分，存储不同内容的。通用寄存器用来存什么都可以，只是由于C语言出现的早，它对各个寄存器的一些用法就成了约定俗成的惯例，例如si、di用来传参，ax保存返回值，bp、sp表示栈底、栈顶，cx用来做循环等都是惯例。\n但指令寄存器是在硬件层面上和其他寄存器有不同，专门用来放程序执行的下一条指令的。\n标志寄存器 我们通过一个示例代码来观察标志寄存器的用途。\nglobal _start section .data hello : db `hello,world!\\n` section .text _start: mov rax, 1 test rax, rax ; 如果AX为0，则把ZF设为1，否则把ZF设为0  jne .exit ; 如果ZF为0，则跳转至.exit标签  .hello: mov rax, 1 mov rdi, 1 mov rsi, hello mov rdx, 14 syscall .exit: mov rax, 60 xor rdi, rdi syscall 标志寄存器有很多个位，ZF就是其中的一个位。哪个指令对哪个标志位有影响，都有手册可以查到，例如test指令可以通过这里查到，jne也是。\n接着，我们在gdb中观察: [ubuntu] ~/.mac/assem $ nasm -g -F dwarf -f elf64 -o fr.o fr.s [ubuntu] ~/.mac/assem $ ld -o fr fr.o [ubuntu] ~/.mac/assem $ gdb fr ... (gdb) b 9 Breakpoint 1 at 0x4000b0: file fr.s, line 9. (gdb) r Starting program: /root/.mac/assem/fr Breakpoint 1, _start () at fr.s:9 9\tmov rax, 1 (gdb) display $rax 1: $rax = 0 (gdb) display $eflags 2: $eflags = [ IF ] (gdb) n 10\ttest rax, rax ; ZF=1 if AX==0 else ZF=0 1: $rax = 1 2: $eflags = [ IF ] (gdb) n 11\tjne .exit ; jmp if ZF==0 1: $rax = 1 2: $eflags = [ IF ] (gdb) n _start.exit () at fr.s:21 21\tmov rax, 60\n标志寄存器中若某位有值则会出现在eflags中，按当前代码逻辑，ZF为0会直接跳转到.exit部分。然后我们在gdb中修改$rax的值，会发现跳转至.hello部分。\n(gdb) n 10\ttest rax, rax ; ZF=1 if AX==0 else ZF=0 1: $rax = 1 2: $eflags = [ IF ] (gdb) set $rax=0 (gdb) n 11\tjne .exit ; jmp if ZF==0 1: $rax = 0 2: $eflags = [ PF ZF IF ] (gdb) n _start.hello () at fr.s:14 14\tmov rax, 1 1: $rax = 0 2: $eflags = [ PF ZF IF ] 可执行文件 一个可执行程序看上去像是单个文件的数据库，我们以ELF格式的可执行文件为例，它包括头部元数据、Section header table、Program header table和各个section段。\nHead 文件头部包含一些元数据，用于进程加载找入口地址等:\n[ubuntu] ~/.mac/assem $ readelf -h hello ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 // 魔法数，可以快速读取出来用于预判整个文件是不是一个合法的内容 Class: ELF64 // ELF文件的格式 Data: 2\u0026#39;s complement, little endian // 大小端情况 Version: 1 (current) OS/ABI: UNIX - System V // 哪个平台使用 ABI Version: 0 Type: EXEC (Executable file) // 哪种类型，可执行的还是需重定位的等 Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x4000b0 //入口地址 Start of program headers: 64 (bytes into file) Start of section headers: 736 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 2 Size of section headers: 64 (bytes) Number of section headers: 8 Section header string table index: 7 Section 头部之后紧跟着各种各样的表，我们称之为Section(段)，各个section被计入可执行文件的Section header table中，我们可以这样查看:\n[ubuntu] ~/.mac/assem $ readelf -S hello There are 8 section headers, starting at offset 0x2e0: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 00000000004000b0 000000b0 0000000000000025 0000000000000000 AX 0 0 16 [ 2] .data PROGBITS 00000000006000d8 000000d8 000000000000000e 0000000000000000 WA 0 0 4 [ 3] .stab PROGBITS 0000000000000000 000000e8 0000000000000084 0000000000000014 4 0 4 [ 4] .stabstr STRTAB 0000000000000000 0000016c 0000000000000009 0000000000000000 0 0 1 [ 5] .symtab SYMTAB 0000000000000000 00000178 0000000000000108 0000000000000018 6 7 8 [ 6] .strtab STRTAB 0000000000000000 00000280 0000000000000027 0000000000000000 0 0 1 [ 7] .shstrtab STRTAB 0000000000000000 000002a7 0000000000000036 0000000000000000 0 0 1 Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), l (large), p (processor specific) 其中，Address表示这个section加载到进程中的虚拟内存地址，Offset表示这个section相对于文件头部的偏移量，有了Offset+Size进程才知道如何安排相应的Address。Flags表示权限标志位，A表示这个section的内容需要在内存中载入，X表示可执行的权限，W表示可写入的权限。\n.text用于存放二进制的执行代码(指令)。我们可以看到这个段的地址恰好是文件头中的Entry point address。\n.data用于存放所有已经初始化过的全局变量的数据，.bss用于存放未初始化的全局变量数据，虽然它们在内存中都需要相应的起始地址和内存区域，但在可执行文件中没必要用一定区域去记下.bss中的零值。.rodata专门用于保存只读数据，例如字符串的字面量，在很多语言中它都是只读的。\n.symtab表示符号表，源码中的字面量、全局变量、函数名、类型名、文件名等会作为符号记录在该表中，会记录它们的类型、作用域和内存地址。对于程序运行来讲，符号表没有什么用，CPU不管什么符号、类型，它只需要内存地址。符号就相当于是内存地址的助记符，主要是便于我们调试和反汇编使用的。\nSegment 执行的时候，我们需要告诉操作系统，有哪些section需要载入为内存中的segment，这个信息被链接器放在Program header table中，操作系统的载入器以此信息来安排程序在内存中的样子，我们可以这样查看:\n[ubuntu] ~/.mac/assem $ readelf -l hello Elf file type is EXEC (Executable file) Entry point 0x4000b0 There are 2 program headers, starting at offset 64 Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align LOAD 0x0000000000000000 0x0000000000400000 0x0000000000400000 0x00000000000000d5 0x00000000000000d5 R E 0x200000 LOAD 0x00000000000000d8 0x00000000006000d8 0x00000000006000d8 0x000000000000000e 0x000000000000000e RW 0x200000 Section to Segment mapping: Segment Sections... 00 .text 01 .data 上面的section to segment mapping就表示把section中的.text段的内容放在内存中00号的segment上。在可执行文件中会把section分的很细，但在内存中可能会把一些section合并起来，忽略掉一些section，起到节约内存的目的。\n函数调用 函数本身相当于一个图纸，出了设计院它就是只读的，放在.text段中，线程参考图纸来执行。线程通过IP/PC寄存器知道执行到图纸的哪里，下一条指令是什么，主线程通过可执行文件的入口地址找到第一条指令。\n调用堆栈 那么每个CPU核心只有一个IP寄存器，线程却有很多个怎么办？实际上在同一时刻，只有一个线程绑定了一套物理寄存器，若它的时间片用完了则由操作系统保存它对应的寄存器状态在某段内存中，下次轮到它执行时再恢复寄存器的状态。那么我们可以在抽象层面上理解为每个线程都有一套自己的寄存器。同时，这种切换线程需要消耗一定的资源，用于保存和恢复状态，用于内核态和用户态的切换。\n函数执行过程中需要在线程中保存参数、返回值、局部变量等，这块内存叫做栈(Stack)。那么如果是嵌套调用，如何保存各函数的状态呢？\n如左图所示，A函数嵌套了B函数，A要等待B执行完成之后再接着执行自己的逻辑。所以我们一般把栈内存竖着画，由底部的高位向低位分配，函数执行结束则把其对应的内存区域销毁，如右图所示。我们把每一个函数所占的格子叫栈帧(Stack Frame)，把整个A、B、C的调用层次称为调用堆栈(Call Stack)。程序出错时候我们看到一级级的错误信息就是通过调用堆栈追溯到的。\n调用一个函数，在指令级别上还是有很大的开销的，所以有了内联(inline)的优化手段。\n调用约定 接下来的问题是A调用B的时候，如何给B传递参数，如何接收B的返回值，要么A划定区域，要么B划定区域，要么用寄存器，要么用内存，我们把这种约定称为调用约定。以Go语言为例，若A调用B，则A会把自己的栈帧一分为二，下半部分存本地局部变量，上半部分存给B用的参数和B的返回值。若A调用B、C、D等多个函数，则上半部分占用多大空间按哪个函数的参数和返回值最大来算。如此一来，栈帧的大小是在编译期就能确定的，访问栈内某块内存只需根据相对位置，基于栈顶做加法或栈底做减法即可。\n一般会把栈顶的地址放在SP寄存器，把栈底的地址放在BP寄存器。理论上，SP或者BP使用一个就够了，每个语言都有自己的选择。Go早期只用SP，后来也引入了BP，因为很多的调试器、自动化检测工具需要使用BP确定栈底的位置。\n如果SP/BP用来存当前正在执行的B函数的栈帧，B执行完以后如何知道调用它的A函数的栈帧有多大呢？所以在两个栈帧之间还有一段空间用来存储A的BP/SP、IP，A在调用B的时候就把自己的BP/SP写进去，把自己调用完B之后下一条要执行什么指令写进IP，这叫保存现场。B执行完以后，通过这段空间恢复现场。接着，我们看看C语言和Go语言的保存现场和恢复现场分别是怎么做的。\nGo语言 func add(x, y int) int { z := x + y return z } func main() { a, b := 0x11, 0x22 s := add(a, b) println(s) } 通过go build -gcflags \u0026quot;-N -l\u0026quot; call.go接着进行gdb调试: (gdb) b 4 Breakpoint 1 at 0x452347: file /root/.mac/gocode/call.go, line 4. (gdb) r Thread 1 \u0026#34;call\u0026#34; hit Breakpoint 1, main.add (x=17, y=34, ~r2=0) at /root/.mac/gocode/call.go:4 4\tz := x + y (gdb) disass Dump of assembler code for function main.add: 0x0000000000452330 \u0026lt;+0\u0026gt;:\tsub rsp,0x10 0x0000000000452334 \u0026lt;+4\u0026gt;:\tmov QWORD PTR [rsp+0x8],rbp 0x0000000000452339 \u0026lt;+9\u0026gt;:\tlea rbp,[rsp+0x8] 0x000000000045233e \u0026lt;+14\u0026gt;:\tmov QWORD PTR [rsp+0x28],0x0 =\u0026gt; 0x0000000000452347 \u0026lt;+23\u0026gt;:\tmov rax,QWORD PTR [rsp+0x18] 0x000000000045234c \u0026lt;+28\u0026gt;:\tadd rax,QWORD PTR [rsp+0x20] 0x0000000000452351 \u0026lt;+33\u0026gt;:\tmov QWORD PTR [rsp],rax 0x0000000000452355 \u0026lt;+37\u0026gt;:\tmov QWORD PTR [rsp+0x28],rax 0x000000000045235a \u0026lt;+42\u0026gt;:\tmov rbp,QWORD PTR [rsp+0x8] 0x000000000045235f \u0026lt;+47\u0026gt;:\tadd rsp,0x10 0x0000000000452363 \u0026lt;+51\u0026gt;:\tret End of assembler dump.\n我们可以把它的栈帧变化情况画出来:\nC语言 int __attribute__((noinline, optimize(\u0026#34;-O0\u0026#34;))) add(int x, int y) { int z; z = x + y; return z; } int __attribute__((noinline)) main(int argc, char **argv) { int x, y, a; x = 0x11; y = 0x22; a = add(x, y); printf(\u0026#34;%d\\n\u0026#34;, a); } 通过gcc -g -O0 -o frame frame.c接着进行gdb调试: (gdb) b 5 Breakpoint 1 at 0x654: file frame.c, line 5. (gdb) r Breakpoint 1, add (x=17, y=34) at frame.c:6 6\tz = x + y; (gdb) disass Dump of assembler code for function add: 0x000055555555464a \u0026lt;+0\u0026gt;:\tpush rbp 0x000055555555464b \u0026lt;+1\u0026gt;:\tmov rbp,rsp 0x000055555555464e \u0026lt;+4\u0026gt;:\tmov DWORD PTR [rbp-0x14],edi 0x0000555555554651 \u0026lt;+7\u0026gt;:\tmov DWORD PTR [rbp-0x18],esi =\u0026gt; 0x0000555555554654 \u0026lt;+10\u0026gt;:\tmov edx,DWORD PTR [rbp-0x14] 0x0000555555554657 \u0026lt;+13\u0026gt;:\tmov eax,DWORD PTR [rbp-0x18] 0x000055555555465a \u0026lt;+16\u0026gt;:\tadd eax,edx 0x000055555555465c \u0026lt;+18\u0026gt;:\tmov DWORD PTR [rbp-0x4],eax 0x000055555555465f \u0026lt;+21\u0026gt;:\tmov eax,DWORD PTR [rbp-0x4] 0x0000555555554662 \u0026lt;+24\u0026gt;:\tpop rbp 0x0000555555554663 \u0026lt;+25\u0026gt;:\tret End of assembler dump. 同样可以画出图来: 比较 相同点是在调用CALL指令的时候，先把main函数中执行完add函数的下一条指令(在IP寄存器中)存在栈里，在调用RET指令的时候，这条指令会被自动恢复入IP寄存器。\n不同点是C语言通过push和pop指令入栈、出栈，让栈顶SP自动随着变化。而Go语言采用了sub、add指令直接计算栈顶地址。\n此外，在C语言中，是优先通过寄存器传递参数和返回值，经常使用SI、DI寄存器传参，使用AX寄存器存储返回值，因为C是性能优先，寄存器肯定是最快的。Go是使用栈内存传参和返回值的，这和它本身Goroutine的运行方式有关。\n栈和堆 堆、栈既是两种数据结构，也是函数执行单位，在不同的场景有不同的概念。\n对于栈内存来讲，它是整块的，不需要垃圾回收器参与，访问的时候只需要根据BP、SP按相对位置进行访问，所以它的效率是非常高的。而堆内存是和单个线程无关的，是共享的，就会涉及到很复杂的内存管理方式，分配的时候要找到大小和位置合适的块，释放的时候要尽可能的避免内存碎片化。所以说，编译器有责任尽可能把数据分配在栈上。但是，栈上内存是按栈帧整块释放的，某些情况下如果某个变量要在不同的栈帧中维持，它的生命周期发生了改变，这种情况这个变量的内存就要在堆上分配了，这种现象就叫逃逸。逃逸也会带来严重的性能问题。\n"});index.add({'id':19,'href':'/docs/go/closure/','title':"闭包",'content':"闭包 原理 我们先来看这样一个示例: func test() func() { x := 100 return func() { println(x) } } func main() { closure := test() closure() } 声明了一个test函数，它会返回一个匿名函数，这个匿名函数引用了它的局部变量x。那么当执行完closure := test()时，test的栈帧会被销毁，局部变量x应该失效，按照常理，匿名函数应该找不到x而无法打印，但实际上运行之后是能够正常打印的。那么这个x在哪？只有一种可能，它逃逸到堆上去了。既然是在堆上，x就会有一个地址，问题就变为匿名函数是怎么知道x的地址的？\n我们把这种现象叫做闭包，当一个匿名函数离开了它的宿主时，它依然持有它所引用的环境变量。所以闭包是包含两个部分的，其一是一个指针指向匿名函数的地址，其二是所拥有的环境变量，这两个东西打包合起来才称为一个闭包。\n可以理解为test函数的返回用伪码来表达应该是:\nreturn closure struct{ f : func(){println(x)} v : malloc(x) } 只不过Go的语法上让我们可以简写为示例代码中的样子，调用的时候编译器也是隐式的使用closure.f(closure.v)这样的方式来调用。\n实现 下面我们观察它的编译过程来证明这件事。使用go build -gcflags \u0026quot;-S\u0026quot; 2\u0026gt;a.txt closure.go把编译过程放到一个文本文件里，从中能找到一些相关线索: \u0026#34;\u0026#34;.test STEXT size=126 args=0x8 locals=0x28 0x0026 00038 (/root/.mac/gocode/closure.go:4)\tMOVQ\t$100, \u0026#34;\u0026#34;.x+16(SP) 0x002f 00047 (/root/.mac/gocode/closure.go:5)\tLEAQ\ttype.noalg.struct { F uintptr; \u0026#34;\u0026#34;.x int }(SB), AX \t0x003a 00058 (/root/.mac/gocode/closure.go:5)\tCALL\truntime.newobject(SB) 0x0049 00073 (/root/.mac/gocode/closure.go:5)\tLEAQ\t\u0026#34;\u0026#34;.test.func1(SB), CX 0x0050 00080 (/root/.mac/gocode/closure.go:5)\tMOVQ\tCX, (AX) 0x005a 00090 (/root/.mac/gocode/closure.go:5)\tMOVQ\t\u0026#34;\u0026#34;.x+16(SP), CX 0x005f 00095 (/root/.mac/gocode/closure.go:5)\tMOVQ\tCX, 8(AX)\t0x0068 00104 (/root/.mac/gocode/closure.go:5)\tMOVQ\tAX, \u0026#34;\u0026#34;.~r0+48(SP)\t\u0026#34;\u0026#34;.main STEXT size=65 args=0x0 locals=0x18 0x0022 00034 (/root/.mac/gocode/closure.go:11)\tMOVQ\t(SP), DX 0x0026 00038 (/root/.mac/gocode/closure.go:11)\tMOVQ\tDX, \u0026#34;\u0026#34;.closure+8(SP) 0x002b 00043 (/root/.mac/gocode/closure.go:12)\tMOVQ\t(DX), AX 0x002e 00046 (/root/.mac/gocode/closure.go:12)\tCALL\tAX \u0026#34;\u0026#34;.test.func1 STEXT size=84 args=0x0 locals=0x18 0x001d 00029 (/root/.mac/gocode/closure.go:5)\tMOVQ\t8(DX), AX 0x0021 00033 (/root/.mac/gocode/closure.go:5)\tMOVQ\tAX, \u0026#34;\u0026#34;.x+8(SP) 0x0026 00038 (/root/.mac/gocode/closure.go:6)\tCALL\truntime.printlock(SB) 0x002b 00043 (/root/.mac/gocode/closure.go:6)\tMOVQ\t\u0026#34;\u0026#34;.x+8(SP), AX 0x0030 00048 (/root/.mac/gocode/closure.go:6)\tMOVQ\tAX, (SP) 0x0034 00052 (/root/.mac/gocode/closure.go:6)\tCALL\truntime.printint(SB) LEAQ\ttype.noalg.struct { F uintptr; \u0026quot;\u0026quot;.x int }(SB), AX说明编译期就会根据元数据和类型信息创建好一个结构体，这个结构体就代表了一个闭包，现在在运行期只是把这个早已创建好的结构体的内存地址放到了AX寄存器中；接下来通过CALL\truntime.newobject(SB)依照之前的类型信息在堆上创建了一个对象；接着把函数的地址通过CX转到AX存的地址中，之前已经把x的值100放在\u0026quot;\u0026quot;.x+16(SP)的位置现在也转到了AX中存的地址+8的位置，也就是说现在在给之前的结构体填充数据。最终把AX中的内容当做返回值返回，~r0通常表示返回值，伪码表示test函数实际上返回的就是return \u0026amp;struct{F:test.func1, x:100}。\n那么在main函数中也就会接收到这样一个地址的返回值。因为test函数没有参数，SP偏移量为0的地址就是其返回值的地址，MOVQ\t(SP), DX就说明把test的返回放在了DX中；接着通过MOVQ\t(DX), AX把test返回值的地址也就是test.func1返回给AX寄存器，并CALL\tAX调用它。\n在test.func1中，通过MOVQ\t8(DX), AX从DX中存的地址偏移量+8也就是x的值100放在了AX寄存器中，接着放到栈上执行print。\nDX寄存器是整个闭包实现的核心，因为结构体是在堆上运行期动态分配的，它的地址在编译期不知道，闭包中的函数也是编译期就被编译为指令的，那么函数执行时如何知道它的本地变量的内存地址就是问题。DX寄存器是一个名字，编译期、运行期都一样，Go把动态的地址写进去，通过这个静态的名字加上偏移量来交互实现闭包。\n应用场景 计数器 每次调用返回一个自增的值，以前可能通过类或者全局变量，用函数实现会比较麻烦，有了闭包会比较简单: func getCounter() func() int { x := 0 return func() int { x++ return x } } func main() { c := getCounter() println(c()) println(c()) println(c()) } 有点类似于C语言中的静态局部变量，可以把数据绑定到函数身上，也就有点像类了。\n封闭区间 也可以把一份数据绑定到多个函数中去，如下例: func test() (func(), func(), func()) { x := 100 fmt.Printf(\u0026#34;%v\\n\u0026#34;, \u0026amp;x) return func() { fmt.Printf(\u0026#34;f1.x:%v\\n\u0026#34;, \u0026amp;x) }, func() { fmt.Printf(\u0026#34;f2.x:%v\\n\u0026#34;, \u0026amp;x) }, func() { fmt.Printf(\u0026#34;f3.x:%v\\n\u0026#34;, \u0026amp;x) } } func main() { f1, f2, f3 := test() f1() f2() f3() } x像是把全局变量的作用域缩小到test函数中，使得里面的三个不同逻辑共享它，构成了一个相对封闭的区间。\n绑定数据和逻辑 有时候需要A把方法和不同数据都传给B，直接传看上去不优雅，把它们打包为一个闭包看上去就像只传了一个方法，B只是接收一套逻辑，这个逻辑具体是怎么运行B不需要知道。 func hello(db Database) func(http.ResponseWriter, *http.Request) { return func(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, db.Url) } } func main() { db := NewDatabase(\u0026#34;localhost:5432\u0026#34;) http.HandleFunc(\u0026#34;/hello\u0026#34;, hello(db)) http.ListenAndServe(\u0026#34;:3000\u0026#34;, nil) }\n改变函数签名 例如把一个函数变成偏函数(partial) func test(x int) { println(x) } func partial(f func(int), x int) func() { return func() { f(x) } } func main() { f := partial(test, 100) f() }\n总结 闭包虽然改善了一些代码上的设计，让代码看上去更干净整洁，可以实现一些设计模式。但它延长了变量的生命周期，必然会导致逃逸行为，其内部的一些交互过程也会使执行性能降低。所以对于闭包也不能滥用。\n"});})();